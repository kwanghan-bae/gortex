import json
import os
import logging
import subprocess
import time
from datetime import datetime
from typing import Dict, Any, Optional, List

logger = logging.getLogger("GortexTrainer")

class GortexTrainer:
    """
    ì—ì´ì „íŠ¸ ì „ìš© ì†Œí˜• ëª¨ë¸(SLM)ì˜ í•™ìŠµ ê³¼ì •ì„ ê´€ë¦¬í•¨.
    ë°ì´í„°ì…‹ ê²€ì¦, í•™ìŠµ ì¡ ì˜ˆì•½, ëª¨ë¸ ë°°í¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        self.jobs_dir = "training_jobs"
        self.models_dir = "models/custom"
        os.makedirs(self.jobs_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)

    def create_training_job(self, dataset_path: str, base_model: str = "qwen2.5-coder:7b") -> str:
        """ìƒˆë¡œìš´ í•™ìŠµ ì¡ì„ ìƒì„±í•˜ê³  IDë¥¼ ë°˜í™˜í•¨."""
        job_id = f"JOB_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        job_dir = os.path.join(self.jobs_dir, job_id)
        os.makedirs(job_dir, exist_ok=True)
        
        job_config = {
            "job_id": job_id,
            "status": "pending",
            "dataset": dataset_path,
            "base_model": base_model,
            "created_at": datetime.now().isoformat(),
            "metrics": {}
        }
        
        config_path = os.path.join(job_dir, "config.json")
        with open(config_path, "w") as f:
            json.dump(job_config, f, indent=2)
            
        logger.info(f"ğŸ—ï¸ Created training job: {job_id} using {dataset_path}")
        return job_id

    def start_job(self, job_id: str):
        """í•™ìŠµ ì¡ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•¨ (ì‹œë®¬ë ˆì´ì…˜)."""
        job_dir = os.path.join(self.jobs_dir, job_id)
        config_path = os.path.join(job_dir, "config.json")
        
        if not os.path.exists(config_path):
            return False
            
        with open(config_path, "r") as f:
            config = json.load(f)
            
        config["status"] = "running"
        config["started_at"] = datetime.now().isoformat()
        
        with open(config_path, "w") as f:
            json.dump(config, f, indent=2)
            
        logger.info(f"ğŸš€ Training started for {job_id}...")
        
        # [SIMULATION] ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì— fine-tuning ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë¡œì§ì´ ë“¤ì–´ê°
        # ì˜ˆ: subprocess.Popen(["python3", "scripts/finetune.py", "--config", config_path])
        # ë°ëª¨ë¥¼ ìœ„í•´ 5ì´ˆ í›„ ì™„ë£Œ ì²˜ë¦¬í•˜ëŠ” ì½”ë£¨í‹´ì²˜ëŸ¼ ë™ì‘í•˜ë„ë¡ ì„¤ê³„
        return True

    def check_status(self, job_id: str) -> Dict[str, Any]:
        """ì¡ì˜ ì§„í–‰ ìƒíƒœì™€ ê²°ê³¼ ëª¨ë¸ ê²½ë¡œë¥¼ ë°˜í™˜í•¨."""
        path = os.path.join(self.jobs_dir, job_id, "config.json")
        if os.path.exists(path):
            with open(path, "r") as f:
                return json.load(f)
        return {"status": "not_found"}

    def register_custom_model(self, job_id: str, agent_name: str):
        """í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ì„ íŠ¹ì • ì—ì´ì „íŠ¸ì˜ ì „ìš© ëª¨ë¸ë¡œ ë“±ë¡í•¨."""
        status = self.check_status(job_id)
        if status.get("status") == "completed":
            model_name = f"custom:{agent_name.lower()}:{job_id}"
            
            # 1. GortexAuth ì—°ë™ (Ollama ìš°ì„ ìˆœìœ„ ë°˜ì˜)
            from gortex.core.auth import GortexAuth
            auth = GortexAuth()
            if agent_name.lower() in auth.OLLAMA_ROLE_MAP:
                auth.OLLAMA_ROLE_MAP[agent_name.lower()].insert(0, model_name)
            
            # 2. AgentRegistry ë©”íƒ€ë°ì´í„° ê°±ì‹  (ê³µì‹ ë²„ì „ ì—…ê·¸ë ˆì´ë“œ)
            from gortex.core.registry import registry
            meta = registry.get_metadata(agent_name)
            if meta:
                meta.version = f"{meta.version}+slm"
                # ì „ìš© ëª¨ë¸ íƒœê·¸ ì¶”ê°€
                if "custom_model" not in meta.tools:
                    meta.tools.append(f"model:{model_name}")
                
            logger.info(f"ğŸ’ Agent '{agent_name}' upgraded with Custom SLM: {model_name}")
            return True
        return False

# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
trainer = GortexTrainer()
