import logging
import uuid
import time
import json
import asyncio
from typing import Dict, Any, List, Optional
from gortex.core.graph import compile_gortex_graph
from gortex.core.state import GortexState
from gortex.core.config import GortexConfig
from gortex.utils.tools import execute_shell
from gortex.utils.token_counter import count_tokens
from gortex.utils.notifier import Notifier
from gortex.utils.healing_memory import SelfHealingMemory
from gortex.utils.token_counter import count_tokens, DailyTokenTracker

logger = logging.getLogger("GortexEngine")

class GortexEngine:
    """
    Gortex ì‹œìŠ¤í…œì˜ í•µì‹¬ ì‹¤í–‰ ì—”ì§„.
    ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ê³  ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    def __init__(self, ui=None, observer=None, vocal_bridge=None, thread_id: str = None):
        self.ui = ui
        self.observer = observer
        self.vocal = vocal_bridge
        self.graph = compile_gortex_graph()
        self.thread_id = thread_id or str(uuid.uuid4())
        self.config = {"configurable": {"thread_id": self.thread_id}}
        self.healer = SelfHealingMemory()
        self.tracker = DailyTokenTracker()

    def select_optimal_model(self, state: GortexState, agent_name: str) -> str:
        """ì—ì´ì „íŠ¸ í‰íŒ, ì‘ì—… ìœ„í—˜ë„, ì¼ì¼ ì˜ˆì‚°ì„ ê³ ë ¤í•˜ì—¬ ìµœì  ëª¨ë¸ ì„ íƒ"""
        risk = state.get("risk_score", 0.5)
        budget_status = self.tracker.get_budget_status()
        economy = state.get("agent_economy", {}).get(agent_name, {})
        points = economy.get("points", 0)
        
        # 1. ì˜ˆì‚° ê³ ê°ˆ ìƒíƒœ (80% ì´ìƒ ì†Œëª¨) -> ê°•ì œ Ollama ë‹¤ìš´ê·¸ë ˆì´ë“œ
        if budget_status > 0.8:
            logger.warning(f"ğŸ”‹ Budget critical ({budget_status:.1%}). Downgrading to Ollama.")
            return "ollama/llama3"
            
        # 2. ê³ ìœ„í—˜/ì—í”½ ì‘ì—… + ì—˜ë¦¬íŠ¸ ì—ì´ì „íŠ¸ -> Gemini Pro
        if risk > 0.8 and points > 1000:
            return "gemini-1.5-pro"
            
        # 3. ì¼ë°˜ ì „ë¬¸ ì‘ì—… -> Gemini Flash
        if points > 500 or risk > 0.4:
            return "gemini-2.0-flash"
            
        # 4. ë‹¨ìˆœ ë°˜ë³µ ì‘ì—…/ì €í‰íŒ ì—ì´ì „íŠ¸ -> Ollama
        return "ollama/llama3"

    async def process_node_output(self, node_name: str, output: Dict[str, Any], state: Dict[str, Any]):
        """ë…¸ë“œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  UI/ê´€ì°°ìì—ê²Œ ì•Œë¦¼"""
        # í† í° ì¶”ì  ì—…ë°ì´íŠ¸
        tokens = count_tokens(json.dumps(output))
        model = state.get("assigned_model", "flash")
        self.tracker.update_usage(tokens, model)


        
        # 2. ì¸ê³¼ ê´€ê³„ ë° ê´€ì°°ì ê¸°ë¡
        event_id = str(uuid.uuid4())
        if self.observer:
            # state["last_event_id"]ë¥¼ cause_idë¡œ ì‚¬ìš©
            cause_id = state.get("last_event_id")
            res_id = self.observer.log_event(
                agent=node_name, 
                event="node_complete", 
                payload=output, 
                cause_id=cause_id
            )
            # ê²°ê³¼ IDë¥¼ ë‹¤ì‹œ last_event_idì— ì €ì¥ (ì—°ì‡„)
            state["last_event_id"] = res_id or event_id
        
        # 3. UI ì—…ë°ì´íŠ¸ ë° ì„±ê³¼ ê¸°ë¡
        if self.ui:
            self.ui.update_thought(output.get("thought", ""), agent_name=node_name)
            
            if "ui_mode" in output:
                self.ui.set_layout_mode(output["ui_mode"])
            
            # ì„±ê³¼ ê¸°ë¡ ì¡°ê±´: ë©”ì‹œì§€ì— "ì™„ë£Œí–ˆìŠµë‹ˆë‹¤" í¬í•¨ ì‹œ
            msg_str = str(output.get("messages", ""))
            if "ì™„ë£Œí–ˆìŠµë‹ˆë‹¤" in msg_str:
                self.ui.add_achievement("Goal Reached")
            
            # ë³´ì•ˆ ê²½ê³ 
            if "âŒ" in msg_str or "security alert" in msg_str.lower():
                self.ui.add_security_event("High", "Security issue detected")
            
            # [ECONOMY] ê²½ì œ ìƒíƒœ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
            if "agent_economy" in state or "agent_economy" in output:
                eco_data = output.get("agent_economy") or state.get("agent_economy")
                if eco_data:
                    self.ui.update_economy_panel(eco_data)
        
        # 4. ìŒì„± ë¸Œë¦¿ì§€ ì—°ë™
        if self.vocal and output.get("messages"):
            last_msg = str(output["messages"][-1][1] if isinstance(output["messages"][-1], tuple) else output["messages"][-1])
            self.vocal.text_to_speech(last_msg)
            self.vocal.play_audio()
            
        # 5. ìê°€ ì¹˜ìœ  (Healer)
        if output.get("status") == "failed":
            hint = self.healer.get_solution_hint("Error detected in node output")
            if hint:
                logger.info(f"ğŸ©¹ Healing hint found: {hint}")

        # 6. ìƒíƒœ ë³€ìˆ˜ ë³‘í•© ë° ìºì‹œ ê´€ë¦¬
        if "file_cache" in output:
            if "session_cache" not in state: state["session_cache"] = {}
            state["session_cache"].update(output["file_cache"])
            
        state.update(output)
        return tokens

    def run(self, user_input: str, initial_state: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì—ì´ì „íŠ¸ ë£¨í”„ ì‹¤í–‰"""
        state = initial_state or {
            "messages": [("user", user_input)],
            "pinned_messages": [],
            "plan": [],
            "current_step": 0,
            "working_dir": ".",
            "file_cache": {},
            "agent_energy": 100,
            "api_call_count": 0,
            "token_credits": {},
            "agent_economy": {}
        }
        
        # [MAINTENANCE] ì—ë„ˆì§€ ê³ ê°ˆ ì²´í¬
        energy = state.get("agent_energy", 100)
        if energy < 10:
            logger.warning(f"ğŸ”‹ Energy critical ({energy}%). Entering Maintenance Mode.")
            return {
                "messages": [("ai", "ğŸ”‹ **ì‹œìŠ¤í…œ ì—ë„ˆì§€ ê³ ê°ˆ**: í˜„ì¬ ìœ ì§€ë³´ìˆ˜ ëª¨ë“œì…ë‹ˆë‹¤. ì—ë„ˆì§€ê°€ ì¶©ì „ë  ë•Œê¹Œì§€ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” (ìµœì†Œ 20% í•„ìš”).")],
                "next_node": "__end__"
            }
        
        try:
            final_state = self.graph.invoke(state, self.config)
            return final_state
        except Exception as e:
            logger.error(f"Engine execution failed: {e}")
            return {"error": str(e), "next_node": "__end__"}

    async def run_async(self, user_input: str, initial_state: Optional[Dict[str, Any]] = None):
        """ë¹„ë™ê¸° ì‹¤í–‰ ì§€ì›"""
        return self.run(user_input, initial_state)