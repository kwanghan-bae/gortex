import os
import time
import random
import logging
from typing import List, Optional, Any, Dict
from google import genai
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("GortexAuth")

# .env ë¡œë“œ
env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
if os.path.exists(env_path):
    load_dotenv(env_path)
else:
    load_dotenv()

from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class APIKeyInfo:
    key: str
    client: genai.Client
    status: str = "alive" # alive, cooldown, exhausted
    last_failure: Optional[datetime] = None
    cooldown_until: Optional[datetime] = None
    failure_count: int = 0

class GortexAuth:
    """
    API í• ë‹¹ëŸ‰ ì†Œì§„ ì‹œ ë‹¤ë¥¸ ê³„ì •ì´ë‚˜ ì„œë¹„ìŠ¤(OpenAI)ë¡œ í´ë°±í•˜ëŠ” ë©€í‹° LLM ì¸ì¦ ì—”ì§„.
    ì§€ëŠ¥í˜• í‚¤ ë¡œí…Œì´ì…˜ ë° ì¿¨ë‹¤ìš´(Cooldown) ì‹œìŠ¤í…œ íƒ‘ì¬.
    """
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GortexAuth, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    @classmethod
    def _reset(cls):
        """ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ìš©)"""
        cls._instance = None

    def __init__(self):
        if hasattr(self, '_initialized') and self._initialized:
            return
            
        # Gemini í‚¤ í’€ ì´ˆê¸°í™”
        raw_keys = [
            os.getenv("GEMINI_API_KEY_1"),
            os.getenv("GEMINI_API_KEY_2"),
            os.getenv("GEMINI_API_KEY_3"),
            os.getenv("GEMINI_API_KEY_4")
        ]
        self.key_pool: List[APIKeyInfo] = []
        for k in raw_keys:
            if k:
                self.key_pool.append(APIKeyInfo(key=k, client=genai.Client(api_key=k)))
        
        self.current_key_idx = 0
        
        # OpenAI ì„¤ì • (ìµœì¢… í´ë°±ìš©)
        self.openai_key = os.getenv("OPENAI_API_KEY")
        self.openai_client = OpenAI(api_key=self.openai_key) if (OpenAI and self.openai_key) else None
        
        self.model_mapping = {
            "gemini-1.5-flash": "gpt-4o-mini",
            "gemini-1.5-pro": "gpt-4o",
            "gemini-2.0-flash": "gpt-4o",
            "gemini-2.5-flash-lite": "gpt-4o-mini"
        }
        
        self.call_history: List[float] = []
        self._provider = "gemini"
        self._initialized = True

    def _track_call(self):
        now = time.time()
        self.call_history.append(now)
        self.call_history = [t for t in self.call_history if now - t < 60]

    def get_call_count(self) -> int:
        now = time.time()
        self.call_history = [t for t in self.call_history if now - t < 60]
        return len(self.call_history)

    def get_provider(self) -> str:
        return self._provider.upper()

    def _get_available_gemini_key(self) -> Optional[APIKeyInfo]:
        """í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ(Alive ë˜ëŠ” Cooldown ì¢…ë£Œëœ) í‚¤ë¥¼ ì°¾ìŒ"""
        now = datetime.now()
        
        # 1. ë§Œë£Œëœ Cooldown ë¨¼ì € í•´ì œ
        for key_info in self.key_pool:
            if key_info.status == "cooldown" and key_info.cooldown_until and now >= key_info.cooldown_until:
                logger.info(f"ğŸ”„ Key Cooldown expired for a key. Resetting to alive.")
                key_info.status = "alive"
                key_info.failure_count = 0
        
        # 2. ì²« ë²ˆì§¸ Alive ìƒíƒœì¸ í‚¤ ë°˜í™˜
        for key_info in self.key_pool:
            if key_info.status == "alive":
                return key_info
                
        return None

    def report_key_failure(self, key_info: APIKeyInfo, is_quota_error: bool):
        """í‚¤ ì‹¤íŒ¨ ë³´ê³  ë° ì¿¨ë‹¤ìš´ ì„¤ì •"""
        key_info.last_failure = datetime.now()
        key_info.failure_count += 1
        
        if is_quota_error:
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ëŠ” ê¸´ ì¿¨ë‹¤ìš´ (ìµœì†Œ 10ë¶„)
            cooldown_mins = 10 * key_info.failure_count
            key_info.status = "cooldown"
            key_info.cooldown_until = datetime.now() + timedelta(minutes=cooldown_mins)
            logger.warning(f"âš ï¸ Key Quota Exhausted. Cooldown for {cooldown_mins} mins.")
        else:
            # ë‹¨ìˆœ ì„œë²„ ì˜¤ë¥˜ ë“±ì€ ì§§ì€ ëŒ€ê¸° í›„ ì¬ì‹œë„ ê°€ëŠ¥í•˜ë„ë¡ alive ìœ ì§€í•˜ë˜ ì¹´ìš´íŠ¸ë§Œ ì¦ê°€
            if key_info.failure_count >= 3:
                key_info.status = "cooldown"
                key_info.cooldown_until = datetime.now() + timedelta(minutes=2)
                logger.warning(f"âš ï¸ Key repeated failures. 2 mins cooldown.")

    def generate(self, model_id: str, contents: Any, config: Optional[Any] = None) -> Any:
        self._track_call()
        
        # 1. Gemini ì‹œë„
        for _ in range(len(self.key_pool) * 2): # ëª¨ë“  í‚¤ë¥¼ ìµœì†Œ ë‘ ë²ˆì€ ëŒì•„ë´„
            key_info = self._get_available_gemini_key()
            if not key_info:
                break
                
            try:
                self._provider = "gemini"
                return key_info.client.models.generate_content(model=model_id, contents=contents, config=config)
            except Exception as e:
                err = str(e)
                is_quota = any(x in err for x in ["429", "Quota", "Exhausted", "Resource"])
                is_server = any(x in err for x in ["500", "503", "Overloaded"])
                
                self.report_key_failure(key_info, is_quota)
                
                if is_server:
                    logger.warning(f"â— Gemini server busy. Retrying with next key...")
                    time.sleep(2)
                    continue
                elif is_quota:
                    # ì§€í„° ëŒ€ê¸° í›„ ë‹¤ìŒ í‚¤
                    time.sleep(random.uniform(1.0, 3.0))
                    continue
                else:
                    logger.error(f"âŒ Gemini Critical Error: {e}")
                    raise e

        # 2. OpenAI í´ë°±
        if self.openai_client:
            self._provider = "openai"
            logger.warning("ğŸš¨ No Gemini keys available. Switching to OpenAI fallback.")
            return self._generate_openai(model_id, contents, config)
            
        raise Exception("ğŸš« ëª¨ë“  LLM ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€ëŠ¥ (Gemini/OpenAI ì†Œì§„)")

    def _generate_openai(self, model_id: str, contents: Any, config: Optional[Any]) -> Any:
        # (ê¸°ì¡´ OpenAI ë³€í™˜ ë¡œì§ ìœ ì§€)
        target_model = self.model_mapping.get(model_id, "gpt-4o-mini")
        messages = []
        if isinstance(contents, list):
            for c in contents:
                role = "user" if (isinstance(c, tuple) and c[0] == "user") or (hasattr(c, 'role') and c.role == "user") else "assistant"
                text = c[1] if isinstance(c, tuple) else (c.parts[0].text if hasattr(c, 'parts') else str(c))
                messages.append({"role": role, "content": text})
        else:
            messages.append({"role": "user", "content": str(contents)})

        if config and hasattr(config, 'system_instruction'):
            messages.insert(0, {"role": "system", "content": str(config.system_instruction)})

        response = self.openai_client.chat.completions.create(
            model=target_model,
            messages=messages,
            temperature=getattr(config, 'temperature', 0.0) if config else 0.0
        )
        
        class OpenAIResponseAdapter:
            def __init__(self, res):
                self.text = res.choices[0].message.content
        return OpenAIResponseAdapter(response)

