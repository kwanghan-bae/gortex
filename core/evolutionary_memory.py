import json
import os
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional

logger = logging.getLogger("GortexEvolutionaryMemory")

class EvolutionaryMemory:
    """
    ì£¼ì œë³„ ìƒ¤ë”©(Sharding) ê¸°ìˆ ì„ ì ìš©í•˜ì—¬ ì§€ëŠ¥ ë°ì´í„°ë¥¼ ë¶„ì‚° ê´€ë¦¬í•˜ëŠ” ë©”ëª¨ë¦¬ í´ë˜ìŠ¤.
    """
    def __init__(self, base_dir: str = "logs/memory"):
        self.base_dir = base_dir
        os.makedirs(self.base_dir, exist_ok=True)
        os.makedirs(os.path.join(self.base_dir, "snapshots"), exist_ok=True)
        self.legacy_path = "experience.json"
        self.shards: Dict[str, List[Dict[str, Any]]] = {}
        self._initialize_shards()

    def detect_global_conflicts(self) -> List[Dict[str, Any]]:
        """ì „ì²´ ìƒ¤ë“œë¥¼ ìŠ¤ìº”í•˜ì—¬ íŠ¸ë¦¬ê±° ì¤‘ë³µ ë° ì§€ì¹¨ ëª¨ìˆœì„ ê°ì§€í•˜ê³  í† ë¡  ì˜ì œë¥¼ ì„¤ì •í•¨."""
        conflicts = []
        all_rules = []
        for cat, rules in self.shards.items():
            all_rules.extend(rules)
            
        for i, rule_a in enumerate(all_rules):
            patterns_a = set(rule_a["trigger_patterns"])
            for j, rule_b in enumerate(all_rules[i+1:]):
                if rule_a["id"] == rule_b["id"]: continue
                
                patterns_b = set(rule_b["trigger_patterns"])
                intersection = patterns_a.intersection(patterns_b)
                
                # 1. íŠ¸ë¦¬ê±° íŒ¨í„´ ì¤‘ì²© (50% ì´ìƒ) ë˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œ ì¼ì¹˜ ì‹œ ê°ˆë“± í›„ë³´
                if len(intersection) / max(len(patterns_a), len(patterns_b)) >= 0.5:
                    conflicts.append({
                        "type": "semantic_conflict",
                        "agenda": f"Conflict between {rule_a['category']} and {rule_b['category']} rules",
                        "rule_a": rule_a,
                        "rule_b": rule_b,
                        "overlap": list(intersection),
                        "severity": max(rule_a.get("severity", 3), rule_b.get("severity", 3))
                    })
        return conflicts

    def _initialize_shards(self):
        """ê¸°ì¡´ ì§€ì‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ìƒ¤ë“œ ë¡œë“œ"""
        if os.path.exists(self.legacy_path):
            logger.info("ğŸ“¦ Migrating legacy experience.json to shards...")
            try:
                with open(self.legacy_path, 'r', encoding='utf-8') as f:
                    legacy_data = json.load(f)
                for item in legacy_data:
                    category = self._guess_category(item.get("learned_instruction", ""))
                    self.save_rule(
                        instruction=item["learned_instruction"],
                        trigger_patterns=item["trigger_patterns"],
                        category=category,
                        severity=item.get("severity", 3),
                        source_session=item.get("source_session", "legacy_migration")
                    )
                os.rename(self.legacy_path, self.legacy_path + ".migrated.bak")
            except Exception as e:
                logger.error(f"Migration failed: {e}")

        for cat in ["coding", "research", "design", "general"]:
            self.shards[cat] = self._load_shard(cat)

    def _load_shard(self, category: str) -> List[Dict[str, Any]]:
        path = os.path.join(self.base_dir, f"{category}_shard.json")
        if os.path.exists(path):
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return []
        return []

    def _persist_shard(self, category: str):
        path = os.path.join(self.base_dir, f"{category}_shard.json")
        try:
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(self.shards.get(category, []), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to persist {category} shard: {e}")

    def _guess_category(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ìƒ¤ë“œ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        text = text.lower()
        if any(k in text for k in ["code", "python", "import", "class", "def", "syntax"]):
            return "coding"
        elif any(k in text for k in ["search", "trend", "latest", "find", "google"]):
            return "research"
        elif any(k in text for k in ["ui", "dashboard", "layout", "design", "color"]):
            return "design"
        return "general"

    def save_rule(self, instruction: str, trigger_patterns: List[str], category: Optional[str] = None, severity: int = 3, source_session: Optional[str] = None, context: Optional[str] = None) -> str:
        """ìƒˆë¡œìš´ ê·œì¹™ì„ íŠ¹ì • ìƒ¤ë“œì— ì €ì¥ (ID ë°˜í™˜ ë° ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì‹ë³„ì ì‚¬ìš©)"""
        cat = category or self._guess_category(instruction + " " + " ".join(trigger_patterns))
        if cat not in self.shards:
            self.shards[cat] = self._load_shard(cat)
            
        shard = self.shards[cat]
        new_patterns = set(trigger_patterns)
        
        for existing in shard:
            if existing["learned_instruction"].strip() == instruction.strip():
                existing["trigger_patterns"] = list(set(existing["trigger_patterns"]).union(new_patterns))
                existing["reinforcement_count"] = existing.get("reinforcement_count", 0) + 1
                self._persist_shard(cat)
                return existing["id"]

        # %f ì¶”ê°€í•˜ì—¬ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì¶©ëŒ ë°©ì§€
        rule_id = f"RULE_{cat.upper()}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        new_rule = {
            "id": rule_id,
            "category": cat,
            "trigger_patterns": trigger_patterns,
            "learned_instruction": instruction,
            "context": context,
            "severity": severity,
            "reinforcement_count": 1,
            "created_at": datetime.now().isoformat(),
            "usage_count": 0,
            "success_count": 0,
            "failure_count": 0,
            "is_certified": False
        }
        shard.append(new_rule)
        self._persist_shard(cat)
        logger.info(f"New rule saved to '{cat}' shard: {rule_id}")
        return rule_id

    def get_active_constraints(self, context_text: str) -> List[str]:
        """ë§¥ë½ê³¼ ê´€ë ¨ëœ ìƒ¤ë“œì—ì„œ í™œì„± ì œì•½ ì¡°ê±´ ì¶”ì¶œ (ë””ìŠ¤í¬ ê°•ì œ ë™ê¸°í™” ë° 3ë‹¨ê³„ ì •ë°€ ì •ë ¬)"""
        target_cat = self._guess_category(context_text)
        search_cats = {target_cat, "general"}
        
        matching_rules = []
        for cat in search_cats:
            # ì‹¤ì‹œê°„ ë™ê¸°í™”: í•­ìƒ ë””ìŠ¤í¬ì—ì„œ ìµœì‹  ìƒ¤ë“œë¥¼ ì½ì–´ì˜´
            shard = self._load_shard(cat)
            self.shards[cat] = shard
            
            for rule in shard:
                if any(p.lower() in context_text.lower() for p in rule["trigger_patterns"]):
                    # 1. ìƒíƒœ ë³´ì • (ëˆ„ë½ëœ í•„ë“œ ë³µêµ¬)
                    usage = int(rule.get("usage_count", 0))
                    success = int(rule.get("success_count", 0))
                    is_certified = bool(rule.get("is_certified", False))
                    
                    # 2. ì˜í–¥ë ¥ ì ìˆ˜ ê³„ì‚° (Laplace Smoothing)
                    # usageë¥¼ 1 ì¦ê°€ì‹œí‚¨ ê°€ìƒì˜ ì ìˆ˜ë¡œ ì •ë ¬
                    rule["impact_score"] = float((success + 1) / (usage + 2))
                    rule["is_certified"] = is_certified
                    
                    matching_rules.append(rule)
                    # í†µê³„ ê°±ì‹  (ì‹¤ì œ ë°˜ì˜ì€ record_rule_outcomeì—ì„œ í•˜ë˜, 
                    # ì¡°íšŒ íšŸìˆ˜ ì¦ê°€ëŠ” ì¶”ì ìš©ìœ¼ë¡œ ë‚¨ê¸¸ ìˆ˜ ìˆìŒ. ì—¬ê¸°ì„  ìƒëµí•˜ì—¬ ìˆœìˆ˜ ì¡°íšŒ ìœ ì§€)
            
        # [Precision Sorting] 1. ê³µì¸ ì—¬ë¶€(ìš°ì„ ), 2. ì˜í–¥ë ¥ ì ìˆ˜, 3. ì‹¬ê°ë„ ìˆœ ì •ë ¬
        # reverse=True -> í° ê°’ì´ ì•ìœ¼ë¡œ (1 > 0, 0.8 > 0.3, 5 > 1)
        def get_sort_key(r):
            cert_val = 1 if r.get("is_certified") is True else 0
            impact = float(r.get("impact_score", 0.0))
            sev = int(r.get("severity", 0))
            return (cert_val, impact, sev)

        matching_rules.sort(key=get_sort_key, reverse=True)
        return [r["learned_instruction"] for r in matching_rules]

    def record_rule_outcome(self, rule_id: str, success: bool):
        """íŠ¹ì • ê·œì¹™ì˜ ì„±ê³¼ ê¸°ë¡ ë° ìë™ ì¸ì¦ ì²´í¬"""
        for cat, shard in self.shards.items():
            for rule in shard:
                if rule["id"] == rule_id:
                    rule["usage_count"] = rule.get("usage_count", 0) + 1
                    if success: 
                        rule["success_count"] = rule.get("success_count", 0) + 1
                    else: 
                        rule["failure_count"] = rule.get("failure_count", 0) + 1
                    
                    # [Auto-Certification] ì„±ê³¼ ê¸°ë°˜ ê³µì¸ ì§€í˜œ ìŠ¹ê²© (ì„ê³„ì¹˜: 10íšŒ ì‚¬ìš©, ì„±ê³µë¥  90% ì´ìƒ)
                    usage = rule.get("usage_count", 0)
                    success_count = rule.get("success_count", 0)
                    if usage >= 10 and (success_count / usage) >= 0.9:
                        if not rule.get("is_certified"):
                            rule["is_certified"] = True
                            logger.info(f"ğŸ“ Rule {rule['id']} promoted to CERTIFIED WISDOM.")
                    
                    self._persist_shard(cat)
                    return

    def prune_memory(self, model_id: str = "gemini-2.0-flash"):
        """ìƒ¤ë“œë³„ë¡œ ì˜ë¯¸ë¡ ì  í†µí•© ìˆ˜í–‰í•˜ì—¬ ì¤‘ë³µ ì§€ì‹ ì œê±°"""
        for cat in list(self.shards.keys()):
            shard = self.shards[cat]
            if len(shard) < 2: continue
            
            logger.info(f"âœ¨ Pruning '{cat}' memory shard semantically...")
            rules_text = "\n".join([f"[{i}] {r['learned_instruction']} (Patterns: {r['trigger_patterns']})" for i, r in enumerate(shard)])
            prompt = f"ë‹¹ì‹ ì€ ì§€ì‹ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ '{cat}' ë¶„ì•¼ì˜ ê·œì¹™ë“¤ì„ ë¶„ì„í•˜ì—¬ í•˜ë‚˜ë¡œ í†µí•©í•˜ì‹­ì‹œì˜¤.\n{rules_text}"
            
            try:
                from gortex.core.llm.factory import LLMFactory
                backend = LLMFactory.get_default_backend()
                response = backend.generate(model_id, [{"role": "user", "content": prompt}])
                import re
                # ì •ê·œì‹ ìˆ˜ì •: [.*]
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    new_data = json.loads(json_match.group(0))
                    updated_shard = []
                    for idx, r_data in enumerate(new_data):
                        updated_shard.append({
                            "id": f"RULE_{cat.upper()}_PRUNED_{datetime.now().strftime('%Y%m%d')}_{idx}",
                            "category": cat,
                            "learned_instruction": r_data["instruction"],
                            "trigger_patterns": r_data["trigger_patterns"],
                            "severity": r_data.get("severity", 3),
                            "reinforcement_count": 1,
                            "created_at": datetime.now().isoformat(),
                            "usage_count": 0,
                            "success_count": 0,
                            "failure_count": 0
                        })
                    self.shards[cat] = updated_shard
                    self._persist_shard(cat)
            except:
                pass