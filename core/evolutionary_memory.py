import json
import os
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional

logger = logging.getLogger("GortexEvolutionaryMemory")

class EvolutionaryMemory:
    """
    ì£¼ì œë³„ ìƒ¤ë”©(Sharding) ê¸°ìˆ ì„ ì ìš©í•˜ì—¬ ì§€ëŠ¥ ë°ì´í„°ë¥¼ ë¶„ì‚° ê´€ë¦¬í•˜ëŠ” ë©”ëª¨ë¦¬ í´ë˜ìŠ¤.
    """
    def __init__(self, base_dir: Optional[str] = None, **kwargs):
        # í•˜ìœ„ í˜¸í™˜ì„±: file_pathê°€ kwargsë¡œ ë“¤ì–´ì˜¤ë©´ base_dirë¡œ ì‚¬ìš© (ë””ë ‰í† ë¦¬ë¡œ ì·¨ê¸‰)
        file_path = kwargs.get("file_path")
        self.base_dir = base_dir or (os.path.dirname(file_path) if file_path else "logs/memory") or "logs/memory"
        
        if not self.base_dir or self.base_dir == ".":
             self.base_dir = "logs/memory"

        os.makedirs(self.base_dir, exist_ok=True)
        os.makedirs(os.path.join(self.base_dir, "snapshots"), exist_ok=True)
        self.legacy_path = "experience.json"
        self.shards: Dict[str, List[Dict[str, Any]]] = {}
        self._initialize_shards()

    @property
    def memory(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  ìƒ¤ë“œì˜ ê·œì¹™ì„ ì·¨í•©í•˜ì—¬ ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
        all_rules = []
        for cat in self.shards:
            all_rules.extend(self.shards[cat])
        return all_rules

    def detect_global_conflicts(self) -> List[Dict[str, Any]]:
        """ì „ì²´ ìƒ¤ë“œë¥¼ ìŠ¤ìº”í•˜ì—¬ íŠ¸ë¦¬ê±° ì¤‘ë³µ ë° ì§€ì¹¨ ëª¨ìˆœì„ ê°ì§€í•˜ê³  í† ë¡  ì˜ì œë¥¼ ì„¤ì •í•¨."""
        conflicts = []
        all_rules = []
        for cat, rules in self.shards.items():
            all_rules.extend(rules)
            
        for i, rule_a in enumerate(all_rules):
            patterns_a = set(rule_a["trigger_patterns"])
            for j, rule_b in enumerate(all_rules[i+1:]):
                if rule_a["id"] == rule_b["id"]: continue
                
                patterns_b = set(rule_b["trigger_patterns"])
                intersection = patterns_a.intersection(patterns_b)
                
                # 1. íŠ¸ë¦¬ê±° íŒ¨í„´ ì¤‘ì²© (50% ì´ìƒ) ë˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œ ì¼ì¹˜ ì‹œ ê°ˆë“± í›„ë³´
                if len(intersection) / max(len(patterns_a), len(patterns_b)) >= 0.5:
                    conflicts.append({
                        "type": "semantic_conflict",
                        "agenda": f"Conflict between {rule_a['category']} and {rule_b['category']} rules",
                        "rule_a": rule_a,
                        "rule_b": rule_b,
                        "overlap": list(intersection),
                        "severity": max(rule_a.get("severity", 3), rule_b.get("severity", 3))
                    })
        return conflicts

    def _initialize_shards(self):
        """ê¸°ì¡´ ì§€ì‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ìƒ¤ë“œ ë¡œë“œ"""
        if os.path.exists(self.legacy_path):
            logger.info("ğŸ“¦ Migrating legacy experience.json to shards...")
            try:
                with open(self.legacy_path, 'r', encoding='utf-8') as f:
                    legacy_data = json.load(f)
                for item in legacy_data:
                    category = self._guess_category(item.get("learned_instruction", ""))
                    self.save_rule(
                        instruction=item["learned_instruction"],
                        trigger_patterns=item["trigger_patterns"],
                        category=category,
                        severity=item.get("severity", 3),
                        source_session=item.get("source_session", "legacy_migration")
                    )
                os.rename(self.legacy_path, self.legacy_path + ".migrated.bak")
            except Exception as e:
                logger.error(f"Migration failed: {e}")

        for cat in ["coding", "research", "design", "general"]:
            self.shards[cat] = self._load_shard(cat)

    def _load_shard(self, category: str) -> List[Dict[str, Any]]:
        # Storage Provider Abstraction (Redis or Local/SQLite)
        from gortex.core.mq import mq_bus
        key = f"gortex:memory:shard:{category}"
        try:
            data_str = mq_bus.storage.get(key)
            if data_str:
                logger.debug(f"Loaded '{category}' shard from Storage.")
                return json.loads(data_str)
        except Exception as e:
            logger.warning(f"Failed to load shard from Storage: {e}")
        
        # Legacy File Fallback (Migration support only, prioritized Storage)
        path = os.path.join(self.base_dir, f"{category}_shard.json")
        if os.path.exists(path):
             try:
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
             except: pass
        return []

    def _persist_shard(self, category: str):
        data = self.shards.get(category, [])
        from gortex.core.mq import mq_bus
        key = f"gortex:memory:shard:{category}"
        
        # Logic: Acquire Lock -> Set to Storage -> Publish Event
        lock_name = f"shard_write:{category}"
        if mq_bus.acquire_lock(lock_name):
            try:
                # Save to Unified Storage
                mq_bus.storage.set(key, json.dumps(data, ensure_ascii=False, indent=2))
                mq_bus.publish_event("gortex:memory_updates", "Memory", "shard_updated", {"category": category})
            except Exception as e:
                logger.error(f"Failed to persist {category} shard to Storage: {e}")
            finally:
                mq_bus.release_lock(lock_name)
        else:
            logger.warning(f"Failed to acquire lock for shard '{category}'. Possible concurrent write.")

    def _guess_category(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ìƒ¤ë“œ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        text = text.lower()
        if any(k in text for k in ["code", "python", "import", "class", "def", "syntax"]):
            return "coding"
        elif any(k in text for k in ["search", "trend", "latest", "find", "google"]):
            return "research"
        elif any(k in text for k in ["ui", "dashboard", "layout", "design", "color"]):
            return "design"
        return "general"

    def save_rule(self, instruction: str, trigger_patterns: List[str], category: Optional[str] = None, severity: int = 3, source_session: Optional[str] = None, context: Optional[str] = None, is_super_rule: bool = False) -> str:
        """ìƒˆë¡œìš´ ê·œì¹™ì„ íŠ¹ì • ìƒ¤ë“œì— ì €ì¥ (ID ë°˜í™˜ ë° ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì‹ë³„ì ì‚¬ìš©)"""
        # 0. ì „ì—­ ì¤‘ë³µ ì²´í¬ (ëª¨ë“  ìƒ¤ë“œì—ì„œ ê²€ìƒ‰)
        instruction_clean = instruction.strip()
        for cat_name, shard_list in self.shards.items():
            for existing in shard_list:
                if existing["learned_instruction"].strip() == instruction_clean:
                    existing["trigger_patterns"] = list(set(existing["trigger_patterns"]).union(set(trigger_patterns)))
                    existing["reinforcement_count"] = existing.get("reinforcement_count", 0) + 1
                    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                    if severity > existing.get("severity", 0):
                        existing["severity"] = severity
                    if context:
                        existing["context"] = context
                    if is_super_rule:
                        existing["is_super_rule"] = True
                    self._persist_shard(cat_name)
                    return existing["id"]

        cat = category or self._guess_category(instruction + " " + " ".join(trigger_patterns))
        if cat not in self.shards:
            self.shards[cat] = self._load_shard(cat)
            
        shard = self.shards[cat]
        
        # %f ì¶”ê°€í•˜ì—¬ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì¶©ëŒ ë°©ì§€
        rule_id = f"RULE_{cat.upper()}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        new_rule = {
            "id": rule_id,
            "category": cat,
            "trigger_patterns": trigger_patterns,
            "learned_instruction": instruction,
            "context": context,
            "severity": severity,
            "reinforcement_count": 1,
            "created_at": datetime.now().isoformat(),
            "usage_count": 0,
            "success_count": 0,
            "failure_count": 0,
            "is_certified": False,
            "is_super_rule": is_super_rule
        }
        shard.append(new_rule)
        self._persist_shard(cat)
        logger.info(f"New rule saved to '{cat}' shard: {rule_id}")
        return rule_id

    def get_active_constraints(self, context_text: str) -> List[str]:
        """ë§¥ë½ê³¼ ê´€ë ¨ëœ ìƒ¤ë“œì—ì„œ í™œì„± ì œì•½ ì¡°ê±´ ì¶”ì¶œ (ë””ìŠ¤í¬ ê°•ì œ ë™ê¸°í™” ë° 3ë‹¨ê³„ ì •ë°€ ì •ë ¬)"""
        target_cat = self._guess_category(context_text)
        search_cats = {target_cat, "general"}
        
        matching_rules = []
        for cat in search_cats:
            # ì‹¤ì‹œê°„ ë™ê¸°í™”: í•­ìƒ ë””ìŠ¤í¬ì—ì„œ ìµœì‹  ìƒ¤ë“œë¥¼ ì½ì–´ì˜´
            shard = self._load_shard(cat)
            self.shards[cat] = shard
            
            for rule in shard:
                if any(p.lower() in context_text.lower() for p in rule["trigger_patterns"]):
                    # 1. ìƒíƒœ ë³´ì • (ëˆ„ë½ëœ í•„ë“œ ë³µêµ¬)
                    usage = int(rule.get("usage_count", 0))
                    success = int(rule.get("success_count", 0))
                    is_certified = bool(rule.get("is_certified", False))
                    
                    # 2. ì˜í–¥ë ¥ ì ìˆ˜ ê³„ì‚° (Laplace Smoothing)
                    # usageë¥¼ 1 ì¦ê°€ì‹œí‚¨ ê°€ìƒì˜ ì ìˆ˜ë¡œ ì •ë ¬
                    rule["impact_score"] = float((success + 1) / (usage + 2))
                    rule["is_certified"] = is_certified
                    rule["is_super_rule"] = bool(rule.get("is_super_rule", False))
                    
                    matching_rules.append(rule)
                    # í†µê³„ ê°±ì‹  (ì‹¤ì œ ë°˜ì˜ì€ record_rule_outcomeì—ì„œ í•˜ë˜, 
                    # ì¡°íšŒ íšŸìˆ˜ ì¦ê°€ëŠ” ì¶”ì ìš©ìœ¼ë¡œ ë‚¨ê¸¸ ìˆ˜ ìˆìŒ. ì—¬ê¸°ì„  ìƒëµí•˜ì—¬ ìˆœìˆ˜ ì¡°íšŒ ìœ ì§€)
            
        # [Precision Sorting] 1. ì´ˆì›”ì  ê·œì¹™(Super), 2. ê³µì¸ ì—¬ë¶€(Cert), 3. ì˜í–¥ë ¥ ì ìˆ˜, 4. ì‹¬ê°ë„ ìˆœ ì •ë ¬
        # reverse=True -> í° ê°’ì´ ì•ìœ¼ë¡œ (1 > 0, 0.8 > 0.3, 5 > 1)
        def get_sort_key(r):
            super_val = 1 if r.get("is_super_rule") is True else 0
            cert_val = 1 if r.get("is_certified") is True else 0
            impact = float(r.get("impact_score", 0.0))
            sev = int(r.get("severity", 0))
            return (super_val, cert_val, impact, sev)

        matching_rules.sort(key=get_sort_key, reverse=True)
        return [r["learned_instruction"] for r in matching_rules]

    def record_rule_outcome(self, rule_id: str, success: bool):
        """íŠ¹ì • ê·œì¹™ì˜ ì„±ê³¼ ê¸°ë¡ ë° ìë™ ì¸ì¦ ì²´í¬"""
        for cat, shard in self.shards.items():
            for rule in shard:
                if rule["id"] == rule_id:
                    rule["usage_count"] = rule.get("usage_count", 0) + 1
                    if success: 
                        rule["success_count"] = rule.get("success_count", 0) + 1
                    else: 
                        rule["failure_count"] = rule.get("failure_count", 0) + 1
                    
                    # [Auto-Certification] ì„±ê³¼ ê¸°ë°˜ ê³µì¸ ì§€í˜œ ìŠ¹ê²© (ì„ê³„ì¹˜: 10íšŒ ì‚¬ìš©, ì„±ê³µë¥  90% ì´ìƒ)
                    usage = rule.get("usage_count", 0)
                    success_count = rule.get("success_count", 0)
                    if usage >= 10 and (success_count / usage) >= 0.9:
                        if not rule.get("is_certified"):
                            rule["is_certified"] = True
                            logger.info(f"ğŸ“ Rule {rule['id']} promoted to CERTIFIED WISDOM.")
                    
                    self._persist_shard(cat)
                    return

    def calculate_rule_value(self, rule: Dict[str, Any]) -> float:
        """ê²½í—˜ ê·œì¹™ì˜ ìƒì¡´ ê°€ì¹˜ë¥¼ í‰ê°€í•¨ (0~100)."""
        # 1. ë³´í˜¸ ëŒ€ìƒ: ì´ˆì›”ì  ê·œì¹™, ê³µì¸ ì§€í˜œ ë˜ëŠ” ìƒì„±ëœ ì§€ ì–¼ë§ˆ ì•ˆ ëœ ê·œì¹™
        if rule.get("is_super_rule") or rule.get("is_certified"): return 100.0
        
        created_at = datetime.fromisoformat(rule.get("created_at", datetime.now().isoformat()))
        age_days = (datetime.now() - created_at).days
        if age_days < 7: return 90.0 # ì¼ì£¼ì¼ ë‚´ ìƒì„±ëœ ì§€ì‹ì€ ë³´ì¡´
        
        # 2. ì„±ëŠ¥ ê¸°ë°˜ ì ìˆ˜ (ì„±ê³µë¥ )
        usage = rule.get("usage_count", 0)
        success = rule.get("success_count", 0)
        success_rate = (success / usage) if usage > 0 else 0.5
        
        # 3. ì‚¬ìš© ë¹ˆë„ ì ìˆ˜ (10ì„¸ì…˜ ê¸°ì¤€)
        usage_score = min(1.0, usage / 10.0)
        
        # 4. ìµœì¢… ê°€ì¹˜ ê³„ì‚°: (ì„±ê³µë¥  * 0.7) + (ë¹ˆë„ * 0.3)
        # ë‹¨, ì‚¬ìš©ì´ ì „í˜€ ì—†ëŠ” ë…¸í›„ ì§€ì‹ì€ ê°ì 
        value = (success_rate * 70) + (usage_score * 30)
        if usage == 0 and age_days > 14: value -= 40
        
        return round(max(0.0, min(100.0, value)), 1)

    def prune_memory(self, model_id: str = "gemini-2.0-flash"):
        """ìƒ¤ë“œë³„ë¡œ ì˜ë¯¸ë¡ ì  í†µí•© ìˆ˜í–‰í•˜ì—¬ ì¤‘ë³µ ì§€ì‹ ì œê±°"""
        for cat in list(self.shards.keys()):
            shard = self.shards[cat]
            if len(shard) < 2: continue
            
            logger.info(f"âœ¨ Pruning '{cat}' memory shard semantically...")
            rules_text = "\n".join([f"[{i}] {r['learned_instruction']} (Patterns: {r['trigger_patterns']})" for i, r in enumerate(shard)])
            prompt = f"ë‹¹ì‹ ì€ ì§€ì‹ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ '{cat}' ë¶„ì•¼ì˜ ê·œì¹™ë“¤ì„ ë¶„ì„í•˜ì—¬ í•˜ë‚˜ë¡œ í†µí•©í•˜ì‹­ì‹œì˜¤.\n{rules_text}"
            
            try:
                from gortex.core.llm.factory import LLMFactory
                backend = LLMFactory.get_default_backend()
                response = backend.generate(model_id, [{"role": "user", "content": prompt}])
                import re
                # ì •ê·œì‹ ìˆ˜ì •: [.*]
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    new_data = json.loads(json_match.group(0))
                    updated_shard = []
                    for idx, r_data in enumerate(new_data):
                        updated_shard.append({
                            "id": f"RULE_{cat.upper()}_PRUNED_{datetime.now().strftime('%Y%m%d')}_{idx}",
                            "category": cat,
                            "learned_instruction": r_data["instruction"],
                            "trigger_patterns": r_data["trigger_patterns"],
                            "severity": r_data.get("severity", 3),
                            "reinforcement_count": 1,
                            "created_at": datetime.now().isoformat(),
                            "usage_count": 0,
                            "success_count": 0,
                            "failure_count": 0
                        })
                    self.shards[cat] = updated_shard
                    self._persist_shard(cat)
            except:
                pass