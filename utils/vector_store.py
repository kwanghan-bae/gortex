import json
import os
import logging
import math
import uuid
from datetime import datetime
from typing import List, Dict, Any
from gortex.core.auth import GortexAuth

logger = logging.getLogger("GortexVectorStore")

class LongTermMemory:
    """
    ì„¸ì…˜ì´ ì¢…ë£Œë˜ì–´ë„ ìœ ì§€ë˜ëŠ” ì˜ë¯¸ ê¸°ë°˜ ì§€ì‹ ì €ì¥ì†Œ (ì¥ê¸° ê¸°ì–µ).
    í”„ë¡œì íŠ¸ë³„ ìƒ¤ë”©(Sharding)ì„ í†µí•´ ëŒ€ê·œëª¨ ì§€ì‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    def __init__(self, store_dir: str = "logs/memory"):
        self.store_dir = store_dir
        os.makedirs(self.store_dir, exist_ok=True)
        self.auth = GortexAuth()
        self.shards: Dict[str, List[Dict[str, Any]]] = {} # ë©”ëª¨ë¦¬ ë‚´ ìƒ¤ë“œ ìºì‹œ

    def _get_shard_path(self, namespace: str) -> str:
        # ì•ˆì „í•œ íŒŒì¼ëª…ì„ ìœ„í•´ ì •ê·œí™”
        safe_name = "".join([c if c.isalnum() else "_" for c in namespace])
        return os.path.join(self.store_dir, f"shard_{safe_name}.json")

    def _load_shard(self, namespace: str) -> List[Dict[str, Any]]:
        if namespace in self.shards:
            return self.shards[namespace]
            
        path = self._get_shard_path(namespace)
        if os.path.exists(path):
            try:
                with open(path, "r", encoding='utf-8') as f:
                    data = json.load(f)
                    self.shards[namespace] = data
                    return data
            except:
                return []
        return []

    def _save_shard(self, namespace: str):
        if namespace not in self.shards:
            return
        path = self._get_shard_path(namespace)
        with open(path, "w", encoding='utf-8') as f:
            json.dump(self.shards[namespace], f, ensure_ascii=False, indent=2)

    @property
    def memory(self) -> List[Dict[str, Any]]:
        """AnalystAgent ë“±ì˜ í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ 'global' ìƒ¤ë“œë¥¼ ê¸°ë³¸ ë©”ëª¨ë¦¬ë¡œ ë°˜í™˜"""
        return self._load_shard("global")

    @memory.setter
    def memory(self, value: List[Dict[str, Any]]):
        self.shards["global"] = value

    def _save_store(self):
        """AnalystAgent ë“±ì—ì„œ í˜¸ì¶œí•˜ëŠ” ì €ì¥ ë©”ì„œë“œ (global ìƒ¤ë“œ ì €ì¥)"""
        self._save_shard("global")

    def _get_embedding(self, text: str) -> List[float]:
        """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì ˆì‚­
            clean_text = text[:2000]
            # GortexAuthë¥¼ í†µí•´ í˜„ì¬ í™œì„± í´ë¼ì´ì–¸íŠ¸ íšë“
            client = self.auth.get_current_client()
            response = client.models.embed_content(
                model="models/embedding-001",
                contents=clean_text
            )
            return response.embeddings[0].values
        except Exception as e:
            logger.warning(f"Embedding failed: {e}. Falling back to zero-vector.")
            return [0.0] * 768 # ê¸°ë³¸ ì°¨ì›

    def memorize(self, text: str, metadata: Dict[str, Any] = None, namespace: str = "global"):
        """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤(ìƒ¤ë“œ)ì— ì§€ì‹ì„ ì €ì¥"""
        vector = self._get_embedding(text)
        shard = self._load_shard(namespace)
        
        shard.append({
            "id": str(uuid.uuid4())[:8],
            "content": text,
            "vector": vector,
            "metadata": metadata or {},
            "timestamp": datetime.now().isoformat(),
            "usage_count": 0,
            "links": []
        })
        self.shards[namespace] = shard
        self._save_shard(namespace)
        logger.info(f"ğŸ§  Knowledge memorized in shard: {namespace}")

    def recall(self, query: str, limit: int = 3, namespace: str = "global") -> List[Dict[str, Any]]:
        """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤(ìƒ¤ë“œ)ì—ì„œ ì§€ì‹ ì†Œí™˜"""
        shard = self._load_shard(namespace)
        if not shard:
            return []
            
        query_vector = self._get_embedding(query)
        scored_results = []
        
        for item in shard:
            if "vector" in item and len(item["vector"]) == len(query_vector):
                dot_product = sum(a * b for a, b in zip(query_vector, item["vector"]))
                norm_a = math.sqrt(sum(a * a for a in query_vector))
                norm_b = math.sqrt(sum(b * b for b in item["vector"]))
                similarity = dot_product / (norm_a * norm_b) if norm_a > 0 and norm_b > 0 else 0
                scored_results.append((similarity, item))
            else:
                match_score = 0.1 if any(p in item["content"].lower() for p in query.lower().split()) else 0
                scored_results.append((match_score, item))
        
        scored_results.sort(key=lambda x: x[0], reverse=True)
        
        final_results = []
        for score, item in scored_results[:limit]:
            if score > 0.3:
                if score > 0.5: item["usage_count"] = item.get("usage_count", 0) + 1
                final_results.append({
                    "content": item["content"], 
                    "metadata": item.get("metadata", {}), 
                    "score": round(score, 2)
                })
            
        if final_results:
            self._save_shard(namespace)
        return final_results

if __name__ == "__main__":
    # ë…ë¦½ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    ltm = LongTermMemory()
    ltm.memorize("Gortexì˜ ìƒ¤ë”© ì—”ì§„ì´ í™œì„±í™”ë˜ì—ˆë‹¤.", {"topic": "system"}, namespace="test_project")
    print(ltm.recall("ìƒ¤ë”©", namespace="test_project"))