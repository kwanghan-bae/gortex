import os
import logging
import math
from typing import Dict, Any
from gortex.agents.analyst.base import AnalystAgent as BaseAnalyst
from gortex.utils.tools import archive_project_artifacts

logger = logging.getLogger("GortexAnalystOrganizer")

class WorkspaceOrganizer(BaseAnalyst):
    """ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì‘ì—… ê³µê°„ì„ ì •ë¦¬í•˜ê³  ì•„ì¹´ì´ë¹™í•˜ëŠ” ì „ë¬¸ê°€"""
    
    def organize_workspace(self, project_name: str, version: str):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬ ë° ì•„ì¹´ì´ë¹™ (ë³µêµ¬ ì™„ë£Œ)"""
        targets = []
        for d in ["logs/backups", "logs/versions"]:
            if os.path.exists(d):
                for f in os.listdir(d): targets.append(os.path.join(d, f))
        if targets:
            archive_project_artifacts(project_name, version, targets)

    def garbage_collect_knowledge(self):
        """ì €í’ˆì§ˆ ë˜ëŠ” ì¤‘ë³µ ì§€ì‹ì„ ì •ë¦¬í•˜ì—¬ ìµœì í™” (ë³µêµ¬ ì™„ë£Œ)"""
        original_count = len(self.ltm.memory)
        if original_count < 5: return 0
        
        unique_memory = {}
        for item in self.ltm.memory:
            unique_memory[item["content"]] = item
            
        final_memory = list(unique_memory.values())
        self.ltm.memory = final_memory
        self.ltm._save_store()
        
        removed = original_count - len(final_memory)
        if removed > 0:
            logger.info(f"âœ… Knowledge GC complete: Removed {removed} items.")
        return removed

    def map_knowledge_relations(self):
        """ì§€ì‹ ê°„ì˜ ì˜ë¯¸ë¡ ì  ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì§€ì‹ ì§€ë„ êµ¬ì¶• (ë³µêµ¬ ì™„ë£Œ)"""
        ltm = self.ltm
        if len(ltm.memory) < 2: return 0
            
        connections_made = 0
        for i, item_a in enumerate(ltm.memory):
            if "vector" not in item_a: continue
            if "links" not in item_a: item_a["links"] = []
            
            for j, item_b in enumerate(ltm.memory):
                if i == j or "vector" not in item_b: continue
                
                vec_a, vec_b = item_a["vector"], item_b["vector"]
                dot = sum(a * b for a, b in zip(vec_a, vec_b))
                norm_a = math.sqrt(sum(a * a for a in vec_a))
                norm_b = math.sqrt(sum(b * b for b in vec_b))
                similarity = dot / (norm_a * norm_b) if norm_a > 0 and norm_b > 0 else 0
                
                target_id = item_b.get("id", str(j))
                if similarity >= 0.85 and target_id not in item_a["links"]:
                    item_a["links"].append(target_id)
                    connections_made += 1
                    
        if connections_made > 0:
            ltm._save_store()
        return connections_made

    def curate_session_data(self):
        """ê³ í’ˆì§ˆ ì‚¬ê³  ë°ì´í„° íë ˆì´ì…˜ ë° ì•„ì¹´ì´ë¹™ (ë³µêµ¬ ì™„ë£Œ)"""
        # (ìƒëµí–ˆë˜ ë¡œì§ ë³µêµ¬ - ì¶”í›„ ë°ì´í„°ì…‹ êµ¬ì¶•ìš©)
        logger.info("ğŸ¨ Curating session data for evolution...")
        pass

    def auto_finalize_session(self, state: Dict[str, Any]):
        """ì„¸ì…˜ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ë° ì•„ì¹´ì´ë¹™ ìˆ˜í–‰"""
        logger.info("ğŸ Finalizing Gortex session...")
        try:
            # 1. ë¬¸ì„œ ìë™ ì—…ë°ì´íŠ¸ (docs/sessions/ ë“±)
            # 2. ì‘ì—… ê³µê°„ ì •ë¦¬
            self.organize_workspace("Gortex", "1.0.0")
            # 3. ì§€ì‹ ê´€ê³„ ë§¤í•‘
            self.map_knowledge_relations()
        except Exception as e:
            logger.error(f"Session finalization failed: {e}")
