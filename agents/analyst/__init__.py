import logging
import json
import os
import re
from typing import Dict, Any, List
from datetime import datetime
from gortex.core.state import GortexState
from gortex.utils.translator import i18n
from gortex.core.registry import registry
from gortex.utils.tools import read_file
from .base import AnalystAgent as BaseAnalyst
from .reflection import ReflectionAnalyst
from .organizer import WorkspaceOrganizer

logger = logging.getLogger("GortexAnalyst")

class AnalystAgent(ReflectionAnalyst, WorkspaceOrganizer):
    """ëª¨ë“  ë¶„ì„ ë° ì •ë¦¬ ê¸°ëŠ¥ì´ í†µí•©ëœ ìµœì¢… ì—ì´ì „íŠ¸ í´ë˜ìŠ¤"""
    @property
    def metadata(self):
        return BaseAnalyst().metadata

    def perform_peer_review(self, source_file: str, new_code: str, model_id: str = "gemini-1.5-flash") -> Dict[str, Any]:
        """ë‹¤ë¥¸ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ìƒì„±ëœ ì½”ë“œì˜ í’ˆì§ˆì„ êµì°¨ ë¦¬ë·°í•¨"""
        prompt = f"""ë‹¤ìŒ ë¦¬íŒ©í† ë§ëœ ì½”ë“œë¥¼ ì „ë¬¸ê°€ì˜ ì‹œê°ì—ì„œ ë¦¬ë·°í•˜ë¼.
        
        [Target File] {source_file}
        [New Code]
        {new_code}
        
        ê°€ë…ì„±, ì„±ëŠ¥, ë³´ì•ˆ ìœ„ë°˜ ì—¬ë¶€ë¥¼ ì ê²€í•˜ê³  100ì  ë§Œì ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ë¼.
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ì„ ë”°ë¥´ë¼: {{ "score": int, "comment": "...", "is_approved": bool }}
        """
        try:
            response_text = self.backend.generate(model_id, [{"role": "user", "content": prompt}], {"response_mime_type": "application/json"})
            json_match = re.search(r'{{.*}}', response_text, re.DOTALL)
            return json.loads(json_match.group(0)) if json_match else json.loads(response_text)
        except Exception as e:
            logger.error(f"Peer review failed: {e}")
            return {"score": 50, "comment": "Review failed", "is_approved": True}

# ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡ ë° í˜¸í™˜ì„± ë˜í¼
analyst_instance = AnalystAgent()
registry.register("Analyst", AnalystAgent, analyst_instance.metadata)

def analyst_node(state: GortexState) -> Dict[str, Any]:
    """
    Analyst ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸.
    ì½”ë“œ ê²€ì¦, í•©ì˜ ë„ì¶œ, ë°ì´í„° ë¶„ì„ ë° ì§„í™” ë¡œë“œë§µ ìƒì„±ì„ ì´ê´„í•©ë‹ˆë‹¤.
    """
    agent = analyst_instance
    
    # [MULTIMODAL - Priority 0] ì‹œê° ë¶„ì„ ê²°ê³¼ ëŒ€ê¸° ì¤‘ì¸ ê²½ìš° ìµœìš°ì„  ì²˜ë¦¬
    if state.get("awaiting_visual_diagnosis"):
        logger.info("ğŸ§  Performing multimodal visual analysis...")
        prompt = state.get("handoff_instruction", "Analyze the current UI state.")
        response = agent.backend.generate("gemini-2.0-flash", [{"role": "user", "content": prompt}])
        
        return {
            "messages": [("ai", f"ğŸ‘ï¸ **ì‹œê° ë¶„ì„ ê²°ê³¼**:\n{response}")],
            "next_node": "manager",
            "awaiting_visual_diagnosis": False
        }

    # [Priority 1] ë°ì´í„° ë¶„ì„ ë° ì‹œê°ì  ì´ìŠˆ ê°ì§€
    last_msg_obj = state["messages"][-1]
    last_msg = last_msg_obj[1] if isinstance(last_msg_obj, tuple) else last_msg_obj.content
    
    # ì‹œê°ì  ì´ìŠˆ ê°ì§€
    visual_keywords = ["í™”ë©´", "UI", "ê¹¨ì§", "ì´ìƒí•¨", "screen", "glitch", "looks wrong"]
    if any(k in last_msg.lower() for k in visual_keywords):
        from gortex.utils.multimodal import capture_ui_screenshot
        screenshot_path = capture_ui_screenshot()
        logger.info(f"ğŸ¨ Visual issue detected. Analyzing screenshot: {screenshot_path}")
        
        analysis_msg = f"ì‚¬ìš©ìê°€ ì‹œê°ì  ì´ìƒì„ ë³´ê³ í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ìŠ¤í¬ë¦°ìƒ·ì„ ë¶„ì„í•˜ì—¬ UI ê²°í•¨ì´ë‚˜ ìƒíƒœ ì´ìƒì´ ìˆëŠ”ì§€ ì§„ë‹¨í•˜ë¼. image:{screenshot_path}"
        
        return {
            "messages": [("ai", "ğŸ“¸ **ì‹œê°ì  ì§„ë‹¨ ì‹œì‘**: í˜„ì¬ í™”ë©´ ìƒíƒœë¥¼ ìº¡ì²˜í•˜ì—¬ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.")],
            "next_node": "analyst", 
            "handoff_instruction": analysis_msg,
            "awaiting_visual_diagnosis": True
        }

    data_files = [f for f in last_msg.split() if f.lower().endswith(('.csv', '.xlsx', '.json'))]
    if data_files:
        agent.analyze_data(data_files[0])
        return {"messages": [("ai", f"ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤: {data_files[0]}")], "next_node": "manager"}

    # 1. ì§€ì‹ ë² ì´ìŠ¤ ìµœì í™”
    agent.garbage_collect_knowledge()
    agent.map_knowledge_relations()
    
    # 2. ì•„í‚¤í…ì²˜ ê°ì‚¬
    violations = agent.audit_architecture()
    if violations:
        for v in violations:
            logger.warning(f"ğŸ›¡ï¸ [Architecture Drift] {v['reason']} ({v['source']} -> {v['target']})")
            
    try:
        prediction = agent.predict_architectural_bottleneck()
        if prediction.get("risk_level") == "High":
            state["messages"].append(("system", f"ğŸ”® **Architecture Alert**: ê±´ê°•ë„ í•˜ë½ì´ ì˜ˆìƒë©ë‹ˆë‹¤. (ì˜ˆìƒ ì ìˆ˜: {prediction['projected_score_3_sessions']})"))
    except Exception:
        pass

    # 3. ì§„í™” ë¡œë“œë§µ
    try:
        roadmap = agent.generate_evolution_roadmap()
        if roadmap: 
            state["evolution_roadmap"] = roadmap 
    except Exception:
        pass

    debate_data = state.get("debate_context", [])

    # [Consensus] Swarmìœ¼ë¡œë¶€í„° í† ë¡  ê²°ê³¼ê°€ ë„˜ì–´ì˜¨ ê²½ìš°
    if debate_data and any(s.get("persona") for s in debate_data):
        res = agent.synthesize_consensus("High-Risk System Decision", debate_data)
        msg = f"ğŸ¤ **{i18n.t('analyst.consensus_reached', decision=res.get('final_decision', '')[:50])}**\nğŸ’¡ Rationale: {res.get('rationale', 'N/A')}"
        
        history = state.get("consensus_history", [])
        history.append({"timestamp": datetime.now().isoformat(), "decision": res.get("final_decision")})
        return {
            "messages": [("ai", msg)],
            "next_node": "manager",
            "consensus_history": history,
            "debate_context": []
        }

    # [Cross-Validation / Peer Review]
    if state.get("next_node") == "analyst" or state.get("awaiting_review"):
        ai_outputs = [m for m in state["messages"] if (isinstance(m, tuple) and m[0] == "ai") or (hasattr(m, 'type') and m.type == "ai")]
        if ai_outputs:
            last_ai_msg = ai_outputs[-1][1] if isinstance(ai_outputs[-1], tuple) else ai_outputs[-1].content
            val_res = agent.validate_constraints(state.get("active_constraints", []), {"content": last_ai_msg})
            
            if not val_res.get("is_valid", True):
                return {"messages": [("ai", f"ğŸ›¡ï¸ [Validation Alert] {val_res.get('reason')}")], "next_node": "planner"}
            
            if state.get("awaiting_review"):
                review_res = agent.perform_peer_review(state.get("review_target", "code"), last_ai_msg)
                score = review_res.get("score", 70)
                if not review_res.get("is_approved", True) or score < 70:
                    issue_report = f"[CRITICAL ERROR DETECTED]\nType: Peer Review Rejected\nScore: {score}\nComment: {review_res.get('comment')}\nTarget: {state.get('review_target', 'Unknown')}"
                    return {
                        "messages": [("ai", f"ğŸ§ [Peer Review Rejected] {review_res.get('comment')} (Score: {score})")], 
                        "next_node": "swarm",
                        "current_issue": issue_report,
                        "awaiting_review": False
                    }
                else:
                    state["messages"].append(("system", f"âœ… [Peer Review Approved] {review_res.get('comment')} (Score: {review_res.get('score')})"))

            from gortex.utils.economy import get_economy_manager
            eco_manager = get_economy_manager()
            target_agent = state.get("review_target_agent", "Coder")
            quality = score / 100.0 if 'score' in locals() else 1.0
            difficulty = 3.0 if state.get("is_recovery_mode") else 1.5
            
            eco_manager.record_success(state, target_agent, quality_score=quality, difficulty=difficulty)
            eco_manager.update_skill_points(state, target_agent, category="Coding", quality_score=quality, difficulty=difficulty)
            
            return {
                "messages": [("ai", i18n.t("analyst.review_complete", risk_count=0))],
                "agent_economy": state.get("agent_economy"), 
                "token_credits": state.get("token_credits"), 
                "next_node": "manager", 
                "awaiting_review": False,
                "is_recovery_mode": False
            }

    # [Self-Evolution & Guardian Cycle]
    energy = state.get("agent_energy", 100)
    if energy > 70 and not debate_data:
        # 1. ì§€ì‹ ì¦ë¥˜ ë° ì „ì—­ ìµœì í™” (Neural Distillation)
        if len(agent.memory.memory) > 10: 
            try: 
                from gortex.core.llm.distiller import distiller
                # ë¶„ì•¼ë³„ ê³µì¸ ì§€í˜œ ì¦ë¥˜ (Coding, Analysis ë“±)
                for cat in ["coding", "general"]:
                    wisdom = distiller.distill_wisdom(cat)
                    if wisdom:
                        logger.info(f"âœ¨ Distilled new 'ìµœìƒìœ„ ì›ì¹™' for {cat.capitalize()}.")
                        agent.memory.save_rule(
                            instruction=wisdom,
                            trigger_patterns=[cat, "system", "rule"],
                            category=cat,
                            severity=5,
                            is_super_rule=True,
                            context=f"Neural Distillation from {cat} shard"
                        )
                
                # 2. ìê°€ í•™ìŠµ ë°ì´í„°ì…‹ íë ˆì´ì…˜ ë° í•™ìŠµ íŠ¸ë¦¬ê±°
                if datetime.now().hour % 12 == 0: 
                    dataset_path = distiller.prepare_training_dataset()
                    if dataset_path:
                        with open(dataset_path, 'r') as f:
                            sample_count = sum(1 for _ in f)
                        
                        if sample_count >= 50:
                            logger.info(f"ğŸ§  Dataset reached {sample_count} samples. Triggering autonomous training!")
                            from gortex.core.llm.trainer import trainer
                            job_id = trainer.create_training_job(dataset_path)
                            trainer.start_job(job_id)
                            state["messages"].append(("system", f"ğŸš€ **ìê°€ í•™ìŠµ ê°œì‹œ**: {sample_count}ê°œì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SLM í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. (Job: {job_id})"))
            except Exception as e:
                logger.error(f"Intelligence refinement failed: {e}")

        # 3. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë° ì •ì  ìµœì í™”
        agent.garbage_collect_knowledge()
        agent.synthesize_global_rules()
            
        # 2. [Guardian Cycle] ì„ ì œì  ê²°í•¨ íƒì§€ ë° ë¦¬íŒ©í† ë§ ì œì•ˆ
        if energy > 85:
            logger.info("ğŸ›¡ï¸ Initiating Guardian Cycle: Scanning for proactive refactoring...")
            try:
                guardian_proposals = agent.propose_proactive_refactoring()
                if guardian_proposals:
                    # ê°€ì¥ ë¦¬ìŠ¤í¬ê°€ ë†’ì€ ì œì•ˆ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì§„í–‰
                    top_p = guardian_proposals[0]
                    msg = f"ğŸ›¡ï¸ **ê°€ë””ì–¸ ëª¨ë“œ í™œì„±í™”**: ì ì¬ì  ê²°í•¨ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n**ëŒ€ìƒ**: `{top_p['target_file']}`\n**ì´ìœ **: {top_p['reason']}\n**ê¸°ëŒ€ íš¨ê³¼**: {top_p['expected_gain']}"
                    
                    # Swarmì˜ ë³µêµ¬ ëª¨ë“œì™€ ìœ ì‚¬í•œ íë¦„ìœ¼ë¡œ Managerì—ê²Œ ì „ë‹¬
                    state["debate_result"] = {
                        "final_decision": f"Proactive Refactoring: {top_p['reason']}",
                        "action_plan": top_p["action_plan"]
                    }
                    
                    return {
                        "messages": [("ai", msg)],
                        "next_node": "manager",
                        "debate_result": state["debate_result"],
                        "agent_energy": energy - 15,
                        "is_guardian_mode": True # ì„ ì œì  ìµœì í™” ëª¨ë“œ í‘œì‹œ
                    }
            except Exception as e:
                logger.error(f"Guardian Cycle failed: {e}")

        # 3. ë²„ì „ ê´€ë¦¬ ë° í˜ë¥´ì†Œë‚˜ ì§„í™” (ê¸°ì¡´ ë¡œì§)
        if datetime.now().minute % 30 == 0:
            try:
                agent.generate_release_note()
                new_v = agent.bump_version()
                state["messages"].append(("system", f"ğŸš€ **System Released**: Version {new_v} updated."))
                if datetime.now().hour % 6 == 0: 
                    agent.evolve_personas()
                agent.reinforce_successful_personas()
            except Exception:
                pass

        if len(agent.memory.memory) > 20: 
            try: 
                agent.memory.prune_memory()
            except Exception:
                pass
            
        try:
            proposals = agent.propose_test_generation()
            if proposals:
                updates = {"messages": [], "agent_energy": energy - 10}
                for p in proposals:
                    from gortex.utils.tools import write_file, execute_shell
                    write_file(p["target_file"], p["content"])
                    if "Ready to commit" in execute_shell(f"./scripts/pre_commit.sh --selective {p['target_file']}"):
                        updates["messages"].append(("ai", f"ğŸ§ª **í…ŒìŠ¤íŠ¸ ìê°€ ì¦ì‹**: {p['target_file']} ìƒì„± ì™„ë£Œ"))
                    else:
                        if os.path.exists(p["target_file"]): os.remove(p["target_file"])
                if updates["messages"]:
                    updates["next_node"] = "manager"
                    return updates
        except Exception: 
            pass

    return {"messages": [("ai", "ë¶„ì„ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.")], "next_node": "manager"}
