import logging
import asyncio
import re
from typing import Dict, Any, List
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright
from gortex.core.auth import GortexAuth
from gortex.core.state import GortexState
from gortex.utils.cache import GortexCache
from gortex.utils.vector_store import LongTermMemory

logger = logging.getLogger("GortexResearcher")

class ResearcherAgent:
    """
    Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ìš”ì•½í•˜ëŠ” ì—ì´ì „íŠ¸.
    ì„±ëŠ¥ì„ ìœ„í•´ ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤(ì´ë¯¸ì§€ ë“±)ë¥¼ ì°¨ë‹¨í•˜ê³  ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        self.cache = GortexCache()
        self.ltm = LongTermMemory()
        self.timeout = 8000  # 8 seconds (SPEC)

# ... (ì¤‘ëµ) ...

    async def fetch_api_docs(self, library_name: str) -> str:
        """ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìµœì‹  API ë¬¸ì„œë¥¼ ì •ë°€í•˜ê²Œ ê²€ìƒ‰ ë° ì¶”ì¶œ"""
        query = f"official documentation {library_name} python api reference example"
        logger.info(f"ğŸ” Fetching API documentation for: {library_name}")
        
        # 1. ê²€ìƒ‰ ìˆ˜í–‰
        search_results = await self.search_and_summarize(query)
        
        # 2. LLMì„ í†µí•œ ì •ë°€ í•„í„°ë§ ë° ì‹œê·¸ë‹ˆì²˜ ì¶”ì¶œ
        auth = GortexAuth()
        prompt = f"""ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ '{library_name}'ì˜ 
        í•µì‹¬ í´ë˜ìŠ¤, í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜, ê·¸ë¦¬ê³  ê°„ë‹¨í•œ ì˜ˆì œ ì½”ë“œë¥¼ ì¶”ì¶œí•˜ë¼. 
        ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ë°°ì œí•˜ê³  ê°œë°œìê°€ ì¦‰ì‹œ ì°¸ì¡°í•  ìˆ˜ ìˆëŠ” ê¸°ìˆ  ì •ë³´ ìœ„ì£¼ë¡œ ìš”ì•½í•˜ë¼.
        
        [Search Results]
        {search_results}
        """
        response = auth.generate("gemini-1.5-flash", [("user", prompt)], None)
        
        # 3. [Knowledge Integration] ì‹¤ì‹œê°„ ë¬¸ì„œë¥¼ ì¥ê¸° ê¸°ì–µì— ì„ì‹œ ì €ì¥
        self.ltm.memorize(
            f"Live API Docs ({library_name}): {response.text[:1000]}...",
            {"source": "LiveDocs", "library": library_name, "type": "api_reference"}
        )
        
        return response.text

    async def search_and_summarize(self, query: str) -> str:
        """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›¹ ì¡°ì‚¬ ìˆ˜í–‰"""
        # DuckDuckGo HTML ê²€ìƒ‰ í™œìš©
        search_url = f"https://duckduckgo.com/html/?q={query.replace(' ', '+')}"
        
        # ë¹„ë™ê¸° ì œì–´ê¶Œ ì–‘ë³´
        await asyncio.sleep(0)
        return await self.scrape_url(search_url)


def researcher_node(state: GortexState) -> Dict[str, Any]:
    """Researcher ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    agent = ResearcherAgent()
    auth = GortexAuth()
    
    # ìµœê·¼ API í˜¸ì¶œ ë¹ˆë„ì— ë”°ë¼ ëª¨ë¸ ì„ íƒ
    call_count = state.get("api_call_count", 0)
    gemini_model = "gemini-2.5-flash-lite" if call_count > 10 else "gemini-1.5-flash"
    
    # 1. ì˜ë„ ë° ì¿¼ë¦¬ ì¶”ì¶œ
    last_msg_obj = state["messages"][-1]
    last_msg = last_msg_obj[1] if isinstance(last_msg_obj, tuple) else last_msg_obj.content
    
    prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬:
    1. ë¼ì´ë¸ŒëŸ¬ë¦¬ë‚˜ API ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ë¼. (is_docs_needed: true/false)
    2. ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤ë©´ ìµœì ì˜ ê²€ìƒ‰ì–´(ì˜ì–´ ê¶Œì¥)ë¥¼ ìƒì„±í•˜ë¼. (query: string)
    
    [User Request]
    {last_msg}
    
    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
    {{ "is_docs_needed": true, "query": "..." }}
    """
    
    try:
        response = auth.generate(gemini_model, [("user", prompt)], None)
        import json
        req_info = json.loads(response.text)
        query = req_info.get("query", last_msg)
    except:
        req_info = {"is_docs_needed": False, "query": last_msg}
        query = last_msg

    # 2. ë¹„ë™ê¸° ì‹¤í–‰ (Playwright)
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    if loop.is_running():
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            if req_info.get("is_docs_needed"):
                future = executor.submit(lambda: asyncio.run(agent.fetch_api_docs(query)))
            else:
                future = executor.submit(lambda: asyncio.run(agent.search_and_summarize(query)))
            research_result = future.result()
    else:
        if req_info.get("is_docs_needed"):
            research_result = loop.run_until_complete(agent.fetch_api_docs(query))
        else:
            research_result = loop.run_until_complete(agent.search_and_summarize(query))

    # 3. ê²°ê³¼ ìš”ì•½
    summary_prompt = f"""ë‹¤ìŒì€ '{query}'ì— ëŒ€í•œ ì›¹ ì¡°ì‚¬ ê²°ê³¼ë‹¤. 
    ì‚¬ìš©ìì˜ ì›ë˜ ìš”ì²­({last_msg})ì— ë‹µí•˜ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ì •ë³´ë¥¼ ìš”ì•½í•˜ë¼.
    íŠ¹íˆ API ë¬¸ì„œë¼ë©´ í´ë˜ìŠ¤/í•¨ìˆ˜ëª…ê³¼ ì‚¬ìš©ë²• ì˜ˆì‹œë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ë¼.
    
    [Research Findings]
    {research_result}
    """
    summary_res = auth.generate("gemini-3-flash-preview", [("user", summary_prompt)], None)

    return {
        "messages": [("ai", summary_res.text)],
        "next_node": "manager"
    }