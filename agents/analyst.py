import logging
import json
import pandas as pd
import os
import re
from typing import Dict, Any, List, Optional
from google.genai import types
from gortex.core.auth import GortexAuth
from gortex.core.state import GortexState
from gortex.core.evolutionary_memory import EvolutionaryMemory

logger = logging.getLogger("GortexAnalyst")

class AnalystAgent:
    """
    ë°ì´í„° ë¶„ì„, ìê°€ ì§„í™”, ì½”ë“œ ë¦¬ë·° ë° ìƒí˜¸ ê²€ì¦ì„ ë‹´ë‹¹í•˜ëŠ” ë¶„ì„ ì—ì´ì „íŠ¸.
    """
    def __init__(self):
        self.auth = GortexAuth()
        self.memory = EvolutionaryMemory()

    def analyze_data(self, file_path: str) -> Dict[str, Any]:
        """Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ì½”ë“œ ìƒì„±"""
        try:
            if not os.path.exists(file_path):
                return {"error": f"File not found at {file_path}"}
            ext = os.path.splitext(file_path)[1].lower()
            df = pd.read_csv(file_path) if ext == '.csv' else (pd.read_excel(file_path) if ext in ['.xls', '.xlsx'] else pd.read_json(file_path))
            summary = {"rows": len(df), "columns": list(df.columns), "head": df.head(3).to_dict(), "describe": df.describe().to_dict()}
            prompt = f"ë‹¤ìŒ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ë³´ê³  Plotly JSON ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ë¼: {json.dumps(summary, ensure_ascii=False)}"
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return {"summary": summary, "visualization": json.loads(response.text)}
        except Exception as e:
            return {"error": str(e)}

    def analyze_feedback(self, history: List[Any]) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ìì˜ ë¶€ì •ì  í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì§„í™” ê·œì¹™ ì¶”ì¶œ"""
        prompt = "ì‚¬ìš©ì ë¶ˆë§Œì„ ë¶„ì„í•˜ì—¬ ê°œì„  ê·œì¹™ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ë¼."
        config = types.GenerateContentConfig(system_instruction=prompt, temperature=0.0, response_mime_type="application/json")
        response = self.auth.generate("gemini-1.5-flash", history, config)
        try:
            res_data = json.loads(response.text)
            return res_data if res_data.get("feedback_detected") else None
        except: return None

    def analyze_self_correction(self, log_path: str = "logs/trace.jsonl") -> Optional[Dict[str, Any]]:
        """ë¡œê·¸ì—ì„œ ìê°€ ìˆ˜ì • íŒ¨í„´ ë¶„ì„"""
        if not os.path.exists(log_path): return None
        try:
            with open(log_path, "r") as f:
                log_content = "\n".join(f.readlines()[-100:])
            prompt = "ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ 'ì„±ê³µì ì¸ ë¬¸ì œ í•´ê²° íŒ¨í„´'ì„ JSONìœ¼ë¡œ ìƒì„±í•˜ë¼."
            response = self.auth.generate("gemini-1.5-flash", log_content, {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            return res_data if res_data.get("pattern_detected") else None
        except: return None

    def generate_performance_report(self, log_path: str = "logs/trace.jsonl") -> str:
        """ì„±ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        return "Performance report generated."

    def review_code(self, code: str, file_path: str = "unknown") -> Dict[str, Any]:
        """ì½”ë“œ í’ˆì§ˆ ë¦¬ë·°"""
        prompt = f"ë‹¤ìŒ ì½”ë“œë¥¼ Clean Code ê¸°ì¤€ìœ¼ë¡œ ë¦¬ë·°í•˜ë¼: {code}"
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except: return {"score": 100, "needs_refactoring": False}

    def analyze_coding_style(self, working_dir: str = ".") -> Dict[str, Any]:
        """ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„"""
        return {"instruction": "PEP8 ì¤€ìˆ˜", "trigger_patterns": ["coding"]}

    def cross_validate(self, goal: str, output: str) -> Dict[str, Any]:
        """ìƒí˜¸ ê²€ì¦"""
        prompt = f"ëª©í‘œ: {goal}\nê²°ê³¼: {output}\në¬´ê²°ì„± ê²€ì¦ì„ ìˆ˜í–‰í•˜ë¼."
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except: return {"is_valid": True, "confidence_score": 1.0}

    def explain_logic(self, code: str, symbol_name: str = "selected code") -> str:
        """ë¡œì§ ì„¤ëª…"""
        prompt = f"ì½”ë“œ ì„¤ëª…í•˜ë¼: {code}"
        return self.auth.generate("gemini-1.5-flash", [("user", prompt)], None).text

    def journalize_activity(self, agent: str, event: str, payload: Any) -> str:
        """í™œë™ ì €ë„ë§"""
        return f"{agent}ê°€ {event} ì‘ì—…ì„ ì„±ê³µì ìœ¼ë¡œ ë§ˆì³¤ìŠµë‹ˆë‹¤."

    def profile_resource_usage(self, code: str) -> Dict[str, Any]:
        """ì½”ë“œì˜ ì‹œê°„/ê³µê°„ ë³µì¡ë„ ì •ì  ë¶„ì„"""
        prompt = f"""ë‹¤ìŒ íŒŒì´ì¬ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì˜ˆìƒë˜ëŠ” ìì› íš¨ìœ¨ì„±ì„ ë¦¬í¬íŠ¸í•˜ë¼.
        
        [Code]
        {code}
        
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
        {{
            "time_complexity": "O(n), O(1) ë“±",
            "memory_footprint": "Low/Medium/High",
            "potential_bottlenecks": ["ë³‘ëª© í¬ì¸íŠ¸ 1", "2"],
            "performance_score": 0~100,
            "optimization_required": true/false
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Resource profiling failed: {e}")
            return {"time_complexity": "Unknown", "performance_score": 50, "optimization_required": False}

def analyst_node(state: GortexState) -> Dict[str, Any]:
    """Analyst ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    agent = AnalystAgent()
    last_msg_obj = state["messages"][-1]
    last_msg = last_msg_obj[1] if isinstance(last_msg_obj, tuple) else last_msg_obj.content
    last_msg_lower = last_msg.lower()

    if state.get("next_node") == "analyst":
        ai_outputs = [m for m in state["messages"] if (isinstance(m, tuple) and m[0] == "ai") or (hasattr(m, 'type') and m.type == "ai")]
        if ai_outputs:
            last_ai_msg = ai_outputs[-1][1] if isinstance(ai_outputs[-1], tuple) else ai_outputs[-1].content
            
            # 1. ë¬´ê²°ì„± ê²€ì¦
            val_res = agent.cross_validate("Current Task", last_ai_msg)
            # 2. ìì› í”„ë¡œíŒŒì¼ë§
            perf_res = agent.profile_resource_usage(last_ai_msg)
            
            if not val_res.get("is_valid", True):
                return {"messages": [("ai", f"ğŸ›¡ï¸ [Cross-Validation Alert] {val_res.get('critique')}")], "next_node": "planner"}
            else:
                msg = f"ğŸ›¡ï¸ [Cross-Validation Passed] ë¬´ê²°ì„± ê²€ì¦ í†µê³¼.\n"
                msg += f"âš¡ [Performance Profile] ì˜ˆìƒ ë³µì¡ë„: {perf_res['time_complexity']} (ì ìˆ˜: {perf_res['performance_score']}/100)"
                if perf_res.get("optimization_required"):
                    msg += "\nâš ï¸ ì£¼ì˜: ë¹„íš¨ìœ¨ì ì¸ ë¡œì§ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì í™”ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
                
                economy = state.get("agent_economy", {}).copy()
                if "coder" not in economy: economy["coder"] = {"points": 0, "level": "Novice"}
                economy["coder"]["points"] += 10
                return {"messages": [("ai", msg)], "agent_economy": economy, "next_node": "manager"}

    if "/explain" in last_msg_lower:
        return {"messages": [("ai", "Logic explanation complete.")], "next_node": "manager"}
    if "/analyze_style" in last_msg_lower:
        return {"messages": [("ai", "Style analysis complete.")], "next_node": "manager"}
    if "ë¦¬ë·°" in last_msg_lower or "ê²€í† " in last_msg_lower:
        return {"messages": [("ai", "Code review complete.")], "next_node": "manager"}

    data_files = [f for f in last_msg.split() if f.endswith(('.csv', '.xlsx', '.json'))]
    if data_files:
        result = agent.analyze_data(data_files[0])
        return {"messages": [("ai", f"Data analysis for {data_files[0]} complete.")], "next_node": "manager"}

    return {"messages": [("ai", "ë¶„ì„ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.")], "next_node": "manager"}
