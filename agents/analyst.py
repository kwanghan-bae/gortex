import logging
import json
import pandas as pd
import os
from typing import Dict, Any, List, Optional
from google.genai import types
from gortex.core.auth import GortexAuth
from gortex.core.state import GortexState
from gortex.core.evolutionary_memory import EvolutionaryMemory

logger = logging.getLogger("GortexAnalyst")

class AnalystAgent:
    """
    ë°ì´í„° ë¶„ì„ ë° ìê°€ ì§„í™” í”¼ë“œë°± ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” ì—ì´ì „íŠ¸.
    """
    def __init__(self):
        self.auth = GortexAuth()
        self.memory = EvolutionaryMemory()

    def analyze_data(self, file_path: str) -> str:
        """Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° íŒŒì¼ ë¶„ì„"""
        try:
            if not os.path.exists(file_path):
                return f"Error: File not found at {file_path}"

            ext = os.path.splitext(file_path)[1].lower()
            if ext == '.csv':
                df = pd.read_csv(file_path)
            elif ext in ['.xls', '.xlsx']:
                df = pd.read_excel(file_path)
            elif ext == '.json':
                df = pd.read_json(file_path)
            else:
                return f"Error: Unsupported file format {ext}"

            # ê¸°ì´ˆ í†µê³„ ë° ì •ë³´ ì¶”ì¶œ
            summary = {
                "rows": len(df),
                "columns": list(df.columns),
                "head": df.head(5).to_dict(),
                "describe": df.describe(include='all').to_dict()
            }
            
            return json.dumps(summary, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Data analysis failed: {e}")
            return f"Error analyzing data: {e}"

    def analyze_feedback(self, history: List[Any]) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ìì˜ ë¶€ì •ì  í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì§„í™” ê·œì¹™ ì¶”ì¶œ"""
        # íˆìŠ¤í† ë¦¬ ì¤‘ ë§ˆì§€ë§‰ ëª‡ ê°œì˜ ë©”ì‹œì§€ ë¶„ì„
        prompt = """
        ì‚¬ìš©ìì™€ AIì˜ ìµœê·¼ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œì˜ í–‰ë™ì„ ì˜êµ¬ì ìœ¼ë¡œ ê°œì„ í•  'ì§€ëŠ¥í˜• ê·œì¹™'ì„ ì¶”ì¶œí•˜ë¼.

        [ë¶„ì„ ëŒ€ìƒ í•µì‹¬ ì‹ í˜¸]
        1. ëª…ì‹œì  ê±°ë¶€: "ì•„ë‹ˆ", "í‹€ë ¸ì–´", "ê·¸ê±° ë§ê³ ", "í•˜ì§€ ë§ˆ"
        2. ìˆ˜ì • ìš”êµ¬: "ë‹¤ì‹œ í•´ì¤˜", "ì´ë ‡ê²Œ ë°”ê¿”ì¤˜", "ì™œ ìê¾¸ Xë¥¼ í•´?"
        3. ê°ì •ì  ê°•ì¡°: ëŠë‚Œí‘œ(!), "ì œë°œ", "ëª‡ ë²ˆì„ ë§í•´"
        4. ë°˜ë³µì  ìˆ˜ì •: ì‚¬ìš©ìê°€ ê°™ì€ ë¼ì¸ì„ 2íšŒ ì´ìƒ ì§ì ‘ ìˆ˜ì •í•˜ê±°ë‚˜ ë°˜ë³µ ì§€ì‹œí•¨

        [ê·œì¹™ ìƒì„± ì›ì¹™]
        - ë²”ìš©ì„±: "main.py 10ë²ˆì¤„ ê³ ì³" (X) -> "íŒŒì´ì¬ ì½”ë“œ ì‘ì„± ì‹œ PEP8 ìŠ¤íƒ€ì¼ì„ ì¤€ìˆ˜í•˜ë¼" (O)
        - ëª…í™•ì„±: í–‰ë™ì´ ì¦‰ê°ì ìœ¼ë¡œ ì •ì˜ë˜ì–´ì•¼ í•¨. "í•­ìƒ Xí•˜ë¼" ë˜ëŠ” "ì ˆëŒ€ Yí•˜ì§€ ë§ˆë¼"
        - íŠ¸ë¦¬ê±°: ê·œì¹™ì´ í™œì„±í™”ë˜ì–´ì•¼ í•  ìƒí™©ì„ í‚¤ì›Œë“œë¡œ ì •ì˜ (ì˜ˆ: ì½”ë”©, í•œê¸€, íŒŒì¼ ì‚­ì œ)

        [ì¶”ì¶œ ì‚¬ë¡€ (Few-shot)]
        Example 1:
        User: "ì•„ë‹ˆ ë³€ìˆ˜ëª…ì„ ì™œ ì¹´ë©œì¼€ì´ìŠ¤ë¡œ ì¨? íŒŒì´ì¬ì€ ìŠ¤ë„¤ì´í¬ì¼€ì´ìŠ¤ê°€ ê¸°ë³¸ì´ì•¼."
        Result: {
            "feedback_detected": true,
            "negative_signal_score": 8,
            "instruction": "Python ì½”ë“œ ì‘ì„± ì‹œ ëª¨ë“  ë³€ìˆ˜ëª…ê³¼ í•¨ìˆ˜ëª…ì€ ë°˜ë“œì‹œ snake_caseë¥¼ ì‚¬ìš©í•  ê²ƒ.",
            "context": "Python ì½”ë”© ë° ë¦¬íŒ©í† ë§ ì‹œ",
            "trigger_patterns": ["python", "variable naming", "snake_case"],
            "severity": 4,
            "reason": "ì‚¬ìš©ìê°€ íŒŒì´ì¬ í‘œì¤€ ìŠ¤íƒ€ì¼(PEP8) ì¤€ìˆ˜ë¥¼ ê°•ë ¥íˆ ìš”êµ¬í•¨."
        }

        Example 2:
        User: "ì•ìœ¼ë¡œ ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œë§Œ í•´ì¤˜. ì˜ì–´ ì„ì§€ ë§ê³ ."
        Result: {
            "feedback_detected": true,
            "negative_signal_score": 9,
            "instruction": "ì‚¬ìš©ìì—ê²Œ ì œê³µí•˜ëŠ” ëª¨ë“  ì„¤ëª…ê³¼ ë‹µë³€ì€ ì˜ˆì™¸ ì—†ì´ í•œêµ­ì–´(Korean)ë¡œ ì‘ì„±í•  ê²ƒ.",
            "context": "ì‚¬ìš©ìì™€ì˜ ëª¨ë“  ëŒ€í™” ìƒí™©",
            "trigger_patterns": ["answer language", "korean only"],
            "severity": 5,
            "reason": "ì‚¬ìš©ìê°€ ì–¸ì–´ ì„¤ì •ì„ ìµœìš°ì„ ìˆœìœ„ ì œì•½ ì¡°ê±´ìœ¼ë¡œ ëª…ì‹œí•¨."
        }

        Example 3:
        User: "í…ŒìŠ¤íŠ¸ ì½”ë“œ ì—†ìœ¼ë©´ ë¶ˆì•ˆí•´ì„œ ëª» ì“°ê² ë„¤. í•­ìƒ ë¶™ì—¬ì¤˜."
        Result: {
            "feedback_detected": true,
            "negative_signal_score": 7,
            "instruction": "ì‹ ê·œ ê¸°ëŠ¥ êµ¬í˜„ ë˜ëŠ” ì½”ë“œ ìˆ˜ì • ì‹œ ë°˜ë“œì‹œ í•´ë‹¹ ë¡œì§ì„ ê²€ì¦í•˜ëŠ” ë‹¨ìœ„ í…ŒìŠ¤íŠ¸(pytest)ë¥¼ í¬í•¨í•  ê²ƒ.",
            "context": "ì½”ë“œ êµ¬í˜„ ë° ìˆ˜ì • ì‘ì—… ì‹œ",
            "trigger_patterns": ["coding", "test code", "unit test"],
            "severity": 3,
            "reason": "ì‚¬ìš©ìê°€ ì½”ë“œì˜ ì•ˆì •ì„± í™•ë³´ë¥¼ ìœ„í•´ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±ì„ ì˜ë¬´í™”í•¨."
        }

        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:

        {
            "feedback_detected": true/false,
            "negative_signal_score": 1~10 (ì‹ í˜¸ì˜ ëª…í™•ì„± ë° ê°•ë„),
            "instruction": "AIê°€ ì•ìœ¼ë¡œ ì˜êµ¬ì ìœ¼ë¡œ ì§€ì¼œì•¼ í•  ë²”ìš©ì ì¸ ì§€ì¹¨",
            "context": "ì´ ê·œì¹™ì´ ì ìš©ë˜ì–´ì•¼ í•  êµ¬ì²´ì ì¸ ìƒí™© (ì˜ˆ: Python ì½”ë”© ì¤‘ í•¨ìˆ˜ ì •ì˜ ì‹œ)",
            "trigger_patterns": ["íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ 1", "í‚¤ì›Œë“œ 2"],
            "severity": 1~5,
            "reason": "ì‚¬ìš©ìì˜ ë¶ˆë§Œ ì›ì¸ ë¶„ì„ ê²°ê³¼"
        }
        """



        
        config = types.GenerateContentConfig(
            system_instruction=prompt,
            temperature=0.0,
            response_mime_type="application/json"
        )
        
        response = self.auth.generate("gemini-1.5-flash", history, config)
        try:
            res_data = json.loads(response.text)
            if res_data.get("feedback_detected"):
                return res_data
            return None
        except Exception as e:
            logger.error(f"Feedback analysis parsing failed: {e}")
            return None

    def analyze_self_correction(self, log_path: str = "logs/trace.jsonl") -> Optional[Dict[str, Any]]:
        """ë¡œê·¸ì—ì„œ ì‹¤íŒ¨ í›„ ì„±ê³µí•œ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ìµœì í™” ê·œì¹™ ì¶”ì¶œ"""
        if not os.path.exists(log_path):
            return None

        try:
            with open(log_path, "r") as f:
                lines = f.readlines()
                # ìµœê·¼ 100ì¤„ë§Œ ë¶„ì„ (ì„±ëŠ¥ ë° í† í° ì ˆì•½)
                recent_lines = lines[-100:]
                log_content = "\n".join(recent_lines)

            prompt = """
            ë‹¤ìŒ ë¡œê·¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ì˜¤ë¥˜ë¥¼ ê²ªê³  ìŠ¤ìŠ¤ë¡œ í•´ê²°í•œ 'ì„±ê³µì ì¸ ë¬¸ì œ í•´ê²° íŒ¨í„´'ì„ ì°¾ì•„ë‚´ë¼.
            ì°¾ì•„ë‚¸ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ, ì•ìœ¼ë¡œ ë¹„ìŠ·í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆëŠ” 'ì˜êµ¬ì  ì§€ì¹¨(Constraint)'ì„ ìƒì„±í•˜ë¼.

            [ë¶„ì„ í¬ì¸íŠ¸]
            1. Coderì˜ ì‹œë„: `execute_shell`ì´ non-zero exit codeë¥¼ ë°˜í™˜í–ˆëŠ”ê°€?
            2. Coderì˜ ìˆ˜ì •: ì´í›„ `write_file` ë“±ì„ í†µí•´ ì½”ë“œë¥¼ ìˆ˜ì •í–ˆëŠ”ê°€?
            3. ì„±ê³µ: ì¬ì‹œë„í•œ `execute_shell`ì´ ì„±ê³µ(exit code 0)í–ˆëŠ”ê°€?

            [ê·œì¹™ ìƒì„± ì§€ì¹¨]
            - ì˜¤ë¥˜ì˜ ì›ì¸ì„ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
            - ì˜ˆ: "ë¼ì´ë¸ŒëŸ¬ë¦¬ import ëˆ„ë½ ì‹œ `ImportError`ê°€ ë°œìƒí•˜ë¯€ë¡œ ì‚¬ìš© ì „ ì„¤ì¹˜ ì—¬ë¶€ë¥¼ ë¨¼ì € í™•ì¸í•˜ë¼."
            - severityëŠ” 1~5 ì‚¬ì´ë¡œ ì§€ì •í•˜ë¼.

            ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
            {
                "pattern_detected": true/false,
                "error_cause": "ë°œê²¬ëœ ì˜¤ë¥˜ì˜ ê·¼ë³¸ ì›ì¸",
                "solution": "ì—ì´ì „íŠ¸ê°€ ì ìš©í•œ í•´ê²°ì±…",
                "instruction": "ì•ìœ¼ë¡œ ì§€ì¼œì•¼ í•  ì˜êµ¬ì  ì§€ì¹¨",
                "trigger_patterns": ["ê´€ë ¨ í‚¤ì›Œë“œ 1", "í‚¤ì›Œë“œ 2"],
                "severity": 1~5
            }
            """

            config = types.GenerateContentConfig(
                system_instruction=prompt,
                temperature=0.0,
                response_mime_type="application/json"
            )
            
            response = self.auth.generate("gemini-1.5-flash", log_content, config)
            res_data = json.loads(response.text)
            if res_data.get("pattern_detected"):
                return res_data
            return None
        except Exception as e:
            logger.error(f"Self-correction analysis failed: {e}")
            return None

    def generate_performance_report(self, log_path: str = "logs/trace.jsonl") -> str:
        """ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ ì„¸ì…˜ ì„±ê³¼ ë° í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not os.path.exists(log_path):
            return "ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        try:
            with open(log_path, "r", encoding='utf-8') as f:
                lines = f.readlines()
            
            logs = [json.loads(l) for l in lines]
            total_events = len(logs)
            nodes = [l.get("agent") for l in logs if l.get("agent")]
            node_counts = pd.Series(nodes).value_counts().to_dict()
            
            # ì§€ì—° ì‹œê°„ ë° í† í° ë¶„ì„
            latencies = [l.get("latency_ms") for l in logs if l.get("latency_ms")]
            avg_latency = sum(latencies) / len(latencies) if latencies else 0
            
            total_tokens = 0
            for l in logs:
                tokens = l.get("tokens", {})
                if isinstance(tokens, dict):
                    total_tokens += tokens.get("input", 0) + tokens.get("output", 0)

            # ì„±ê³¼ ìš”ì•½ (LLM)
            recent_goals = [l.get("payload", {}).get("goal") for l in logs if l.get("event") == "node_complete" and l.get("payload", {}).get("goal")]
            
            prompt = f"""ë‹¤ìŒ í†µê³„ì™€ ì‘ì—… ëª©í‘œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ Gortex ì‹œìŠ¤í…œì˜ ì„±ê³¼ ë¦¬í¬íŠ¸ë¥¼ 'ì„ì› ë³´ê³ ìš©(Executive Report)'ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
            
            [Statistics]
            - Total Events: {total_events}
            - Node Usage: {json.dumps(node_counts)}
            - Avg Latency: {avg_latency:.0f}ms
            - Total Tokens Used: {total_tokens}
            
            [Recent Accomplishments]
            {json.dumps(recent_goals[-10:], ensure_ascii=False)}
            
            [Report Guidelines]
            - ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ë¼.
            - ì£¼ìš” ì„±ê³¼ë¥¼ ê°•ì¡°í•˜ê³ , ì‹œìŠ¤í…œ íš¨ìœ¨ì„±(ë¹„ìš©/ì‹œê°„)ì„ í‰ê°€í•˜ë¼.
            - í–¥í›„ ê°œì„  ì œì•ˆ(Next Actions)ì„ í¬í•¨í•˜ë¼.
            """
            
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], None)
            return response.text
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    def review_code(self, code: str, file_path: str = "unknown") -> Dict[str, Any]:
        """ì½”ë“œ í’ˆì§ˆì„ ì •ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì ìˆ˜ì™€ ê°œì„ ì•ˆ ì œê³µ"""
        prompt = f"""ë‹¤ìŒ íŒŒì´ì¬ ì½”ë“œë¥¼ 'Clean Code' ë° 'PEP8' ê¸°ì¤€ìœ¼ë¡œ ì •ë°€ ë¦¬ë·°í•˜ë¼.
        
        [File]
        {file_path}
        
        [Code]
        {code}
        
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
        {{
            "score": 0~100 (ì •ìˆ˜),
            "critique": {{
                "style": "ìŠ¤íƒ€ì¼ ê´€ë ¨ ì§€ì ",
                "complexity": "ë³µì¡ë„ ê´€ë ¨ ì§€ì ",
                "documentation": "ì£¼ì„ ê´€ë ¨ ì§€ì "
            }},
            "refactoring_tips": ["íŒ 1", "íŒ 2"],
            "needs_refactoring": true/false
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], None)
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Code review failed: {e}")
            return {"score": 100, "needs_refactoring": False}

def analyst_node(state: GortexState) -> Dict[str, Any]:
    """Analyst ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    agent = AnalystAgent()
    last_msg_obj = state["messages"][-1]
    last_msg = last_msg_obj[1] if isinstance(last_msg_obj, tuple) else last_msg_obj.content
    last_msg_lower = last_msg.lower()

    # 1. ì˜ë„ íŒë‹¨ (Review vs Data vs Feedback)
    
    # ì½”ë“œ ë¦¬ë·° ìš”ì²­ í™•ì¸
    if "ë¦¬ë·°" in last_msg_lower or "ê²€í† " in last_msg_lower or "review" in last_msg_lower:
        # ì½”ë“œ ì¶”ì¶œ (ë‹¨ìˆœí™”: ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì „ì²´ ë˜ëŠ” ì½”ë“œ ë¸”ë¡)
        code_to_review = last_msg
        review_res = agent.review_code(code_to_review)
        
        msg = f"ğŸ” ì½”ë“œ ë¦¬ë·° ê²°ê³¼ (ì ìˆ˜: {review_res['score']}/100)\n"
        msg += f"- ìŠ¤íƒ€ì¼: {review_res['critique']['style']}\n"
        msg += f"- ë³µì¡ë„: {review_res['critique']['complexity']}\n"
        msg += f"- ê°œì„ íŒ: {', '.join(review_res['refactoring_tips'])}"
        
        updates = {
            "messages": [("ai", msg)],
            "next_node": "planner" if review_res["needs_refactoring"] else "manager"
        }
        return updates

    data_files = [f for f in last_msg.split() if f.endswith(('.csv', '.xlsx', '.json'))]
    
    if data_files:
        # Data Mode
        result = agent.analyze_data(data_files[0])
        return {
            "messages": [("ai", f"ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{result}")],
            "next_node": "manager"
        }
    elif "ë¡œê·¸" in last_msg or "ë¶„ì„" in last_msg or "íŒ¨í„´" in last_msg:
        # Self-Correction Analysis Mode
        correction = agent.analyze_self_correction()
        if correction:
            agent.memory.save_rule(
                instruction=correction["instruction"],
                trigger_patterns=correction["trigger_patterns"],
                severity=correction["severity"],
                context=f"Self-Correction (Cause: {correction['error_cause']})"
            )
            return {
                "messages": [("ai", f"ìê°€ ìˆ˜ì •í•œ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ìƒˆ ê·œì¹™ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤:\n- ì›ì¸: {correction['error_cause']}\n- ì§€ì¹¨: {correction['instruction']}")],
                "next_node": "manager"
            }
        else:
            # Feedback Analysis (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            feedback = agent.analyze_feedback(state["messages"])
            if feedback:
                agent.memory.save_rule(
                    instruction=feedback["instruction"],
                    trigger_patterns=feedback["trigger_patterns"],
                    severity=feedback["severity"],
                    context=feedback.get("context")
                )
                return {
                    "messages": [("ai", f"ìƒˆë¡œìš´ ê·œì¹™ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤: '{feedback['instruction']}'")],
                    "next_node": "manager"
                }
        
    return {
        "messages": [("ai", "ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ ë¶„ì„í–ˆìœ¼ë‚˜ íŠ¹ì´ì‚¬í•­ì„ ë°œê²¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")],
        "next_node": "manager"
    }
