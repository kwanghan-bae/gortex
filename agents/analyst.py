import logging
import json
import pandas as pd
import os
from typing import Dict, Any, List, Optional
from google.genai import types
from gortex.core.auth import GortexAuth
from gortex.core.state import GortexState
from gortex.core.evolutionary_memory import EvolutionaryMemory

logger = logging.getLogger("GortexAnalyst")

class AnalystAgent:
    """
    ë°ì´í„° ë¶„ì„ ë° ìê°€ ì§„í™” í”¼ë“œë°± ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” ì—ì´ì „íŠ¸.
    """
    def __init__(self):
        self.auth = GortexAuth()
        self.memory = EvolutionaryMemory()

    def analyze_data(self, file_path: str) -> Dict[str, Any]:
        """Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° íŒŒì¼ ë¶„ì„ ë° ì‹œê°í™” ì½”ë“œ ìƒì„±"""
        try:
            if not os.path.exists(file_path):
                return {"error": f"File not found at {file_path}"}

            ext = os.path.splitext(file_path)[1].lower()
            df = pd.read_csv(file_path) if ext == '.csv' else (pd.read_excel(file_path) if ext in ['.xls', '.xlsx'] else pd.read_json(file_path))

            summary = {
                "rows": len(df),
                "columns": list(df.columns),
                "head": df.head(3).to_dict(),
                "describe": df.describe().to_dict()
            }

            # ì‹œê°í™” ì œì•ˆ ë° ì½”ë“œ ìƒì„± (LLM)
            prompt = f"""ë‹¤ìŒ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ë³´ê³ , ê°€ì¥ ì í•©í•œ ì‹œê°í™”(Chart) 1ê°œë¥¼ ì œì•ˆí•˜ê³  Plotly JSON ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
            [Data Summary]
            {json.dumps(summary, ensure_ascii=False)}
            
            ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
            {{
                "chart_type": "bar/line/pie/scatter",
                "title": "ì°¨íŠ¸ ì œëª©",
                "plotly_json": {{ "data": [...], "layout": {{ ... }} }}
            }}
            """
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            viz_data = json.loads(response.text)
            
            return {
                "summary": summary,
                "visualization": viz_data
            }
        except Exception as e:
            logger.error(f"Data analysis failed: {e}")
            return {"error": str(e)}

    def analyze_feedback(self, history: List[Any]) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ìì˜ ë¶€ì •ì  í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì§„í™” ê·œì¹™ ì¶”ì¶œ"""
        # íˆìŠ¤í† ë¦¬ ì¤‘ ë§ˆì§€ë§‰ ëª‡ ê°œì˜ ë©”ì‹œì§€ ë¶„ì„
        prompt = """
        ì‚¬ìš©ìì™€ AIì˜ ìµœê·¼ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œì˜ í–‰ë™ì„ ì˜êµ¬ì ìœ¼ë¡œ ê°œì„ í•  'ì§€ëŠ¥í˜• ê·œì¹™'ì„ ì¶”ì¶œí•˜ë¼.

        [ë¶„ì„ ëŒ€ìƒ í•µì‹¬ ì‹ í˜¸]
        1. ëª…ì‹œì  ê±°ë¶€: "ì•„ë‹ˆ", "í‹€ë ¸ì–´", "ê·¸ê±° ë§ê³ ", "í•˜ì§€ ë§ˆ"
        2. ìˆ˜ì • ìš”êµ¬: "ë‹¤ì‹œ í•´ì¤˜", "ì´ë ‡ê²Œ ë°”ê¿”ì¤˜", "ì™œ ìê¾¸ Xë¥¼ í•´?"
        3. ê°ì •ì  ê°•ì¡°: ëŠë‚Œí‘œ(!), "ì œë°œ", "ëª‡ ë²ˆì„ ë§í•´"
        4. ë°˜ë³µì  ìˆ˜ì •: ì‚¬ìš©ìê°€ ê°™ì€ ë¼ì¸ì„ 2íšŒ ì´ìƒ ì§ì ‘ ìˆ˜ì •í•˜ê±°ë‚˜ ë°˜ë³µ ì§€ì‹œí•¨

        [ê·œì¹™ ìƒì„± ì›ì¹™]
        - ë²”ìš©ì„±: "main.py 10ë²ˆì¤„ ê³ ì³" (X) -> "íŒŒì´ì¬ ì½”ë“œ ì‘ì„± ì‹œ PEP8 ìŠ¤íƒ€ì¼ì„ ì¤€ìˆ˜í•˜ë¼" (O)
        - ëª…í™•ì„±: í–‰ë™ì´ ì¦‰ê°ì ìœ¼ë¡œ ì •ì˜ë˜ì–´ì•¼ í•¨. "í•­ìƒ Xí•˜ë¼" ë˜ëŠ” "ì ˆëŒ€ Yí•˜ì§€ ë§ˆë¼"
        - íŠ¸ë¦¬ê±°: ê·œì¹™ì´ í™œì„±í™”ë˜ì–´ì•¼ í•  ìƒí™©ì„ í‚¤ì›Œë“œë¡œ ì •ì˜ (ì˜ˆ: ì½”ë”©, í•œê¸€, íŒŒì¼ ì‚­ì œ)

        [ì¶”ì¶œ ì‚¬ë¡€ (Few-shot)]
        Example 1:
        User: "ì•„ë‹ˆ ë³€ìˆ˜ëª…ì„ ì™œ ì¹´ë©œì¼€ì´ìŠ¤ë¡œ ì¨? íŒŒì´ì¬ì€ ìŠ¤ë„¤ì´í¬ì¼€ì´ìŠ¤ê°€ ê¸°ë³¸ì´ì•¼."
        Result: {
            "feedback_detected": true,
            "negative_signal_score": 8,
            "instruction": "Python ì½”ë“œ ì‘ì„± ì‹œ ëª¨ë“  ë³€ìˆ˜ëª…ê³¼ í•¨ìˆ˜ëª…ì€ ë°˜ë“œì‹œ snake_caseë¥¼ ì‚¬ìš©í•  ê²ƒ.",
            "context": "Python ì½”ë”© ë° ë¦¬íŒ©í† ë§ ì‹œ",
            "trigger_patterns": ["python", "variable naming", "snake_case"],
            "severity": 4,
            "reason": "ì‚¬ìš©ìê°€ íŒŒì´ì¬ í‘œì¤€ ìŠ¤íƒ€ì¼(PEP8) ì¤€ìˆ˜ë¥¼ ê°•ë ¥íˆ ìš”êµ¬í•¨."
        }

        Example 2:
        User: "ì•ìœ¼ë¡œ ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œë§Œ í•´ì¤˜. ì˜ì–´ ì„ì§€ ë§ê³ ."
        Result: {
            "feedback_detected": true,
            "negative_signal_score": 9,
            "instruction": "ì‚¬ìš©ìì—ê²Œ ì œê³µí•˜ëŠ” ëª¨ë“  ì„¤ëª…ê³¼ ë‹µë³€ì€ ì˜ˆì™¸ ì—†ì´ í•œêµ­ì–´(Korean)ë¡œ ì‘ì„±í•  ê²ƒ.",
            "context": "ì‚¬ìš©ìì™€ì˜ ëª¨ë“  ëŒ€í™” ìƒí™©",
            "trigger_patterns": ["answer language", "korean only"],
            "severity": 5,
            "reason": "ì‚¬ìš©ìê°€ ì–¸ì–´ ì„¤ì •ì„ ìµœìš°ì„ ìˆœìœ„ ì œì•½ ì¡°ê±´ìœ¼ë¡œ ëª…ì‹œí•¨."
        }

        Example 3:
        User: "í…ŒìŠ¤íŠ¸ ì½”ë“œ ì—†ìœ¼ë©´ ë¶ˆì•ˆí•´ì„œ ëª» ì“°ê² ë„¤. í•­ìƒ ë¶™ì—¬ì¤˜."
        Result: {
            "feedback_detected": true,
            "negative_signal_score": 7,
            "instruction": "ì‹ ê·œ ê¸°ëŠ¥ êµ¬í˜„ ë˜ëŠ” ì½”ë“œ ìˆ˜ì • ì‹œ ë°˜ë“œì‹œ í•´ë‹¹ ë¡œì§ì„ ê²€ì¦í•˜ëŠ” ë‹¨ìœ„ í…ŒìŠ¤íŠ¸(pytest)ë¥¼ í¬í•¨í•  ê²ƒ.",
            "context": "ì½”ë“œ êµ¬í˜„ ë° ìˆ˜ì • ì‘ì—… ì‹œ",
            "trigger_patterns": ["coding", "test code", "unit test"],
            "severity": 3,
            "reason": "ì‚¬ìš©ìê°€ ì½”ë“œì˜ ì•ˆì •ì„± í™•ë³´ë¥¼ ìœ„í•´ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±ì„ ì˜ë¬´í™”í•¨."
        }

        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:

        {
            "feedback_detected": true/false,
            "negative_signal_score": 1~10 (ì‹ í˜¸ì˜ ëª…í™•ì„± ë° ê°•ë„),
            "instruction": "AIê°€ ì•ìœ¼ë¡œ ì˜êµ¬ì ìœ¼ë¡œ ì§€ì¼œì•¼ í•  ë²”ìš©ì ì¸ ì§€ì¹¨",
            "context": "ì´ ê·œì¹™ì´ ì ìš©ë˜ì–´ì•¼ í•  êµ¬ì²´ì ì¸ ìƒí™© (ì˜ˆ: Python ì½”ë”© ì¤‘ í•¨ìˆ˜ ì •ì˜ ì‹œ)",
            "trigger_patterns": ["íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ 1", "í‚¤ì›Œë“œ 2"],
            "severity": 1~5,
            "reason": "ì‚¬ìš©ìì˜ ë¶ˆë§Œ ì›ì¸ ë¶„ì„ ê²°ê³¼"
        }
        """



        
        config = types.GenerateContentConfig(
            system_instruction=prompt,
            temperature=0.0,
            response_mime_type="application/json"
        )
        
        response = self.auth.generate("gemini-1.5-flash", history, config)
        try:
            res_data = json.loads(response.text)
            if res_data.get("feedback_detected"):
                return res_data
            return None
        except Exception as e:
            logger.error(f"Feedback analysis parsing failed: {e}")
            return None

    def analyze_self_correction(self, log_path: str = "logs/trace.jsonl") -> Optional[Dict[str, Any]]:
        """ë¡œê·¸ì—ì„œ ì‹¤íŒ¨ í›„ ì„±ê³µí•œ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ìµœì í™” ê·œì¹™ ì¶”ì¶œ"""
        if not os.path.exists(log_path):
            return None

        try:
            with open(log_path, "r") as f:
                lines = f.readlines()
                # ìµœê·¼ 100ì¤„ë§Œ ë¶„ì„ (ì„±ëŠ¥ ë° í† í° ì ˆì•½)
                recent_lines = lines[-100:]
                log_content = "\n".join(recent_lines)

            prompt = """
            ë‹¤ìŒ ë¡œê·¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ì˜¤ë¥˜ë¥¼ ê²ªê³  ìŠ¤ìŠ¤ë¡œ í•´ê²°í•œ 'ì„±ê³µì ì¸ ë¬¸ì œ í•´ê²° íŒ¨í„´'ì„ ì°¾ì•„ë‚´ë¼.
            ì°¾ì•„ë‚¸ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ, ì•ìœ¼ë¡œ ë¹„ìŠ·í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆëŠ” 'ì˜êµ¬ì  ì§€ì¹¨(Constraint)'ì„ ìƒì„±í•˜ë¼.

            [ë¶„ì„ í¬ì¸íŠ¸]
            1. Coderì˜ ì‹œë„: `execute_shell`ì´ non-zero exit codeë¥¼ ë°˜í™˜í–ˆëŠ”ê°€?
            2. Coderì˜ ìˆ˜ì •: ì´í›„ `write_file` ë“±ì„ í†µí•´ ì½”ë“œë¥¼ ìˆ˜ì •í–ˆëŠ”ê°€?
            3. ì„±ê³µ: ì¬ì‹œë„í•œ `execute_shell`ì´ ì„±ê³µ(exit code 0)í–ˆëŠ”ê°€?

            [ê·œì¹™ ìƒì„± ì§€ì¹¨]
            - ì˜¤ë¥˜ì˜ ì›ì¸ì„ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
            - ì˜ˆ: "ë¼ì´ë¸ŒëŸ¬ë¦¬ import ëˆ„ë½ ì‹œ `ImportError`ê°€ ë°œìƒí•˜ë¯€ë¡œ ì‚¬ìš© ì „ ì„¤ì¹˜ ì—¬ë¶€ë¥¼ ë¨¼ì € í™•ì¸í•˜ë¼."
            - severityëŠ” 1~5 ì‚¬ì´ë¡œ ì§€ì •í•˜ë¼.

            ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
            {
                "pattern_detected": true/false,
                "error_cause": "ë°œê²¬ëœ ì˜¤ë¥˜ì˜ ê·¼ë³¸ ì›ì¸",
                "solution": "ì—ì´ì „íŠ¸ê°€ ì ìš©í•œ í•´ê²°ì±…",
                "instruction": "ì•ìœ¼ë¡œ ì§€ì¼œì•¼ í•  ì˜êµ¬ì  ì§€ì¹¨",
                "trigger_patterns": ["ê´€ë ¨ í‚¤ì›Œë“œ 1", "í‚¤ì›Œë“œ 2"],
                "severity": 1~5
            }
            """

            config = types.GenerateContentConfig(
                system_instruction=prompt,
                temperature=0.0,
                response_mime_type="application/json"
            )
            
            response = self.auth.generate("gemini-1.5-flash", log_content, config)
            res_data = json.loads(response.text)
            if res_data.get("pattern_detected"):
                return res_data
            return None
        except Exception as e:
            logger.error(f"Self-correction analysis failed: {e}")
            return None

    def generate_performance_report(self, log_path: str = "logs/trace.jsonl") -> str:
        """ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ ì„¸ì…˜ ì„±ê³¼ ë° í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not os.path.exists(log_path):
            return "ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        try:
            with open(log_path, "r", encoding='utf-8') as f:
                lines = f.readlines()
            
            logs = [json.loads(l) for l in lines]
            total_events = len(logs)
            nodes = [l.get("agent") for l in logs if l.get("agent")]
            node_counts = pd.Series(nodes).value_counts().to_dict()
            
            # ì§€ì—° ì‹œê°„ ë° í† í° ë¶„ì„
            latencies = [l.get("latency_ms") for l in logs if l.get("latency_ms")]
            avg_latency = sum(latencies) / len(latencies) if latencies else 0
            
            total_tokens = 0
            for l in logs:
                tokens = l.get("tokens", {})
                if isinstance(tokens, dict):
                    total_tokens += tokens.get("input", 0) + tokens.get("output", 0)

            # ì„±ê³¼ ìš”ì•½ (LLM)
            recent_goals = [l.get("payload", {}).get("goal") for l in logs if l.get("event") == "node_complete" and l.get("payload", {}).get("goal")]
            
            prompt = f"""ë‹¤ìŒ í†µê³„ì™€ ì‘ì—… ëª©í‘œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ Gortex ì‹œìŠ¤í…œì˜ ì„±ê³¼ ë¦¬í¬íŠ¸ë¥¼ 'ì„ì› ë³´ê³ ìš©(Executive Report)'ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
            
            [Statistics]
            - Total Events: {total_events}
            - Node Usage: {json.dumps(node_counts)}
            - Avg Latency: {avg_latency:.0f}ms
            - Total Tokens Used: {total_tokens}
            
            [Recent Accomplishments]
            {json.dumps(recent_goals[-10:], ensure_ascii=False)}
            
            [Report Guidelines]
            - ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ë¼.
            - ì£¼ìš” ì„±ê³¼ë¥¼ ê°•ì¡°í•˜ê³ , ì‹œìŠ¤í…œ íš¨ìœ¨ì„±(ë¹„ìš©/ì‹œê°„)ì„ í‰ê°€í•˜ë¼.
            - í–¥í›„ ê°œì„  ì œì•ˆ(Next Actions)ì„ í¬í•¨í•˜ë¼.
            """
            
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], None)
            return response.text
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    def review_code(self, code: str, file_path: str = "unknown") -> Dict[str, Any]:
        """ì½”ë“œ í’ˆì§ˆì„ ì •ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì ìˆ˜ì™€ ê°œì„ ì•ˆ ì œê³µ"""
        prompt = f"""ë‹¤ìŒ íŒŒì´ì¬ ì½”ë“œë¥¼ 'Clean Code' ë° 'PEP8' ê¸°ì¤€ìœ¼ë¡œ ì •ë°€ ë¦¬ë·°í•˜ë¼.
        
        [File]
        {file_path}
        
        [Code]
        {code}
        
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
        {{
            "score": 0~100 (ì •ìˆ˜),
            "critique": {{
                "style": "ìŠ¤íƒ€ì¼ ê´€ë ¨ ì§€ì ",
                "complexity": "ë³µì¡ë„ ê´€ë ¨ ì§€ì ",
                "documentation": "ì£¼ì„ ê´€ë ¨ ì§€ì "
            }},
            "refactoring_tips": ["íŒ 1", "íŒ 2"],
            "needs_refactoring": true/false
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], None)
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Code review failed: {e}")
            return {"score": 100, "needs_refactoring": False}

    def analyze_coding_style(self, working_dir: str = ".") -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ì¶œ"""
        from gortex.utils.tools import list_files, read_file
        files = list_files(working_dir).split("\n")
        # ë¶„ì„ì„ ìœ„í•œ ìƒ˜í”Œ íŒŒì¼ ì„ íƒ (ìµœëŒ€ 5ê°œ)
        py_files = [f for f in files if f.endswith(".py") and "test" not in f][:5]
        
        sample_codes = ""
        for f in py_files:
            sample_codes += f"\n--- File: {f} ---\n{read_file(os.path.join(working_dir, f))[:2000]}\n"

        prompt = f"""ë‹¤ìŒ ì½”ë“œ ìƒ˜í”Œë“¤ì„ ë¶„ì„í•˜ì—¬ ì´ í”„ë¡œì íŠ¸ë§Œì˜ ê³ ìœ í•œ 'ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œ'ë¥¼ ì‘ì„±í•˜ë¼.
        
        [Sample Codes]
        {sample_codes}
        
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
        {{
            "naming_convention": "ë³€ìˆ˜, í´ë˜ìŠ¤, í•¨ìˆ˜ì˜ ëª…ëª… ê·œì¹™ ë¶„ì„",
            "comment_style": "ì£¼ì„ ì‘ì„± ë°©ì‹ (Docstring í˜•ì‹ ë“±)",
            "architectural_pattern": "ìì£¼ ì‚¬ìš©ë˜ëŠ” êµ¬ì¡°ë‚˜ íŒ¨í„´",
            "instruction": "ì—ì´ì „íŠ¸ê°€ ì½”ë“œë¥¼ ì‘ì„±í•  ë•Œ ë”°ë¼ì•¼ í•  í•œ ë¬¸ì¥ì˜ í•µì‹¬ ìŠ¤íƒ€ì¼ ì§€ì¹¨",
            "trigger_patterns": ["coding", "style", "mimicry"]
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], None)
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Style analysis failed: {e}")
            return {"instruction": "PEP8 í‘œì¤€ ìŠ¤íƒ€ì¼ì„ ì¤€ìˆ˜í•˜ë¼.", "trigger_patterns": ["coding"]}

    def curate_session_data(self, log_path: str = "logs/trace.jsonl") -> List[Dict[str, Any]]:
        """ì„±ê³µì ì¸ ì„¸ì…˜ ë¡œê·¸ë¥¼ í•™ìŠµìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜"""
        if not os.path.exists(log_path):
            return []

        try:
            with open(log_path, "r", encoding='utf-8') as f:
                lines = f.readlines()
            
            logs = [json.loads(l) for l in lines]
            # íë ˆì´ì…˜ ê¸°ì¤€: ì„±ê³µí•œ node_complete ì´ë²¤íŠ¸ê°€ ë§ì€ ì„¸ì…˜
            # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”í•˜ì—¬ ëª¨ë“  ì„±ê³µ ì¼€ì´ìŠ¤ë¥¼ Prompt-Response ìŒìœ¼ë¡œ ë³€í™˜
            dataset = []
            for l in logs:
                if l.get("event") == "node_complete" and l.get("latency_ms", 0) < 30000:
                    payload = l.get("payload", {})
                    if payload.get("goal"):
                        dataset.append({
                            "prompt": f"Task: {payload.get('goal')}\nContext: {l.get('agent')}",
                            "completion": json.dumps(payload, ensure_ascii=False)
                        })
            
            # íŒŒì¼ë¡œ ì €ì¥
            if dataset:
                ds_dir = "logs/datasets"
                os.makedirs(ds_dir, exist_ok=True)
                ds_path = os.path.join(ds_dir, f"dataset_{datetime.now().strftime('%Y%m%d')}.jsonl")
                with open(ds_path, "a", encoding='utf-8') as f:
                    for entry in dataset:
                        f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                logger.info(f"âœ… Curated {len(dataset)} items into dataset.")
            
            return dataset
        except Exception as e:
            logger.error(f"Dataset curation failed: {e}")
            return []

    def cross_validate(self, goal: str, output: str) -> Dict[str, Any]:
        """ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì¶œë ¥ë¬¼ì„ ì œ3ì˜ ê´€ì ì—ì„œ ìƒí˜¸ ê²€ì¦"""
        prompt = f"""ë„ˆëŠ” Gortex v1.0ì˜ ìˆ˜ì„ ê²€ì¦ê´€ì´ë‹¤. 
        ë‹¤ìŒ ì‘ì—… ëª©í‘œì™€ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ë¬´ê²°ì„±ì„ ê²€ì¦í•˜ë¼.
        
        [Goal]
        {goal}
        
        [Resulting Output/Code]
        {output}
        
        [Verification Points]
        1. ëª©í‘œê°€ 100% ë‹¬ì„±ë˜ì—ˆëŠ”ê°€?
        2. ë³´ì•ˆ ì·¨ì•½ì ì´ë‚˜ ë…¼ë¦¬ì  ëª¨ìˆœì´ ìˆëŠ”ê°€?
        3. ê¸°ì¡´ ì‹œìŠ¤í…œ ì œì•½ ì¡°ê±´ì„ ìœ„ë°˜í•˜ì§€ ì•Šì•˜ëŠ”ê°€?
        
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
        {{
            "is_valid": true/false,
            "confidence_score": 0.0~1.0,
            "critique": "ë°œê²¬ëœ ë¬¸ì œì  ë˜ëŠ” ì¹­ì°¬",
            "required_fix": "ìˆ˜ì •ì´ í•„ìš”í•˜ë‹¤ë©´ êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], None)
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Cross-validation failed: {e}")
            return {"is_valid": True, "confidence_score": 1.0}

def analyst_node(state: GortexState) -> Dict[str, Any]:
    """Analyst ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    agent = AnalystAgent()
    last_msg_obj = state["messages"][-1]
    last_msg = last_msg_obj[1] if isinstance(last_msg_obj, tuple) else last_msg_obj.content
    last_msg_lower = last_msg.lower()

    # 1. ì˜ë„ íŒë‹¨ (Validation vs Review vs Style vs Data vs Feedback)
    
    # ìƒí˜¸ ê²€ì¦ ìš”ì²­ (Graphì—ì„œ ì „ì´ëœ ê²½ìš°)
    if state.get("next_node") == "analyst": # ëª…ì‹œì ìœ¼ë¡œ analystë¡œ ì „ì´ë¨
        # ê°€ì¥ ìµœê·¼ì˜ AI ì„±ê³¼ë¬¼ ê²€ì¦
        ai_outputs = [m for m in state["messages"] if (isinstance(m, tuple) and m[0] == "ai") or (hasattr(m, 'type') and m.type == "ai")]
        if ai_outputs:
            last_ai_msg = ai_outputs[-1][1] if isinstance(ai_outputs[-1], tuple) else ai_outputs[-1].content
            val_res = agent.cross_validate("Current Task Plan", last_ai_msg)
            
            if not val_res["is_valid"]:
                msg = f"ğŸ›¡ï¸ [Cross-Validation Alert] ê²°ê³¼ë¬¼ì´ ê¸°ì¤€ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤.\n- ì´ìœ : {val_res['critique']}\n- ì§€ì‹œ: {val_res['required_fix']}"
                return {
                    "messages": [("ai", msg)],
                    "next_node": "planner" # ì¬ìˆ˜ì • ì§€ì‹œ
                }
            else:
                # [ECONOMY] ê²€ì¦ ì„±ê³µ ì‹œ ë³´ìƒ ì§€ê¸‰
                economy = state.get("agent_economy", {}).copy()
                target_agent = "coder" # ì£¼ë¡œ coderì˜ ì„±ê³¼ë¬¼ì„ ê²€ì¦
                if target_agent not in economy:
                    economy[target_agent] = {"points": 0, "level": "Novice"}
                
                economy[target_agent]["points"] += 10 # 10í¬ì¸íŠ¸ ì§€ê¸‰
                if economy[target_agent]["points"] > 50:
                    economy[target_agent]["level"] = "Expert"
                
                return {
                    "messages": [("ai", f"ğŸ›¡ï¸ [Cross-Validation Passed] ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ. {target_agent}ê°€ 10 í¬ì¸íŠ¸ë¥¼ íšë“í–ˆìŠµë‹ˆë‹¤!")],
                    "agent_economy": economy,
                    "next_node": "manager"
                }

    # ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„ ìš”ì²­ (ì´ì „ ë¡œì§ ìœ ì§€)
    if "/analyze_style" in last_msg_lower or "ìŠ¤íƒ€ì¼ ë¶„ì„" in last_msg_lower:
        style_info = agent.analyze_coding_style(state.get("working_dir", "."))
        agent.memory.save_rule(
            instruction=style_info["instruction"],
            trigger_patterns=style_info["trigger_patterns"],
            severity=3,
            context="Personalized Coding Style"
        )
        msg = f"ğŸ¨ í”„ë¡œì íŠ¸ ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„ ì™„ë£Œ!\n"
        msg += f"- ëª…ëª… ê·œì¹™: {style_info.get('naming_convention')}\n"
        msg += f"- ì£¼ì„ ìŠ¤íƒ€ì¼: {style_info.get('comment_style')}\n"
        msg += f"- í•™ìŠµëœ ì§€ì¹¨: '{style_info['instruction']}'ê°€ ì§„í™”ì  ë©”ëª¨ë¦¬ì— ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤."
        return {
            "messages": [("ai", msg)],
            "next_node": "manager"
        }

    # ì½”ë“œ ë¦¬ë·° ìš”ì²­ í™•ì¸
    if "ë¦¬ë·°" in last_msg_lower or "ê²€í† " in last_msg_lower or "review" in last_msg_lower:
        # ì½”ë“œ ì¶”ì¶œ (ë‹¨ìˆœí™”: ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì „ì²´ ë˜ëŠ” ì½”ë“œ ë¸”ë¡)
        code_to_review = last_msg
        review_res = agent.review_code(code_to_review)
        
        msg = f"ğŸ” ì½”ë“œ ë¦¬ë·° ê²°ê³¼ (ì ìˆ˜: {review_res['score']}/100)\n"
        msg += f"- ìŠ¤íƒ€ì¼: {review_res['critique']['style']}\n"
        msg += f"- ë³µì¡ë„: {review_res['critique']['complexity']}\n"
        msg += f"- ê°œì„ íŒ: {', '.join(review_res['refactoring_tips'])}"
        
        updates = {
            "messages": [("ai", msg)],
            "next_node": "planner" if review_res["needs_refactoring"] else "manager"
        }
        return updates

    data_files = [f for f in last_msg.split() if f.endswith(('.csv', '.xlsx', '.json'))]
    
    if data_files:
        # Data Mode
        result = agent.analyze_data(data_files[0])
        if "error" in result:
            return {"messages": [("ai", f"âŒ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {result['error']}")], "next_node": "manager"}
            
        msg = f"ğŸ“Š ë°ì´í„° ë¶„ì„ ê²°ê³¼ ({data_files[0]}):\n"
        msg += f"- í–‰ ìˆ˜: {result['summary']['rows']}, ì»¬ëŸ¼: {', '.join(result['summary']['columns'])}\n"
        msg += f"- ì‹œê°í™” ì œì•ˆ: {result['visualization'].get('title')}"
        
        # ì›¹ ëŒ€ì‹œë³´ë“œë¡œ ì°¨íŠ¸ ë°ì´í„° ë¸Œë¡œë“œìºìŠ¤íŒ… ì‹œë„
        from gortex.ui.web_server import manager as web_manager
        if web_manager:
            try:
                import asyncio
                asyncio.create_task(web_manager.broadcast(json.dumps({
                    "type": "chart_data",
                    "data": result["visualization"]
                }, ensure_ascii=False)))
                msg += "\nğŸ“ˆ ì›¹ ëŒ€ì‹œë³´ë“œì— ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
            except:
                pass

        return {
            "messages": [("ai", msg)],
            "next_node": "manager"
        }
    elif "ë¡œê·¸" in last_msg or "ë¶„ì„" in last_msg or "íŒ¨í„´" in last_msg:
        # Self-Correction Analysis Mode
        correction = agent.analyze_self_correction()
        if correction:
            agent.memory.save_rule(
                instruction=correction["instruction"],
                trigger_patterns=correction["trigger_patterns"],
                severity=correction["severity"],
                context=f"Self-Correction (Cause: {correction['error_cause']})"
            )
            return {
                "messages": [("ai", f"ìê°€ ìˆ˜ì •í•œ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ìƒˆ ê·œì¹™ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤:\n- ì›ì¸: {correction['error_cause']}\n- ì§€ì¹¨: {correction['instruction']}")],
                "next_node": "manager"
            }
        else:
            # Feedback Analysis (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            feedback = agent.analyze_feedback(state["messages"])
            if feedback:
                agent.memory.save_rule(
                    instruction=feedback["instruction"],
                    trigger_patterns=feedback["trigger_patterns"],
                    severity=feedback["severity"],
                    context=feedback.get("context")
                )
                return {
                    "messages": [("ai", f"ìƒˆë¡œìš´ ê·œì¹™ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤: '{feedback['instruction']}'")],
                    "next_node": "manager"
                }
        
    return {
        "messages": [("ai", "ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ ë¶„ì„í–ˆìœ¼ë‚˜ íŠ¹ì´ì‚¬í•­ì„ ë°œê²¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")],
        "next_node": "manager"
    }
