import logging
import json
import pandas as pd
import os
import re
import math
from typing import Dict, Any, List, Optional
from google.genai import types
from gortex.core.auth import GortexAuth
from gortex.core.state import GortexState
from gortex.core.evolutionary_memory import EvolutionaryMemory

logger = logging.getLogger("GortexAnalyst")

class AnalystAgent:
    """
    ë°ì´í„° ë¶„ì„, ìžê°€ ì§„í™”, ì½”ë“œ ë¦¬ë·° ë° ìƒí˜¸ ê²€ì¦ì„ ë‹´ë‹¹í•˜ëŠ” ë¶„ì„ ì—ì´ì „íŠ¸.
    """
    def __init__(self):
        self.auth = GortexAuth()
        self.memory = EvolutionaryMemory()

    def analyze_data(self, file_path: str) -> Dict[str, Any]:
        """Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ì½”ë“œ ìƒì„±"""
        try:
            if not os.path.exists(file_path):
                return {"error": f"File not found at {file_path}"}
            ext = os.path.splitext(file_path)[1].lower()
            df = pd.read_csv(file_path) if ext == '.csv' else (pd.read_excel(file_path) if ext in ['.xls', '.xlsx'] else pd.read_json(file_path))
            summary = {"rows": len(df), "columns": list(df.columns), "head": df.head(3).to_dict(), "describe": df.describe().to_dict()}
            prompt = f"ë‹¤ìŒ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ë³´ê³  Plotly JSON ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ë¼: {json.dumps(summary, ensure_ascii=False)}"
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return {"summary": summary, "visualization": json.loads(response.text)}
        except Exception as e:
            return {"error": str(e)}

    def analyze_feedback(self, history: List[Any]) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ìžì˜ ë¶€ì •ì  í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì§„í™” ê·œì¹™ ì¶”ì¶œ"""
        prompt = "ì‚¬ìš©ìž ë¶ˆë§Œì„ ë¶„ì„í•˜ì—¬ ê°œì„  ê·œì¹™ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ë¼."
        config = types.GenerateContentConfig(system_instruction=prompt, temperature=0.0, response_mime_type="application/json")
        response = self.auth.generate("gemini-1.5-flash", history, config)
        try:
            res_data = json.loads(response.text)
            return res_data if res_data.get("feedback_detected") else None
        except: return None

    def analyze_self_correction(self, log_path: str = "logs/trace.jsonl") -> Optional[Dict[str, Any]]:
        """ë¡œê·¸ì—ì„œ ìžê°€ ìˆ˜ì • íŒ¨í„´ ë¶„ì„"""
        if not os.path.exists(log_path): return None
        try:
            with open(log_path, "r") as f:
                log_content = "\n".join(f.readlines()[-100:])
            prompt = "ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ 'ì„±ê³µì ì¸ ë¬¸ì œ í•´ê²° íŒ¨í„´'ì„ JSONìœ¼ë¡œ ìƒì„±í•˜ë¼."
            response = self.auth.generate("gemini-1.5-flash", log_content, {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            return res_data if res_data.get("pattern_detected") else None
        except: return None

    def generate_performance_report(self, log_path: str = "logs/trace.jsonl") -> str:
        """ì„±ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        return "Performance report generated."

    def review_code(self, code: str, file_path: str = "unknown") -> Dict[str, Any]:
        """ì½”ë“œ í’ˆì§ˆ ë¦¬ë·°"""
        prompt = f"ë‹¤ìŒ ì½”ë“œë¥¼ Clean Code ê¸°ì¤€ìœ¼ë¡œ ë¦¬ë·°í•˜ë¼: {code}"
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except: return {"score": 100, "needs_refactoring": False}

    def analyze_coding_style(self, working_dir: str = ".") -> Dict[str, Any]:
        """ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„"""
        return {"instruction": "PEP8 ì¤€ìˆ˜", "trigger_patterns": ["coding"]}

    def cross_validate(self, goal: str, output: str) -> Dict[str, Any]:
        """ìƒí˜¸ ê²€ì¦"""
        prompt = f"ëª©í‘œ: {goal}\nê²°ê³¼: {output}\në¬´ê²°ì„± ê²€ì¦ì„ ìˆ˜í–‰í•˜ë¼."
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except: return {"is_valid": True, "confidence_score": 1.0}

    def explain_logic(self, code: str, symbol_name: str = "selected code") -> str:
        """ë¡œì§ ì„¤ëª…"""
        prompt = f"ì½”ë“œ ì„¤ëª…í•˜ë¼: {code}"
        return self.auth.generate("gemini-1.5-flash", [("user", prompt)], None).text

    def journalize_activity(self, agent: str, event: str, payload: Any) -> str:
        """í™œë™ ì €ë„ë§"""
        return f"{agent}ê°€ {event} ìž‘ì—…ì„ ì„±ê³µì ìœ¼ë¡œ ë§ˆì³¤ìŠµë‹ˆë‹¤."

    def calculate_efficiency_score(self, success: bool, tokens: int, latency_ms: int, energy_cost: int) -> float:
        """ìž‘ì—… íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚° (0.0 ~ 100.0)"""
        if not success: return 0.0
        
        # ë¹„ìš© í•¨ìˆ˜: í† í° 1ê°œ = 0.01, ë ˆì´í„´ì‹œ 1ms = 0.01, ì—ë„ˆì§€ 1 = 1.0 (ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥)
        cost = (tokens * 0.01) + (latency_ms * 0.01) + (energy_cost * 1.0)
        
        # íš¨ìœ¨ì„± = ê¸°ë³¸ ë³´ìƒ / (ë¹„ìš© + 1)
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ì„ ì ìš©í•˜ì—¬ ë¹„ìš© ì¦ê°€ì— ë”°ë¥¸ ì ìˆ˜ ê°ì†Œí­ì„ ì™„í™”
        base_reward = 500.0
        efficiency = base_reward / (math.log(max(cost, 1.0) + 1) + 1)
        
        return min(100.0, max(0.0, efficiency))

    def profile_resource_usage(self, code: str) -> Dict[str, Any]:
        """ì½”ë“œì˜ ì‹œê°„/ê³µê°„ ë³µìž¡ë„ ì •ì  ë¶„ì„"""
        prompt = f"""ë‹¤ìŒ íŒŒì´ì¬ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì˜ˆìƒë˜ëŠ” ìžì› íš¨ìœ¨ì„±ì„ ë¦¬í¬íŠ¸í•˜ë¼.
        
        [Code]
        {code}
        
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
        {{
            "time_complexity": "O(n), O(1) ë“±",
            "memory_footprint": "Low/Medium/High",
            "potential_bottlenecks": ["ë³‘ëª© í¬ì¸íŠ¸ 1", "2"],
            "performance_score": 0~100,
            "optimization_required": true/false
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Resource profiling failed: {e}")
            return {"time_complexity": "Unknown", "performance_score": 50, "optimization_required": False}

    def scan_project_complexity(self, working_dir: str = ".") -> List[Dict[str, Any]]:
        """í”„ë¡œì íŠ¸ ì „ì²´ì˜ ì½”ë“œ ë³µìž¡ë„(Technical Debt) ìŠ¤ìº”"""
        complexity_scores = []
        ignore_dirs = {'.git', 'venv', '__pycache__', 'logs', 'node_modules', '.idea', '.vscode'}
        
        for root, dirs, files in os.walk(working_dir):
            dirs[:] = [d for d in dirs if d not in ignore_dirs]
            
            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¹´ìš´íŒ…ìœ¼ë¡œ ë³µìž¡ë„ ì¶”ì • (Proxy for Cyclomatic Complexity)
                        # ë¶„ê¸°ë¬¸, ë°˜ë³µë¬¸, ì˜ˆì™¸ì²˜ë¦¬, í•¨ìˆ˜/í´ëž˜ìŠ¤ ì •ì˜ ë“±ì„ í¬ì¸íŠ¸ë¡œ ê³„ì‚°
                        keywords = ['if ', 'elif ', 'for ', 'while ', 'except ', 'with ', 'def ', 'class ', 'return ']
                        score = sum(content.count(k) for k in keywords)
                        
                        # ë¼ì¸ ìˆ˜ ê°€ì¤‘ì¹˜ (ê¸´ íŒŒì¼ì€ ë³µìž¡í•  ê°€ëŠ¥ì„± ë†’ìŒ)
                        lines = len(content.splitlines())
                        score += lines // 10
                        
                        if score > 10: # ì˜ë¯¸ ìžˆëŠ” ë³µìž¡ë„ë§Œ ê¸°ë¡
                            complexity_scores.append({"file": file_path, "score": score})
                    except Exception as e:
                        logger.warning(f"Failed to scan {file_path}: {e}")
                        
        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        complexity_scores.sort(key=lambda x: x["score"], reverse=True)
        return complexity_scores[:10]

    def synthesize_consensus(self, topic: str, scenarios: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ì˜ í† ë¡  ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… í•©ì˜ì•ˆ ë„ì¶œ"""
        logger.info(f"ðŸ¤ Synthesizing consensus for: {topic}")
        
        scenario_data = []
        for s in scenarios:
            scenario_data.append({
                "persona": s.get("persona", "Neutral"),
                "proposal": s.get("task"),
                "report": s.get("report"),
                "confidence": s.get("certainty"),
                "risk": s.get("risk")
            })

        prompt = f"""ë„ˆëŠ” Gortex ì‹œìŠ¤í…œì˜ ìˆ˜ì„ ë¶„ì„ê°€(Analyst)ë‹¤. 
ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ íŽ˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ ì—ì´ì „íŠ¸ë“¤ì´ ì œì•ˆí•œ ì‹œë‚˜ë¦¬ì˜¤ë“¤ì„ ê²€í† í•˜ê³ , ê°€ìž¥ í•©ë¦¬ì ì¸ 'ìµœì¢… í•©ì˜ì•ˆ'ì„ ë„ì¶œí•˜ë¼.

[Topic]
{topic}

[Scenarios]
{json.dumps(scenario_data, ensure_ascii=False, indent=2)}

ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
{{
  "final_decision": "ì„ íƒëœ ê²½ë¡œ ë˜ëŠ” ì ˆì¶©ì•ˆ ìƒì„¸ ì„¤ëª…",
  "rationale": "ì´ ê²°ì •ì„ ë‚´ë¦° í•µì‹¬ ê·¼ê±° (ê° íŽ˜ë¥´ì†Œë‚˜ì˜ ì˜ê²¬ ë°˜ì˜ ì •ë„ í¬í•¨)",
  "tradeoffs": [
    {{ "aspect": "ë¶„ì•¼(ì˜ˆ: ì†ë„, ì•ˆì •ì„± ë“±)", "gain": "ì´ë“", "loss": "í¬ê¸°í•œ ì " }}
  ],
  "residual_risk": "ìµœì¢… ê²°ì • í›„ì—ë„ ë‚¨ì€ ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ",
  "action_plan": ["ìˆ˜í–‰í•´ì•¼ í•  êµ¬ì²´ì  ë‹¨ê³„ 1", "2"]
}}
"""
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Consensus synthesis failed: {e}")
            return {"final_decision": "Error during synthesis.", "rationale": str(e), "action_plan": []}

    def garbage_collect_knowledge(self):
        # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...
        removed = original_count - len(final_memory)
        if removed > 0:
            logger.info(f"âœ… Knowledge GC complete: Removed {removed} items.")
        return removed

    def suggest_refactor_target(self) -> Optional[Dict[str, Any]]:
        """ê¸°ìˆ  ë¶€ì±„ê°€ ê°€ìž¥ ì‹¬ê°í•œ íŒŒì¼ì„ ë¦¬íŒ©í† ë§ ëŒ€ìƒìœ¼ë¡œ ì œì•ˆ"""
        logger.info("ðŸ§ Analyzing technical debt for refactoring target...")
        debt_list = self.scan_project_complexity()
        
        if not debt_list:
            return None
            
        # ìµœìƒìœ„ íƒ€ê²Ÿ ì„ ì •
        target = debt_list[0]
        
        prompt = f"""ë‹¤ìŒ íŒŒì¼ì€ ì½”ë“œ ë³µìž¡ë„ ì ìˆ˜ê°€ {target['score']}ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë‚´ì—ì„œ ê°€ìž¥ ë†’ë‹¤. 
        ì´ íŒŒì¼ì„ ë¦¬íŒ©í† ë§í•˜ì—¬ ë³µìž¡ë„ë¥¼ ë‚®ì¶”ê³  ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì „ëžµì„ ìˆ˜ë¦½í•˜ë¼.
        
        [File Path]
        {target['file']}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "file": "{target['file']}",
            "current_score": {target['score']},
            "issue": "ë³µìž¡ë„ì˜ ì£¼ìš” ì›ì¸ ì„¤ëª…",
            "refactor_strategy": "ê°œì„  ë°©í–¥ ë° ë°©ë²•",
            "priority": "Critical/High"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Failed to suggest refactor target: {e}")
            return None

    def generate_anti_failure_rule(self, error_log: str, attempt_context: str) -> Optional[Dict[str, Any]]:
        """ì˜¤ë¥˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„ í›„ ìž¬ë°œ ë°©ì§€ ê·œì¹™ ìƒì„± ë° ì €ìž¥"""
        logger.info("ðŸ” Generating anti-failure rule based on error...")
        
        prompt = f"""ë‹¤ìŒì€ ì½”ë”© ìž‘ì—… ì¤‘ ë°œìƒí•œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ë¡œê·¸ì™€ ë§¥ë½ì´ë‹¤.
        ì´ ì‹¤ìˆ˜ê°€ ë‹¤ì‹œëŠ” ë°œìƒí•˜ì§€ ì•Šë„ë¡ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ 'ì‹¤íŒ¨ ë°©ì§€ ê·œì¹™'ì„ JSONìœ¼ë¡œ ìƒì„±í•˜ë¼.
        ë‹¨ìˆœí•œ ì˜¤íƒ€ ìˆ˜ì •ì´ ì•„ë‹Œ, ë…¼ë¦¬ì  ì„¤ê³„ë‚˜ ì•„í‚¤í…ì²˜ì  ì£¼ì˜ ì‚¬í•­ ìœ„ì£¼ë¡œ ìž‘ì„±í•˜ë¼.
        
        [Error Log]
        {error_log}
        
        [Context]
        {attempt_context}
        
        ê²°ê³¼ í˜•ì‹:
        {{
            "instruction": "ì—ì´ì „íŠ¸ê°€ ì•žìœ¼ë¡œ ë”°ë¼ì•¼ í•  ì§€ì¹¨",
            "trigger_patterns": ["ì´ ê·œì¹™ì´ í™œì„±í™”ë  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸"],
            "severity": 1~5,
            "reason": "ì™œ ì´ ê·œì¹™ì´ í•„ìš”í•œê°€"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            
            if res_data.get("instruction"):
                self.memory.save_rule(
                    instruction=res_data["instruction"],
                    trigger_patterns=res_data["trigger_patterns"],
                    severity=res_data.get("severity", 3),
                    source_session="reflective_debugging",
                    context=f"Root Cause: {res_data.get('reason')} | Log: {error_log[:200]}"
                )
                logger.info(f"ðŸ›¡ï¸ New anti-failure rule saved: {res_data['instruction'][:50]}...")
                return res_data
        except Exception as e:
            logger.error(f"Failed to generate anti-failure rule: {e}")
            
        return None

    def validate_constraints(self, constraints: List[str], tool_call: Dict[str, Any]) -> Dict[str, Any]:
        """í˜„ìž¬ í™œì„±í™”ëœ ì œì•½ ì¡°ê±´(Constraints) ì¤€ìˆ˜ ì—¬ë¶€ ê²€ì¦"""
        if not constraints:
            return {"is_valid": True}
            
        logger.info(f"ðŸ›¡ï¸ Validating {len(constraints)} constraints against tool call...")
        
        prompt = f"""ë„ˆëŠ” Gortex ì‹œìŠ¤í…œì˜ ì¤€ë²• ê°ì‹œê´€(Compliance Officer)ì´ë‹¤.
        ì—ì´ì „íŠ¸ê°€ ìˆ˜í–‰í•˜ë ¤ëŠ” ìž‘ì—…ì´ ë‹¤ìŒ 'ì‹œìŠ¤í…œ ê·œì¹™'ë“¤ì„ ìœ„ë°˜í•˜ëŠ”ì§€ ë¶„ì„í•˜ë¼.
        
        [System Constraints]
        {json.dumps(constraints, ensure_ascii=False, indent=2)}
        
        [Proposed Tool Call]
        {json.dumps(tool_call, ensure_ascii=False, indent=2)}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "is_valid": true/false,
            "violated_rules": ["ìœ„ë°˜ëœ ê·œì¹™ 1", "2"],
            "reason": "ìœ„ë°˜ ì‚¬ìœ  ì„¤ëª…",
            "remedy": "ê·œì¹™ì„ ì¤€ìˆ˜í•˜ê¸° ìœ„í•œ í•´ê²°ì±… ì œì•ˆ"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Constraint validation failed: {e}")
            return {"is_valid": True} # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ í†µê³¼ (ì•ˆì „ ëª¨ë“œ)

    def learn_from_interaction(self, question: str, user_answer: str) -> Optional[Dict[str, Any]]:
        # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...
        return None

    def auto_finalize_session(self, state: GortexState) -> Dict[str, Any]:
        """ì„¸ì…˜ ì¢…ë£Œ ì‹œ ìžë™ìœ¼ë¡œ í™œë™ ê¸°ë¡ ë° ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ê°±ì‹ """
        logger.info("ðŸ“„ Starting auto-finalization of session...")
        
        # 1. ìµœê·¼ ë¡œê·¸ ë¶„ì„ì„ í†µí•œ ì„±ê³¼ ìš”ì•½ ìš”ì²­
        prompt = f"""ì§€ê¸ˆê¹Œì§€ì˜ ìž‘ì—… ì´ë ¥ê³¼ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë²ˆ ì„¸ì…˜ì˜ ì„±ê³¼ë¥¼ ìš”ì•½í•˜ë¼.
        
        [State Messages]
        {state['messages'][-15:]}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "version": "v2.x.x",
            "goal": "ì´ë²ˆ ì„¸ì…˜ì˜ í•µì‹¬ ëª©í‘œ",
            "done": ["ì™„ë£Œëœ ìž‘ì—… 1", "2"],
            "undone": ["ìˆ˜í–‰í•˜ì§€ ëª»í•œ ìž‘ì—… 1"],
            "decisions": ["ì£¼ìš” ê¸°ìˆ ì  ê²°ì • 1"],
            "next_goal": "ë‹¤ìŒ ì„¸ì…˜ì— ê¶Œìž¥ë˜ëŠ” ëª©í‘œ"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            
            # 2. session_XXXX.md ìž‘ì„±
            sessions_dir = "docs/sessions"
            os.makedirs(sessions_dir, exist_ok=True)
            existing_sessions = [f for f in os.listdir(sessions_dir) if f.startswith("session_")]
            next_num = len(existing_sessions) + 1
            session_file = os.path.join(sessions_dir, f"session_{next_num:04d}.md")
            
            session_content = f"""# Session {next_num:04d}

## Goal
- {res_data.get('goal')}

## What Was Done
{chr(10).join([f'- {d}' for d in res_data.get('done', [])])}

## What Was NOT Done
{chr(10).join([f'- {u}' for u in res_data.get('undone', [])])}

## Decisions
{chr(10).join([f'- {dec}' for d in res_data.get('decisions', [])])}

## Notes for Next Session
- {res_data.get('next_goal')}
"""
            with open(session_file, "w", encoding='utf-8') as f:
                f.write(session_content)

            # 3. release_note.md ì—…ë°ì´íŠ¸
            rel_note_path = "docs/release_note.md"
            if os.path.exists(rel_note_path):
                with open(rel_note_path, "r", encoding='utf-8') as f:
                    content = f.read()
                
                new_entry = f"### {res_data.get('version')} ({res_data.get('goal')})\n"
                new_entry += chr(10).join([f"- [x] {d}" for d in res_data.get('done', [])]) + "\n\n"
                
                # 'Completed' ì„¹ì…˜ ë°”ë¡œ ë’¤ì— ì¶”ê°€
                marker = "## âœ… Completed (Recent Milestones)"
                if marker in content:
                    updated_content = content.replace(marker, f"{marker}\n{new_entry}")
                    with open(rel_note_path, "w", encoding='utf-8') as f:
                        f.write(updated_content)

            # 4. next_session.md ê°±ì‹ 
            next_sess_path = "docs/next_session.md"
            next_sess_content = f"""# Next Session

## Session Goal
- {res_data.get('next_goal')}

## Context
- {res_data.get('goal')} ì™„ë£Œ í›„ ìžë™ ìƒì„±ë¨.

## Scope
### Do
- {res_data.get('next_goal')} ê´€ë ¨ ë¡œì§ êµ¬í˜„

## Expected Outputs
- ê´€ë ¨ ì—ì´ì „íŠ¸ ì½”ë“œ ìˆ˜ì •

## Completion Criteria
- ê¸°ëŠ¥ì„ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê³  í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í•¨
"""
            with open(next_sess_path, "w", encoding='utf-8') as f:
                f.write(next_sess_content)
            
            logger.info(f"âœ… Auto-finalized session: {session_file}")
            return res_data
        except Exception as e:
            logger.error(f"Auto-finalization failed: {e}")
            return {}

def analyst_node(state: GortexState) -> Dict[str, Any]:
    """Analyst ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    agent = AnalystAgent()
    
    # [Knowledge Base Optimization] ì •ê¸°ì ì¸ ì§€ì‹ ì •ë¦¬ ìˆ˜í–‰
    agent.garbage_collect_knowledge()
    
    last_msg_obj = state["messages"][-1]
    last_msg = last_msg_obj[1] if isinstance(last_msg_obj, tuple) else last_msg_obj.content
    last_msg_lower = last_msg.lower()

    # [Consensus Logic] Swarmìœ¼ë¡œë¶€í„° í† ë¡  ê²°ê³¼ê°€ ë„˜ì–´ì˜¨ ê²½ìš°
    debate_data = state.get("debate_context", [])
    if debate_data and any(s.get("persona") for s in debate_data):
        # ì›ë³¸ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë°€ í•©ì˜ ë„ì¶œ
        res = agent.synthesize_consensus("High-Risk System Decision", debate_data)
        
        msg = f"ðŸ¤ **ì—ì´ì „íŠ¸ ê°„ ì •ë°€ í•©ì˜ ë„ì¶œ ì™„ë£Œ**\n\n"
        msg += f"ðŸ“Œ **ìµœì¢… ê²°ì •**: {res.get('final_decision')}\n"
        msg += f"ðŸ’¡ **ê²°ì • ê·¼ê±°**: {res.get('rationale')}\n\n"
        
        msg += "âš–ï¸ **íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„**:\n"
        for t in res.get("tradeoffs", []):
            msg += f"- {t['aspect']}: (+){t['gain']} / (-){t['loss']}\n"
            
        msg += f"\nðŸ›¡ï¸ **ë‚¨ì€ ìœ„í—˜**: {res.get('residual_risk')}\n"
        msg += f"ðŸš€ **ì‹¤í–‰ ê³„íš**: {', '.join(res.get('action_plan', []))}"
            
        history = state.get("consensus_history", [])
        history.append({
            "timestamp": datetime.now().isoformat(),
            "topic": "High-Risk System Decision",
            "decision": res.get("final_decision"),
            "scenarios": debate_data,
            "performance": None # ì‚¬í›„ ì¸¡ì • ì˜ˆì •
        })

        return {
            "messages": [("ai", msg)],
            "next_node": "manager",
            "active_constraints": state.get("active_constraints", []) + [f"Consensus: {res.get('final_decision')[:50]}..."],
            "debate_context": [],
            "consensus_history": history
        }

    # [Consensus Learner] ì´ì „ í•©ì˜ ê²°ê³¼ì˜ ì„±ê³¼ í‰ê°€
    history = state.get("consensus_history", [])
    if history and history[-1]["performance"] is None and state.get("last_efficiency"):
        eff = state["last_efficiency"]
        history[-1]["performance"] = eff
        logger.info(f"ðŸŽ“ Learning from consensus: Efficiency {eff}")
        
        # ì„±ê³¼ê°€ ë§¤ìš° ì¢‹ê±°ë‚˜ ë‚˜ì  ê²½ìš° ì§„í™” ê·œì¹™ìœ¼ë¡œ ë“±ë¡
        if eff >= 90:
            agent.memory.save_rule(
                f"Proven Success: {history[-1]['decision']}",
                ["consensus", "high-risk"],
                severity=5,
                context=f"Achieved {eff} efficiency."
            )
        elif eff < 40:
            agent.memory.save_rule(
                f"Ineffective Strategy (Avoid): {history[-1]['decision']}",
                ["consensus", "avoid"],
                severity=4,
                context=f"Failed with {eff} efficiency."
            )

    if state.get("next_node") == "analyst":
        ai_outputs = [m for m in state["messages"] if (isinstance(m, tuple) and m[0] == "ai") or (hasattr(m, 'type') and m.type == "ai")]
        if ai_outputs:
            last_ai_msg = ai_outputs[-1][1] if isinstance(ai_outputs[-1], tuple) else ai_outputs[-1].content
            
            # 1. ë¬´ê²°ì„± ê²€ì¦
            val_res = agent.cross_validate("Current Task", last_ai_msg)
            # 2. ìžì› í”„ë¡œíŒŒì¼ë§
            perf_res = agent.profile_resource_usage(last_ai_msg)
            
            if not val_res.get("is_valid", True):
                return {"messages": [("ai", f"ðŸ›¡ï¸ [Cross-Validation Alert] {val_res.get('critique')}")], "next_node": "planner"}
            else:
                msg = f"ðŸ›¡ï¸ [Cross-Validation Passed] ë¬´ê²°ì„± ê²€ì¦ í†µê³¼.\n"
                msg += f"âš¡ [Performance Profile] ì˜ˆìƒ ë³µìž¡ë„: {perf_res['time_complexity']} (ì ìˆ˜: {perf_res['performance_score']}/100)"
                if perf_res.get("optimization_required"):
                    msg += "\nâš ï¸ ì£¼ì˜: ë¹„íš¨ìœ¨ì ì¸ ë¡œì§ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì í™”ë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤."
                
                economy = state.get("agent_economy", {}).copy()
                if "coder" not in economy: economy["coder"] = {"points": 0, "level": "Novice"}
                economy["coder"]["points"] += 10
                return {"messages": [("ai", msg)], "agent_economy": economy, "next_node": "manager"}

    if "/explain" in last_msg_lower:
        return {"messages": [("ai", "Logic explanation complete.")], "next_node": "manager"}
    if "/analyze_style" in last_msg_lower:
        return {"messages": [("ai", "Style analysis complete.")], "next_node": "manager"}
    if "ë¦¬ë·°" in last_msg_lower or "ê²€í† " in last_msg_lower:
        return {"messages": [("ai", "Code review complete.")], "next_node": "manager"}

    data_files = [f for f in last_msg.split() if f.endswith(('.csv', '.xlsx', '.json'))]
    if data_files:
        result = agent.analyze_data(data_files[0])
        return {"messages": [("ai", f"Data analysis for {data_files[0]} complete.")], "next_node": "manager"}

    return {"messages": [("ai", "ë¶„ì„ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.")], "next_node": "manager"}
