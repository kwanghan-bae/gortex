import logging
import json
import pandas as pd
import os
import re
import math
from typing import Dict, Any, List, Optional
from google.genai import types
from gortex.core.auth import GortexAuth
from gortex.core.state import GortexState
from gortex.core.evolutionary_memory import EvolutionaryMemory

logger = logging.getLogger("GortexAnalyst")

class AnalystAgent:
    """
    ë°ì´í„° ë¶„ì„, ìê°€ ì§„í™”, ì½”ë“œ ë¦¬ë·° ë° ìƒí˜¸ ê²€ì¦ì„ ë‹´ë‹¹í•˜ëŠ” ë¶„ì„ ì—ì´ì „íŠ¸.
    """
    def __init__(self):
        self.auth = GortexAuth()
        self.memory = EvolutionaryMemory()

    def analyze_data(self, file_path: str) -> Dict[str, Any]:
        """Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ì½”ë“œ ìƒì„±"""
        try:
            if not os.path.exists(file_path):
                return {"error": f"File not found at {file_path}"}
            ext = os.path.splitext(file_path)[1].lower()
            df = pd.read_csv(file_path) if ext == '.csv' else (pd.read_excel(file_path) if ext in ['.xls', '.xlsx'] else pd.read_json(file_path))
            summary = {"rows": len(df), "columns": list(df.columns), "head": df.head(3).to_dict(), "describe": df.describe().to_dict()}
            prompt = f"ë‹¤ìŒ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ë³´ê³  Plotly JSON ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ë¼: {json.dumps(summary, ensure_ascii=False)}"
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return {"summary": summary, "visualization": json.loads(response.text)}
        except Exception as e:
            return {"error": str(e)}

    def analyze_feedback(self, history: List[Any]) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ìì˜ ë¶€ì •ì  í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì§„í™” ê·œì¹™ ì¶”ì¶œ"""
        prompt = "ì‚¬ìš©ì ë¶ˆë§Œì„ ë¶„ì„í•˜ì—¬ ê°œì„  ê·œì¹™ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ë¼."
        config = types.GenerateContentConfig(system_instruction=prompt, temperature=0.0, response_mime_type="application/json")
        response = self.auth.generate("gemini-1.5-flash", history, config)
        try:
            res_data = json.loads(response.text)
            return res_data if res_data.get("feedback_detected") else None
        except: return None

    def analyze_self_correction(self, log_path: str = "logs/trace.jsonl") -> Optional[Dict[str, Any]]:
        """ë¡œê·¸ì—ì„œ ìê°€ ìˆ˜ì • íŒ¨í„´ ë¶„ì„"""
        if not os.path.exists(log_path): return None
        try:
            with open(log_path, "r") as f:
                log_content = "\n".join(f.readlines()[-100:])
            prompt = "ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ 'ì„±ê³µì ì¸ ë¬¸ì œ í•´ê²° íŒ¨í„´'ì„ JSONìœ¼ë¡œ ìƒì„±í•˜ë¼."
            response = self.auth.generate("gemini-1.5-flash", log_content, {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            return res_data if res_data.get("pattern_detected") else None
        except: return None

    def generate_performance_report(self, log_path: str = "logs/trace.jsonl") -> str:
        """ì„±ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        return "Performance report generated."

    def review_code(self, code: str, file_path: str = "unknown") -> Dict[str, Any]:
        """ì½”ë“œ í’ˆì§ˆ ë¦¬ë·°"""
        prompt = f"ë‹¤ìŒ ì½”ë“œë¥¼ Clean Code ê¸°ì¤€ìœ¼ë¡œ ë¦¬ë·°í•˜ë¼: {code}"
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except: return {"score": 100, "needs_refactoring": False}

    def analyze_coding_style(self, working_dir: str = ".") -> Dict[str, Any]:
        """ì½”ë”© ìŠ¤íƒ€ì¼ ë¶„ì„"""
        return {"instruction": "PEP8 ì¤€ìˆ˜", "trigger_patterns": ["coding"]}

    def cross_validate(self, goal: str, output: str) -> Dict[str, Any]:
        """ìƒí˜¸ ê²€ì¦"""
        prompt = f"ëª©í‘œ: {goal}\nê²°ê³¼: {output}\në¬´ê²°ì„± ê²€ì¦ì„ ìˆ˜í–‰í•˜ë¼."
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except: return {"is_valid": True, "confidence_score": 1.0}

    def explain_logic(self, code: str, symbol_name: str = "selected code") -> str:
        """ë¡œì§ ì„¤ëª…"""
        prompt = f"ì½”ë“œ ì„¤ëª…í•˜ë¼: {code}"
        return self.auth.generate("gemini-1.5-flash", [("user", prompt)], None).text

    def journalize_activity(self, agent: str, event: str, payload: Any) -> str:
        """í™œë™ ì €ë„ë§"""
        return f"{agent}ê°€ {event} ì‘ì—…ì„ ì„±ê³µì ìœ¼ë¡œ ë§ˆì³¤ìŠµë‹ˆë‹¤."

    def calculate_efficiency_score(self, success: bool, tokens: int, latency_ms: int, energy_cost: int) -> float:
        """ì‘ì—… íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚° (0.0 ~ 100.0)"""
        if not success: return 0.0
        
        # ë¹„ìš© í•¨ìˆ˜: í† í° 1ê°œ = 0.01, ë ˆì´í„´ì‹œ 1ms = 0.01, ì—ë„ˆì§€ 1 = 1.0 (ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥)
        cost = (tokens * 0.01) + (latency_ms * 0.01) + (energy_cost * 1.0)
        
        # íš¨ìœ¨ì„± = ê¸°ë³¸ ë³´ìƒ / (ë¹„ìš© + 1)
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ì„ ì ìš©í•˜ì—¬ ë¹„ìš© ì¦ê°€ì— ë”°ë¥¸ ì ìˆ˜ ê°ì†Œí­ì„ ì™„í™”
        base_reward = 500.0
        efficiency = base_reward / (math.log(max(cost, 1.0) + 1) + 1)
        
        return min(100.0, max(0.0, efficiency))

    def profile_resource_usage(self, code: str) -> Dict[str, Any]:
        """ì½”ë“œì˜ ì‹œê°„/ê³µê°„ ë³µì¡ë„ ì •ì  ë¶„ì„"""
        prompt = f"""ë‹¤ìŒ íŒŒì´ì¬ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì˜ˆìƒë˜ëŠ” ìì› íš¨ìœ¨ì„±ì„ ë¦¬í¬íŠ¸í•˜ë¼.
        
        [Code]
        {code}
        
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
        {{
            "time_complexity": "O(n), O(1) ë“±",
            "memory_footprint": "Low/Medium/High",
            "potential_bottlenecks": ["ë³‘ëª© í¬ì¸íŠ¸ 1", "2"],
            "performance_score": 0~100,
            "optimization_required": true/false
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Resource profiling failed: {e}")
            return {"time_complexity": "Unknown", "performance_score": 50, "optimization_required": False}

    def scan_project_complexity(self, working_dir: str = ".") -> List[Dict[str, Any]]:
        """í”„ë¡œì íŠ¸ ì „ì²´ì˜ ì½”ë“œ ë³µì¡ë„(Technical Debt) ìŠ¤ìº”"""
        complexity_scores = []
        ignore_dirs = {'.git', 'venv', '__pycache__', 'logs', 'node_modules', '.idea', '.vscode'}
        
        for root, dirs, files in os.walk(working_dir):
            dirs[:] = [d for d in dirs if d not in ignore_dirs]
            
            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¹´ìš´íŒ…ìœ¼ë¡œ ë³µì¡ë„ ì¶”ì • (Proxy for Cyclomatic Complexity)
                        # ë¶„ê¸°ë¬¸, ë°˜ë³µë¬¸, ì˜ˆì™¸ì²˜ë¦¬, í•¨ìˆ˜/í´ë˜ìŠ¤ ì •ì˜ ë“±ì„ í¬ì¸íŠ¸ë¡œ ê³„ì‚°
                        keywords = ['if ', 'elif ', 'for ', 'while ', 'except ', 'with ', 'def ', 'class ', 'return ']
                        score = sum(content.count(k) for k in keywords)
                        
                        # ë¼ì¸ ìˆ˜ ê°€ì¤‘ì¹˜ (ê¸´ íŒŒì¼ì€ ë³µì¡í•  ê°€ëŠ¥ì„± ë†’ìŒ)
                        lines = len(content.splitlines())
                        score += lines // 10
                        
                        if score > 10: # ì˜ë¯¸ ìˆëŠ” ë³µì¡ë„ë§Œ ê¸°ë¡
                            complexity_scores.append({"file": file_path, "score": score})
                    except Exception as e:
                        logger.warning(f"Failed to scan {file_path}: {e}")
                        
        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        complexity_scores.sort(key=lambda x: x["score"], reverse=True)
        return complexity_scores[:10]

    def synthesize_consensus(self, topic: str, scenarios: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ì˜ í† ë¡  ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… í•©ì˜ì•ˆ ë„ì¶œ"""
        logger.info(f"ğŸ¤ Synthesizing consensus for: {topic}")
        
        scenario_data = []
        for s in scenarios:
            scenario_data.append({
                "persona": s.get("persona", "Neutral"),
                "proposal": s.get("task"),
                "report": s.get("report"),
                "confidence": s.get("certainty"),
                "risk": s.get("risk")
            })

        prompt = f"""ë„ˆëŠ” Gortex ì‹œìŠ¤í…œì˜ ìˆ˜ì„ ë¶„ì„ê°€(Analyst)ë‹¤. 
ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ ì—ì´ì „íŠ¸ë“¤ì´ ì œì•ˆí•œ ì‹œë‚˜ë¦¬ì˜¤ë“¤ì„ ê²€í† í•˜ê³ , ê°€ì¥ í•©ë¦¬ì ì¸ 'ìµœì¢… í•©ì˜ì•ˆ'ì„ ë„ì¶œí•˜ë¼.

[Topic]
{topic}

[Scenarios]
{json.dumps(scenario_data, ensure_ascii=False, indent=2)}

ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
{{
  "final_decision": "ì„ íƒëœ ê²½ë¡œ ë˜ëŠ” ì ˆì¶©ì•ˆ ìƒì„¸ ì„¤ëª…",
  "rationale": "ì´ ê²°ì •ì„ ë‚´ë¦° í•µì‹¬ ê·¼ê±° (ê° í˜ë¥´ì†Œë‚˜ì˜ ì˜ê²¬ ë°˜ì˜ ì •ë„ í¬í•¨)",
  "tradeoffs": [
    {{ "aspect": "ë¶„ì•¼(ì˜ˆ: ì†ë„, ì•ˆì •ì„± ë“±)", "gain": "ì´ë“", "loss": "í¬ê¸°í•œ ì " }}
  ],
  "residual_risk": "ìµœì¢… ê²°ì • í›„ì—ë„ ë‚¨ì€ ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ",
  "action_plan": ["ìˆ˜í–‰í•´ì•¼ í•  êµ¬ì²´ì  ë‹¨ê³„ 1", "2"]
}}
"""
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Consensus synthesis failed: {e}")
            return {"final_decision": "Error during synthesis.", "rationale": str(e), "action_plan": []}

    def garbage_collect_knowledge(self):
        """ì €í’ˆì§ˆ ë˜ëŠ” ì¤‘ë³µ ì§€ì‹ì„ ì •ë¦¬í•˜ì—¬ ìµœì í™”"""
        original_count = len(self.memory.ltm.memory)
        if original_count < 10: return 0
        
        # 1. ì¤‘ë³µ ì œê±° (ë‚´ìš© ê¸°ë°˜)
        unique_memory = {}
        for item in self.memory.ltm.memory:
            unique_memory[item["content"]] = item
            
        # 2. ì‚¬ìš©ëŸ‰/ì‹ ì„ ë„ ê¸°ë°˜ í•„í„°ë§ (ë‹¨ìˆœí™”: usage_countê°€ 0ì´ê³  ë„ˆë¬´ ì˜¤ë˜ëœ ê²ƒ ë“±)
        final_memory = list(unique_memory.values())
        self.memory.ltm.memory = final_memory
        self.memory.ltm._save_store()
        
        removed = original_count - len(final_memory)
        if removed > 0:
            logger.info(f"âœ… Knowledge GC complete: Removed {removed} items.")
        return removed

    def suggest_refactor_target(self) -> Optional[Dict[str, Any]]:
        """ê¸°ìˆ  ë¶€ì±„ê°€ ê°€ì¥ ì‹¬ê°í•œ íŒŒì¼ì„ ë¦¬íŒ©í† ë§ ëŒ€ìƒìœ¼ë¡œ ì œì•ˆ"""
        logger.info("ğŸ§ Analyzing technical debt for refactoring target...")
        debt_list = self.scan_project_complexity()
        
        if not debt_list:
            return None
            
        # ìµœìƒìœ„ íƒ€ê²Ÿ ì„ ì •
        target = debt_list[0]
        
        prompt = f"""ë‹¤ìŒ íŒŒì¼ì€ ì½”ë“œ ë³µì¡ë„ ì ìˆ˜ê°€ {target['score']}ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë‚´ì—ì„œ ê°€ì¥ ë†’ë‹¤. 
        ì´ íŒŒì¼ì„ ë¦¬íŒ©í† ë§í•˜ì—¬ ë³µì¡ë„ë¥¼ ë‚®ì¶”ê³  ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì „ëµì„ ìˆ˜ë¦½í•˜ë¼.
        
        [File Path]
        {target['file']}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "file": "{target['file']}",
            "current_score": {target['score']},
            "issue": "ë³µì¡ë„ì˜ ì£¼ìš” ì›ì¸ ì„¤ëª…",
            "refactor_strategy": "ê°œì„  ë°©í–¥ ë° ë°©ë²•",
            "priority": "Critical/High"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Failed to suggest refactor target: {e}")
            return None

    def generate_anti_failure_rule(self, error_log: str, attempt_context: str) -> Optional[Dict[str, Any]]:
        """ì˜¤ë¥˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„ í›„ ì¬ë°œ ë°©ì§€ ê·œì¹™ ìƒì„± ë° ì €ì¥"""
        logger.info("ğŸ” Generating anti-failure rule based on error...")
        
        prompt = f"""ë‹¤ìŒì€ ì½”ë”© ì‘ì—… ì¤‘ ë°œìƒí•œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ë¡œê·¸ì™€ ë§¥ë½ì´ë‹¤.
        ì´ ì‹¤ìˆ˜ê°€ ë‹¤ì‹œëŠ” ë°œìƒí•˜ì§€ ì•Šë„ë¡ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ 'ì‹¤íŒ¨ ë°©ì§€ ê·œì¹™'ì„ JSONìœ¼ë¡œ ìƒì„±í•˜ë¼.
        ë‹¨ìˆœí•œ ì˜¤íƒ€ ìˆ˜ì •ì´ ì•„ë‹Œ, ë…¼ë¦¬ì  ì„¤ê³„ë‚˜ ì•„í‚¤í…ì²˜ì  ì£¼ì˜ ì‚¬í•­ ìœ„ì£¼ë¡œ ì‘ì„±í•˜ë¼.
        
        [Error Log]
        {error_log}
        
        [Context]
        {attempt_context}
        
        ê²°ê³¼ í˜•ì‹:
        {{
            "instruction": "ì—ì´ì „íŠ¸ê°€ ì•ìœ¼ë¡œ ë”°ë¼ì•¼ í•  ì§€ì¹¨",
            "trigger_patterns": ["ì´ ê·œì¹™ì´ í™œì„±í™”ë  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸"],
            "severity": 1~5,
            "reason": "ì™œ ì´ ê·œì¹™ì´ í•„ìš”í•œê°€"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            
            if res_data.get("instruction"):
                self.memory.save_rule(
                    instruction=res_data["instruction"],
                    trigger_patterns=res_data["trigger_patterns"],
                    severity=res_data.get("severity", 3),
                    source_session="reflective_debugging",
                    context=f"Root Cause: {res_data.get('reason')} | Log: {error_log[:200]}"
                )
                logger.info(f"ğŸ›¡ï¸ New anti-failure rule saved: {res_data['instruction'][:50]}...")
                return res_data
        except Exception as e:
            logger.error(f"Failed to generate anti-failure rule: {e}")
            
        return None

    def validate_constraints(self, constraints: List[str], tool_call: Dict[str, Any]) -> Dict[str, Any]:
        """í˜„ì¬ í™œì„±í™”ëœ ì œì•½ ì¡°ê±´(Constraints) ì¤€ìˆ˜ ì—¬ë¶€ ê²€ì¦"""
        if not constraints:
            return {"is_valid": True}
            
        logger.info(f"ğŸ›¡ï¸ Validating {len(constraints)} constraints against tool call...")
        
        prompt = f"""ë„ˆëŠ” Gortex ì‹œìŠ¤í…œì˜ ì¤€ë²• ê°ì‹œê´€(Compliance Officer)ì´ë‹¤.
        ì—ì´ì „íŠ¸ê°€ ìˆ˜í–‰í•˜ë ¤ëŠ” ì‘ì—…ì´ ë‹¤ìŒ 'ì‹œìŠ¤í…œ ê·œì¹™'ë“¤ì„ ìœ„ë°˜í•˜ëŠ”ì§€ ë¶„ì„í•˜ë¼.
        
        [System Constraints]
        {json.dumps(constraints, ensure_ascii=False, indent=2)}
        
        [Proposed Tool Call]
        {json.dumps(tool_call, ensure_ascii=False, indent=2)}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "is_valid": true/false,
            "violated_rules": ["ìœ„ë°˜ëœ ê·œì¹™ 1", "2"],
            "reason": "ìœ„ë°˜ ì‚¬ìœ  ì„¤ëª…",
            "remedy": "ê·œì¹™ì„ ì¤€ìˆ˜í•˜ê¸° ìœ„í•œ í•´ê²°ì±… ì œì•ˆ"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Constraint validation failed: {e}")
            return {"is_valid": True} # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ í†µê³¼ (ì•ˆì „ ëª¨ë“œ)

    def learn_from_interaction(self, question: str, user_answer: str) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ìì™€ì˜ ì§ˆì˜ì‘ë‹µì„ í†µí•´ ìƒˆë¡œìš´ ì§€ì‹ì´ë‚˜ ê·œì¹™ì„ í•™ìŠµ"""
        logger.info("ğŸ“ Learning from user interaction...")
        
        prompt = f"""ë‹¤ìŒ ì‚¬ìš©ìì™€ ì—ì´ì „íŠ¸ ê°„ì˜ ëŒ€í™”ì—ì„œ ì‹œìŠ¤í…œì´ ê¸°ì–µí•´ì•¼ í•  'ì‚¬ìš©ì ì„ í˜¸ë„'ë‚˜ 'ì‹ ê·œ ê·œì¹™'ì´ ìˆë‹¤ë©´ ì¶”ì¶œí•˜ë¼.
        
        [Question]
        {question}
        [User Answer]
        {user_answer}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "knowledge": "ê¸°ì–µí•´ì•¼ í•  í•µì‹¬ ë‚´ìš©",
            "type": "preference | rule | info",
            "confidence": 0.0~1.0
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            if res_data.get("knowledge") and res_data.get("confidence", 0) > 0.7:
                self.memory.ltm.memorize(
                    f"User Learnt: {res_data['knowledge']}",
                    {"source": "Interaction", "type": res_data["type"]}
                )
                return res_data
        except Exception as e:
            logger.error(f"Interaction learning failed: {e}")
        return None

    def auto_finalize_session(self, state: GortexState) -> Dict[str, Any]:
        """ì„¸ì…˜ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ í™œë™ ê¸°ë¡ ë° ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ê°±ì‹ """
        logger.info("ğŸ“„ Starting auto-finalization of session...")
        
        # 1. ìµœê·¼ ë¡œê·¸ ë¶„ì„ì„ í†µí•œ ì„±ê³¼ ìš”ì•½ ìš”ì²­
        prompt = f"""ì§€ê¸ˆê¹Œì§€ì˜ ì‘ì—… ì´ë ¥ê³¼ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë²ˆ ì„¸ì…˜ì˜ ì„±ê³¼ë¥¼ ìš”ì•½í•˜ë¼.
        í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœ: ì—ë„ˆì§€ {state.get('agent_energy')}%, ìµœê·¼ íš¨ìœ¨ {state.get('last_efficiency')}
        
        [State Messages]
        {state['messages'][-20:]}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "version": "v2.x.x (í˜„ì¬ ë²„ì „ë³´ë‹¤ 1ë‹¨ê³„ ë†’ì€ ë²ˆí˜¸ ì œì•ˆ)",
            "goal": "ì´ë²ˆ ì„¸ì…˜ì˜ í•µì‹¬ ëª©í‘œ",
            "done": ["ì™„ë£Œëœ êµ¬ì²´ì  ì‘ì—… 1", "2"],
            "undone": ["ìˆ˜í–‰í•˜ì§€ ëª»í•œ ì‘ì—… ë° ì´ìœ "],
            "decisions": ["ì£¼ìš” ê¸°ìˆ ì  íŒë‹¨ ë° í•©ì˜ ì‚¬í•­"],
            "next_goal": "ë‹¤ìŒ ì„¸ì…˜ì— ìˆ˜í–‰í•  ìµœìš°ì„  ì‘ì—… (Context ë°˜ì˜)"
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            
            # 2. session_XXXX.md ì‘ì„± (ì •í™•í•œ ë²ˆí˜¸ ì‚°ì¶œ)
            sessions_dir = "docs/sessions"
            os.makedirs(sessions_dir, exist_ok=True)
            existing = [f for f in os.listdir(sessions_dir) if f.startswith("session_") and f.endswith(".md")]
            next_num = len(existing) + 1
            session_file = os.path.join(sessions_dir, f"session_{next_num:04d}.md")
            
            session_content = f"""# Session {next_num:04d}

## Goal
- {res_data.get('goal')}

## What Was Done
{chr(10).join([f'- {d}' for d in res_data.get('done', [])])}

## What Was NOT Done
{chr(10).join([f'- {u}' for u in res_data.get('undone', [])])}

## Decisions
{chr(10).join([f'- {dec}' for d in res_data.get('decisions', [])])}

## Notes for Next Session
- {res_data.get('next_goal')}
"""
            with open(session_file, "w", encoding='utf-8') as f:
                f.write(session_content)

            # 3. release_note.md ì—…ë°ì´íŠ¸ (ìµœìƒë‹¨ ì£¼ì…)
            rel_note_path = "docs/release_note.md"
            if os.path.exists(rel_note_path):
                with open(rel_note_path, "r", encoding='utf-8') as f:
                    content = f.read()
                
                version_str = res_data.get('version', 'v2.x.x')
                new_entry = f"### {version_str} ({res_data.get('goal')})\n"
                new_entry += chr(10).join([f"- [x] {d}" for d in res_data.get('done', [])]) + "\n\n"
                
                marker = "## âœ… Completed (Recent Milestones)"
                if marker in content:
                    updated_content = content.replace(marker, f"{marker}\n{new_entry}")
                    with open(rel_note_path, "w", encoding='utf-8') as f:
                        f.write(updated_content)

            # 4. next_session.md ê°±ì‹ 
            next_sess_path = "docs/next_session.md"
            next_sess_content = f"""# Next Session

## Session Goal
- {res_data.get('next_goal')}

## Context
- {res_data.get('goal')} ì™„ë£Œ í›„ ìë™ ê°±ì‹ ë¨ (ì„¸ì…˜ {next_num:04d}).

## Scope
### Do
- {res_data.get('next_goal')} ê´€ë ¨ ê¸°ëŠ¥ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸

## Expected Outputs
- ê´€ë ¨ ì—ì´ì „íŠ¸ ìˆ˜ì • ë° ì‹ ê·œ ë¬¸ì„œ ìƒì„±

## Completion Criteria
- ê¸°ëŠ¥ì„ ì™„ìˆ˜í•˜ê³  pre_commit.shë¥¼ í†µê³¼í•¨
"""
            with open(next_sess_path, "w", encoding='utf-8') as f:
                f.write(next_sess_content)
            
            # [WORKSPACE ORGANIZATION] ë¶€ì‚°ë¬¼ ììœ¨ ì •ë¦¬ ë° ì•„ì¹´ì´ë¹™
            try:
                project_name = os.path.basename(os.getcwd())
                self.organize_workspace(project_name, res_data.get('version', 'v2.x.x'))
            except Exception as org_e:
                logger.warning(f"Workspace organization failed: {org_e}")

            logger.info(f"âœ… Auto-finalized session: {session_file}")
            return res_data
        except Exception as e:
            logger.error(f"Auto-finalization failed: {e}")
            return {}

    def memorize_valuable_thought(self, agent_name: str, thought_tree: List[Dict[str, Any]], success: bool):
        """ì˜ë¯¸ ìˆëŠ” ì‚¬ê³  ê³¼ì •ì„ ë¶„ì„í•˜ì—¬ ì¥ê¸° ê¸°ì–µì— ê°ì¸"""
        if not success or not thought_tree:
            return

        logger.info(f"ğŸ§  Extracting reasoning pattern from {agent_name}'s thought tree...")
        
        prompt = f"""ë‹¤ìŒì€ {agent_name} ì—ì´ì „íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•œ ì‘ì—…ì˜ ì‚¬ê³  ê³¼ì • íŠ¸ë¦¬ë‹¤.
        ì´ ì‚¬ê³  íë¦„ì—ì„œ ë¯¸ë˜ì— ë‹¤ë¥¸ ì—ì´ì „íŠ¸ê°€ ì°¸ê³ í•  ë§Œí•œ 'ìµœì ì˜ ì¶”ë¡  íŒ¨í„´'ì´ë‚˜ 'í•´ê²° ì „ëµ'ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ë¼.
        
        [Thought Tree]
        {json.dumps(thought_tree, ensure_ascii=False, indent=2)}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "strategy_summary": "í•µì‹¬ ì¶”ë¡  ì „ëµ ìš”ì•½",
            "applicability": "ì´ ì „ëµì´ ìœ ìš©í•œ ìƒí™© ì„¤ëª…",
            "keywords": ["ê²€ìƒ‰ìš© í‚¤ì›Œë“œ"]
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            
            if res_data.get("strategy_summary"):
                knowledge_text = f"ì¶”ë¡  íŒ¨í„´ ({agent_name}): {res_data['strategy_summary']} (ì ìš©: {res_data['applicability']})"
                # memory.ltm ëŒ€ì‹  ì§ì ‘ LongTermMemory ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
                from gortex.utils.vector_store import LongTermMemory
                ltm_store = LongTermMemory()
                ltm_store.memorize(
                    knowledge_text, 
                    {"source": "ThoughtReflection", "type": "reasoning_pattern", "agent": agent_name}
                )
                logger.info(f"âœ¨ New reasoning pattern memorized for {agent_name}.")
        except Exception as e:
            logger.error(f"Failed to memorize thought: {e}")

    def predict_next_actions(self, state: GortexState) -> List[Dict[str, str]]:
        """í˜„ì¬ ë§¥ë½ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ë‹¤ìŒ í–‰ë™ì„ ì˜ˆì¸¡ ë° ì œì•ˆ"""
        logger.info("ğŸ”® Predicting next user actions based on context...")
        
        prompt = f"""ì§€ê¸ˆê¹Œì§€ì˜ ì‘ì—… ì§„í–‰ ìƒí™©ê³¼ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ë¼.
        ì‚¬ìš©ìê°€ ë‹¤ìŒì— ìš”ì²­í•  ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì€ ì‘ì—… 3ê°€ì§€ë¥¼ ì˜ˆì¸¡í•˜ê³ , ê°ê°ì— ëŒ€í•´ ê°„ë‹¨í•œ ì œì•ˆ ë¬¸êµ¬ì™€ ì˜ˆìƒ ëª…ë ¹ì–´ë¥¼ ìƒì„±í•˜ë¼.
        
        [Recent Progress]
        {state['messages'][-10:]}
        
        ê²°ê³¼ í˜•ì‹ (JSON):
        {{
            "predictions": [
                {{ "label": "ì œì•ˆ ë¬¸êµ¬ (ì˜ˆ: ë°©ê¸ˆ ì‘ì„±í•œ ì½”ë“œì˜ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í• ê¹Œìš”?)", "command": "ì˜ˆìƒ ëª…ë ¹ì–´ (ì˜ˆ: /test ë˜ëŠ” unittest ì‹¤í–‰ ìš”ì²­)" }}
            ]
        }}
        """
        try:
            response = self.auth.generate("gemini-1.5-flash", [("user", prompt)], {"response_mime_type": "application/json"})
            res_data = json.loads(response.text)
            return res_data.get("predictions", [])[:3]
        except Exception as e:
            logger.error(f"Prediction failed: {e}")
            return []

    def map_knowledge_relations(self):
        """ì§€ì‹ ê°„ì˜ ì˜ë¯¸ë¡ ì  ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì§€ì‹ ì§€ë„(Graph) êµ¬ì¶•"""
        logger.info("ğŸ—ºï¸ Mapping knowledge relations for the brain...")
        from gortex.utils.vector_store import LongTermMemory
        ltm = LongTermMemory()
        
        if len(ltm.memory) < 2:
            return 0
            
        connections_made = 0
        for i, item_a in enumerate(ltm.memory):
            if "vector" not in item_a: continue
            if "links" not in item_a: item_a["links"] = []
            
            for j, item_b in enumerate(ltm.memory):
                if i == j or "vector" not in item_b: continue
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                vec_a, vec_b = item_a["vector"], item_b["vector"]
                dot = sum(a * b for a, b in zip(vec_a, vec_b))
                norm_a = math.sqrt(sum(a * a for a in vec_a))
                norm_b = math.sqrt(sum(b * b for b in vec_b))
                similarity = dot / (norm_a * norm_b) if norm_a > 0 and norm_b > 0 else 0
                
                # ìœ ì‚¬ë„ 0.85 ì´ìƒì´ë©´ ì—°ê²°
                target_id = item_b.get("id", str(j))
                if similarity >= 0.85 and target_id not in item_a["links"]:
                    item_a["links"].append(target_id)
                    connections_made += 1
                    
        if connections_made > 0:
            ltm._save_store()
            logger.info(f"âœ… Knowledge Map updated: {connections_made} connections formed.")
        return connections_made

    def organize_workspace(self, project_name: str, version: str):
        """ì‘ì—… ê³µê°„ì˜ ë¶€ì‚°ë¬¼ë“¤ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°ì ìœ¼ë¡œ ì •ë¦¬ ë° ì•„ì¹´ì´ë¹™"""
        logger.info(f"ğŸ§¹ Organizing workspace for project '{project_name}' (Version: {version})...")
        from gortex.utils.tools import archive_project_artifacts
        
        # ì •ë¦¬ ëŒ€ìƒ í›„ë³´êµ° ìˆ˜ì§‘
        targets = []
        
        # 1. ë°±ì—… íŒŒì¼ë“¤
        if os.path.exists("logs/backups"):
            for f in os.listdir("logs/backups"):
                targets.append(os.path.join("logs/backups", f))
                
        # 2. ë²„ì „ ì•„ì¹´ì´ë¸Œë“¤
        if os.path.exists("logs/versions"):
            for root, dirs, files in os.walk("logs/versions"):
                for f in files: targets.append(os.path.join(root, f))
                
        # 3. ì´ë²ˆ ì„¸ì…˜ì— ìƒì„±ëœ ì„ì‹œ ë°ì´í„° íŒŒì¼ ë“± (ì¶”ê°€ ê°€ëŠ¥)
        
        if targets:
            res = archive_project_artifacts(project_name, version, targets)
            logger.info(res)
            
            # ì •ë¦¬ í›„ ë¹ˆ í´ë” ì‚­ì œ ì‹œë„
            try:
                for d in ["logs/backups", "logs/versions"]:
                    if os.path.exists(d) and not os.listdir(d): os.rmdir(d)
            except: pass
            
        return len(targets)

def analyst_node(state: GortexState) -> Dict[str, Any]:
    """Analyst ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    agent = AnalystAgent()
    
    # [Knowledge Base Optimization] ì •ê¸°ì ì¸ ì§€ì‹ ì •ë¦¬ ë° ê´€ê³„ ë§¤í•‘ ìˆ˜í–‰
    agent.garbage_collect_knowledge()
    agent.map_knowledge_relations()
    
    # [Dynamic Prompting] ì™¸ë¶€ í…œí”Œë¦¿ ë¡œë“œ
    from gortex.utils.prompt_loader import loader
    base_instruction = loader.get_prompt("analyst", persona_id=state.get("assigned_persona", "standard"))
    
    last_msg_obj = state["messages"][-1]
    last_msg = last_msg_obj[1] if isinstance(last_msg_obj, tuple) else last_msg_obj.content
    last_msg_lower = last_msg.lower()

    # [Consensus Logic] Swarmìœ¼ë¡œë¶€í„° í† ë¡  ê²°ê³¼ê°€ ë„˜ì–´ì˜¨ ê²½ìš°
    debate_data = state.get("debate_context", [])
    if debate_data and any(s.get("persona") for s in debate_data):
        # ì›ë³¸ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë°€ í•©ì˜ ë„ì¶œ
        res = agent.synthesize_consensus("High-Risk System Decision", debate_data)
        
        from gortex.utils.translator import i18n
        msg = f"ğŸ¤ **{i18n.t('analyst.consensus_reached', decision=res.get('final_decision')[:50])}**\n\n"
        msg += f"ğŸ“Œ **ìµœì¢… ê²°ì •**: {res.get('final_decision')}\n"
        msg += f"ğŸ’¡ **ê²°ì • ê·¼ê±°**: {res.get('rationale')}\n\n"
        
        msg += "âš–ï¸ **íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„**:\n"
        for t in res.get("tradeoffs", []):
            msg += f"- {t['aspect']}: (+){t['gain']} / (-){t['loss']}\n"
            
        msg += f"\nğŸ›¡ï¸ **ë‚¨ì€ ìœ„í—˜**: {res.get('residual_risk')}\n"
        msg += f"ğŸš€ **ì‹¤í–‰ ê³„íš**: {', '.join(res.get('action_plan', []))}"
            
        history = state.get("consensus_history", [])
        history.append({
            "timestamp": datetime.now().isoformat(),
            "topic": "High-Risk System Decision",
            "decision": res.get("final_decision"),
            "scenarios": debate_data,
            "performance": None # ì‚¬í›„ ì¸¡ì • ì˜ˆì •
        })

        return {
            "messages": [("ai", msg)],
            "next_node": "manager",
            "active_constraints": state.get("active_constraints", []) + [f"Consensus: {res.get('final_decision')[:50]}..."],
            "debate_context": [],
            "consensus_history": history
        }

    # [Consensus Learner] ì´ì „ í•©ì˜ ê²°ê³¼ì˜ ì„±ê³¼ í‰ê°€
    history = state.get("consensus_history", [])
    if history and history[-1]["performance"] is None and state.get("last_efficiency"):
        eff = state["last_efficiency"]
        history[-1]["performance"] = eff
        logger.info(f"ğŸ“ Learning from consensus: Efficiency {eff}")
        
        # ì„±ê³¼ê°€ ë§¤ìš° ì¢‹ê±°ë‚˜ ë‚˜ì  ê²½ìš° ì§„í™” ê·œì¹™ìœ¼ë¡œ ë“±ë¡
        if eff >= 90:
            agent.memory.save_rule(
                f"Proven Success: {history[-1]['decision']}",
                ["consensus", "high-risk"],
                severity=5,
                context=f"Achieved {eff} efficiency."
            )
        elif eff < 40:
            agent.memory.save_rule(
                f"Ineffective Strategy (Avoid): {history[-1]['decision']}",
                ["consensus", "avoid"],
                severity=4,
                context=f"Failed with {eff} efficiency."
            )

    if state.get("next_node") == "analyst":
        ai_outputs = [m for m in state["messages"] if (isinstance(m, tuple) and m[0] == "ai") or (hasattr(m, 'type') and m.type == "ai")]
        if ai_outputs:
            last_ai_msg = ai_outputs[-1][1] if isinstance(ai_outputs[-1], tuple) else ai_outputs[-1].content
            
            # 1. ë¬´ê²°ì„± ê²€ì¦
            val_res = agent.cross_validate("Current Task", last_ai_msg)
            # 2. ìì› í”„ë¡œíŒŒì¼ë§
            perf_res = agent.profile_resource_usage(last_ai_msg)
            
            if not val_res.get("is_valid", True):
                return {"messages": [("ai", f"ğŸ›¡ï¸ [Cross-Validation Alert] {val_res.get('critique')}")], "next_node": "planner"}
            else:
                msg = f"ğŸ›¡ï¸ [Cross-Validation Passed] ë¬´ê²°ì„± ê²€ì¦ í†µê³¼.\n"
                msg += f"âš¡ [Performance Profile] ì˜ˆìƒ ë³µì¡ë„: {perf_res['time_complexity']} (ì ìˆ˜: {perf_res['performance_score']}/100)"
                if perf_res.get("optimization_required"):
                    msg += "\nâš ï¸ ì£¼ì˜: ë¹„íš¨ìœ¨ì ì¸ ë¡œì§ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì í™”ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
                
                economy = state.get("agent_economy", {}).copy()
                credits = state.get("token_credits", {}).copy()
                
                if "coder" not in economy: economy["coder"] = {"points": 0, "level": "Novice"}
                if "coder" not in credits: credits["coder"] = 100.0 # ê¸°ë³¸ í¬ë ˆë”§
                
                economy["coder"]["points"] += 10
                credits["coder"] += 10.0 # ê²€ì¦ í†µê³¼ ë³´ìƒ
                
                return {"messages": [("ai", msg)], "agent_economy": economy, "token_credits": credits, "next_node": "manager"}

    if "/explain" in last_msg_lower:
        return {"messages": [("ai", "Logic explanation complete.")], "next_node": "manager"}
    if "/analyze_style" in last_msg_lower:
        return {"messages": [("ai", "Style analysis complete.")], "next_node": "manager"}
    if "ë¦¬ë·°" in last_msg_lower or "ê²€í† " in last_msg_lower:
        return {"messages": [("ai", "Code review complete.")], "next_node": "manager"}

    data_files = [f for f in last_msg.split() if f.endswith(('.csv', '.xlsx', '.json'))]
    if data_files:
        result = agent.analyze_data(data_files[0])
        from gortex.utils.translator import i18n
        return {"messages": [("ai", i18n.t("analyst.data_analyzed", file=data_files[0]))], "next_node": "manager"}

    return {"messages": [("ai", "ë¶„ì„ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.")], "next_node": "manager"}
