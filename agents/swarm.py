import asyncio
import logging
import time
from typing import Dict, Any, List
from gortex.core.state import GortexState
from gortex.core.auth import GortexAuth
from gortex.agents.analyst import AnalystAgent

from gortex.utils.log_vectorizer import SemanticLogSearch
from gortex.utils.message_queue import GortexMessageQueue

logger = logging.getLogger("GortexSwarm")

async def execute_parallel_task(task_desc: str, state: GortexState) -> Dict[str, Any]:
    """ë‹¨ì¼ í•˜ìœ„ ì‘ì—… ë˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìˆ˜í–‰í•˜ê³  ìƒíƒœ ë¸íƒ€ ë° ì ìˆ˜ ë°˜í™˜"""
    auth = GortexAuth()
    log_search = SemanticLogSearch()
    
    start_time = time.time()
    
    # 1. ê³¼ê±° ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€ í™•ì¸ (Experience Weight)
    past_cases = log_search.search_similar_cases(task_desc, limit=1)
    experience_weight = 0.2 if past_cases else 0.0 # ì„±ê³µ ì‚¬ë¡€ê°€ ìˆìœ¼ë©´ ë³´ë„ˆìŠ¤ ì ìˆ˜
    
    prompt = f"""ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ ë˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ë¼: {task_desc}
    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ì„ ë”°ë¥´ë©°, ì¶”ë¡ ì˜ í™•ì‹ ë„ì™€ ìœ„í—˜ë„ë¥¼ ìì²´ í‰ê°€í•˜ë¼.
    {{ 
        "report": "ì‘ì—… ê²°ê³¼", 
        "certainty": 0.0~1.0, 
        "risk": 0.0~1.0,
        "new_files": {{ "path": "hash" }} 
    }}
    """
    try:
        response = auth.generate("gemini-1.5-flash", [("user", prompt)], {
            "response_mime_type": "application/json"
        })
        latency_ms = int((time.time() - start_time) * 1000)
        
        # í† í° ìˆ˜ ì¶”ì • (metadataê°€ ì—†ìœ¼ë©´ ê¸¸ì´ ê¸°ë°˜)
        tokens = 0
        if hasattr(response, 'usage_metadata') and response.usage_metadata:
            tokens = response.usage_metadata.total_token_count
        else:
            tokens = len(prompt) // 4 + len(response.text) // 4
            
        import json
        res_data = json.loads(response.text)
        return {
            "task": task_desc,
            "report": res_data.get("report", response.text),
            "certainty": res_data.get("certainty", 0.5),
            "risk": res_data.get("risk", 0.5),
            "experience_score": experience_weight,
            "file_cache_delta": res_data.get("new_files", {}),
            "success": True,
            "latency_ms": latency_ms,
            "tokens": tokens
        }
    except Exception as e:
        latency_ms = int((time.time() - start_time) * 1000)
        return {
            "task": task_desc, 
            "report": f"Error: {e}", 
            "certainty": 0, 
            "risk": 1, 
            "experience_score": 0, 
            "file_cache_delta": {}, 
            "success": False,
            "latency_ms": latency_ms,
            "tokens": 0
        }

async def swarm_node_async(state: GortexState) -> Dict[str, Any]:
    """ë³‘ë ¬ ì—ì´ì „íŠ¸ í˜‘ì—… ë…¸ë“œ (Async) - MQ ì—°ë™ ë° íš¨ìœ¨ì„± í‰ê°€ í¬í•¨"""
    tasks = state.get("plan", [])
    if not tasks:
        return {"next_node": "manager"}

    mq = GortexMessageQueue()
    analyst = AnalystAgent()
    logger.info(f"ğŸ Swarm processing {len(tasks)} tasks...")
    
    # 1. íƒœìŠ¤í¬ë“¤ì„ MQì— ë°œí–‰ (Event-Driven ì¤€ë¹„)
    for t in tasks:
        mq.publish("gortex_tasks", {"task": t, "state_id": "session_context"})

    # 2. ê¸°ì¡´ ì‹¤ì‹œê°„ ë³‘ë ¬ ì‹¤í–‰
    task_results = await asyncio.gather(*[execute_parallel_task(t, state) for t in tasks])
    
    # ê³ ë„í™”ëœ ì‹œë‚˜ë¦¬ì˜¤ í‰ê°€ (Score = Efficiency + Certainty - Risk + Experience)
    scored_results = []
    
    # ì—ë„ˆì§€ ë¹„ìš©ì€ ë³‘ë ¬ ì‘ì—… ê°œìˆ˜ì— ë¹„ë¡€ (ë‹¨ìˆœí™”)
    energy_cost_per_task = 5 
    
    for res in task_results:
        # íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°
        eff_score = analyst.calculate_efficiency_score(
            res["success"], 
            res.get("tokens", 0), 
            res.get("latency_ms", 0), 
            energy_cost_per_task
        )
        
        # ì¢…í•© ì ìˆ˜ (íš¨ìœ¨ì„± ì ìˆ˜ë¥¼ 0~1 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜ì˜)
        normalized_eff = eff_score / 100.0
        base_score = res["certainty"] * (1 - res["risk"])
        final_score = base_score + res.get("experience_score", 0) + (normalized_eff * 0.5) # íš¨ìœ¨ì„± ê°€ì¤‘ì¹˜ 0.5
        
        res["efficiency_score"] = eff_score
        scored_results.append((final_score, res))
    
    scored_results.sort(key=lambda x: x[0], reverse=True)
    winner_score, winner = scored_results[0]
    
    # ìš°ìˆ˜ íŒ¨í„´ ìŠ¹ê²© ì‹œë„ (íš¨ìœ¨ì„± ì ìˆ˜ê°€ ë†’ìœ¼ë©´)
    if winner["efficiency_score"] >= 80:
        analyst.memory.promote_efficient_pattern(winner["task"], winner["efficiency_score"], context=winner["report"])
    
    logger.info(f"ğŸ† Scenario Winner: '{winner['task']}' (Score: {winner_score:.2f}, Eff: {winner['efficiency_score']:.1f})")

    merged_file_cache = state.get("file_cache", {}).copy()
    merged_file_cache.update(winner.get("file_cache_delta", {}))

    combined_msg = f"ğŸ Swarm ê°€ì„¤ ì¶”ë¡  ê²°ê³¼:\n\n"
    combined_msg += f"âœ… **ì„ íƒëœ ì•ˆ**: {winner['task']}\n"
    combined_msg += f"ğŸ“Š **ìµœì¢… ì ìˆ˜**: {winner_score:.2f} (í™•ì‹ : {winner['certainty']*100:.0f}%, íš¨ìœ¨: {winner['efficiency_score']:.1f})\n\n"
    combined_msg += f"ğŸ“ **ìƒì„¸ ë³´ê³ **:\n{winner['report']}\n\n"
    
    if len(scored_results) > 1:
        combined_msg += "--- ê¸°íƒ€ ê²€í† ëœ ì‹œë‚˜ë¦¬ì˜¤ ---\n"
        for score, res in scored_results[1:]:
            combined_msg += f"- {res['task']} (Score: {score:.2f}, Eff: {res['efficiency_score']:.1f})\n"

    return {
        "messages": [("ai", combined_msg)],
        "file_cache": merged_file_cache,
        "next_node": "manager",
        "last_efficiency": winner["efficiency_score"], # íš¨ìœ¨ì„± ìƒíƒœ ì—…ë°ì´íŠ¸
        "agent_energy": max(0, state.get("agent_energy", 100) - (len(tasks) * 2)) # ì—ë„ˆì§€ ì†Œëª¨
    }

def swarm_node(state: GortexState) -> Dict[str, Any]:
    """Swarm ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ (Sync wrapper)"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    if loop.is_running():
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(lambda: asyncio.run(swarm_node_async(state)))
            return future.result()
    else:
        return loop.run_until_complete(swarm_node_async(state))
