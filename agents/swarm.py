import asyncio
import logging
import time
from typing import Dict, Any, List
from gortex.core.state import GortexState
from gortex.core.auth import GortexAuth
from gortex.agents.analyst import AnalystAgent

from gortex.utils.log_vectorizer import SemanticLogSearch
from gortex.utils.message_queue import GortexMessageQueue

logger = logging.getLogger("GortexSwarm")

async def execute_parallel_task(task_desc: str, state: GortexState, persona: str = None) -> Dict[str, Any]:
    """ë‹¨ì¼ í•˜ìœ„ ì‘ì—… ë˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìˆ˜í–‰í•˜ê³  ìƒíƒœ ë¸íƒ€ ë° ì ìˆ˜ ë°˜í™˜"""
    auth = GortexAuth()
    log_search = SemanticLogSearch()
    
    start_time = time.time()
    
    # 1. ê³¼ê±° ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€ í™•ì¸ (Experience Weight)
    past_cases = log_search.search_similar_cases(task_desc, limit=1)
    experience_weight = 0.2 if past_cases else 0.0
    
    persona_instruction = ""
    if persona == "Innovation":
        persona_instruction = "[Persona: Innovation] ë„ˆëŠ” íŒŒê²©ì ì´ê³  í˜ì‹ ì ì¸ í•´ê²°ì±…ì„ ì„ í˜¸í•œë‹¤. ì‹ ê¸°ìˆ  ë„ì…ê³¼ êµ¬ì¡°ì  ê°œì„ ì— ì§‘ì¤‘í•˜ë¼."
    elif persona == "Stability":
        persona_instruction = "[Persona: Stability] ë„ˆëŠ” ë³´ìˆ˜ì ì´ê³  ì•ˆì •ì ì¸ í•´ê²°ì±…ì„ ì„ í˜¸í•œë‹¤. ë³´ì•ˆ, í•˜ìœ„ í˜¸í™˜ì„±, ë¦¬ìŠ¤í¬ ìµœì†Œí™”ì— ì§‘ì¤‘í•˜ë¼."

    prompt = f"""{persona_instruction}
    ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ ë˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ë¼: {task_desc}
    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ì„ ë”°ë¥´ë©°, ì¶”ë¡ ì˜ í™•ì‹ ë„ì™€ ìœ„í—˜ë„ë¥¼ ìì²´ í‰ê°€í•˜ë¼.
    {{ 
        "report": "ì‘ì—… ê²°ê³¼", 
        "certainty": 0.0~1.0, 
        "risk": 0.0~1.0,
        "new_files": {{ "path": "hash" }} 
    }}
    """
    try:
        # í• ë‹¹ëœ ëª¨ë¸ ì‚¬ìš© (state ê¸°ë°˜)
        model_id = state.get("assigned_model", "gemini-1.5-flash")
        response = auth.generate(model_id, [("user", prompt)], {
            "response_mime_type": "application/json"
        })
        latency_ms = int((time.time() - start_time) * 1000)
        
        tokens = response.usage_metadata.total_token_count if hasattr(response, 'usage_metadata') and response.usage_metadata else (len(prompt) // 4 + len(response.text) // 4)
            
        import json
        res_data = json.loads(response.text)
        return {
            "task": task_desc,
            "persona": persona,
            "report": res_data.get("report", response.text),
            "certainty": res_data.get("certainty", 0.5),
            "risk": res_data.get("risk", 0.5),
            "experience_score": experience_weight,
            "file_cache_delta": res_data.get("new_files", {}),
            "success": True,
            "latency_ms": latency_ms,
            "tokens": tokens
        }
    except Exception as e:
        latency_ms = int((time.time() - start_time) * 1000)
        return {
            "task": task_desc, "persona": persona, "report": f"Error: {e}", "certainty": 0, "risk": 1, 
            "experience_score": 0, "file_cache_delta": {}, "success": False, "latency_ms": latency_ms, "tokens": 0
        }

async def swarm_node_async(state: GortexState) -> Dict[str, Any]:
    """ë³‘ë ¬ ì—ì´ì „íŠ¸ í˜‘ì—… ë…¸ë“œ (Async) - í† ë¡  í”„ë¡œí† ì½œ ì—°ë™"""
    tasks = state.get("plan", [])
    if not tasks:
        return {"next_node": "manager"}

    mq = GortexMessageQueue()
    analyst = AnalystAgent()
    logger.info(f"ğŸ Swarm processing {len(tasks)} tasks...")
    
    # [Debate Mode] íƒœìŠ¤í¬ê°€ 2ê°œ ì´ìƒì´ê³  ê³ ìœ„í—˜ ìƒí™©ì¸ ê²½ìš° í˜ë¥´ì†Œë‚˜ í• ë‹¹
    is_debate = len(tasks) >= 2 and any("debate" in t.lower() or "í† ë¡ " in t.lower() for t in tasks)
    
    parallel_calls = []
    for i, t in enumerate(tasks):
        persona = None
        if is_debate:
            persona = "Innovation" if i % 2 == 0 else "Stability"
        parallel_calls.append(execute_parallel_task(t, state, persona=persona))
        mq.publish("gortex_tasks", {"task": t, "persona": persona})

    task_results = await asyncio.gather(*parallel_calls)
    
    # ... (ì´í›„ ë­í‚¹ ë¡œì§)
    scored_results = []
    energy_cost_per_task = 5 
    
    for res in task_results:
        eff_score = analyst.calculate_efficiency_score(res["success"], res.get("tokens", 0), res.get("latency_ms", 0), energy_cost_per_task)
        normalized_eff = eff_score / 100.0
        base_score = res["certainty"] * (1 - res["risk"])
        final_score = base_score + res.get("experience_score", 0) + (normalized_eff * 0.5)
        res["efficiency_score"] = eff_score
        scored_results.append((final_score, res))
    
    scored_results.sort(key=lambda x: x[0], reverse=True)
    winner_score, winner = scored_results[0]
    
    # ìš°ìˆ˜ íŒ¨í„´ ìŠ¹ê²©
    if winner["efficiency_score"] >= 80:
        analyst.memory.promote_efficient_pattern(winner["task"], winner["efficiency_score"], context=winner["report"])
    
    logger.info(f"ğŸ† Scenario Winner: '{winner['task']}' (Persona: {winner.get('persona')}, Score: {winner_score:.2f})")

    merged_file_cache = state.get("file_cache", {}).copy()
    merged_file_cache.update(winner.get("file_cache_delta", {}))

    combined_msg = f"ğŸ Swarm {'í† ë¡  ë° ' if is_debate else ''}ê°€ì„¤ ì¶”ë¡  ê²°ê³¼:\n\n"
    combined_msg += f"âœ… **ì„ íƒëœ ì•ˆ**: {winner['task']} ({winner.get('persona', 'Standard')})\n"
    combined_msg += f"ğŸ“Š **ìµœì¢… ì ìˆ˜**: {winner_score:.2f} (íš¨ìœ¨: {winner['efficiency_score']:.1f})\n\n"
    combined_msg += f"ğŸ“ **ìƒì„¸ ë³´ê³ **:\n{winner['report']}\n\n"
    
    if len(scored_results) > 1:
        combined_msg += "--- ê¸°íƒ€ ê²€í† ëœ ì‹œë‚˜ë¦¬ì˜¤ ---\n"
        for score, res in scored_results[1:]:
            combined_msg += f"- {res['task']} ({res.get('persona', 'N/A')}, Score: {score:.2f})\n"

    # í† ë¡  ëª¨ë“œì˜€ì„ ê²½ìš° Analystì—ê²Œ ìµœì¢… í•©ì˜ ë„ì¶œ ìš”ì²­ ê°€ëŠ¥ (next_node ë³€ê²½)
    next_node = "analyst" if is_debate else "manager"

    return {
        "messages": [("ai", combined_msg)],
        "file_cache": merged_file_cache,
        "next_node": next_node,
        "last_efficiency": winner["efficiency_score"],
        "agent_energy": max(0, state.get("agent_energy", 100) - (len(tasks) * 2))
    }
def swarm_node(state: GortexState) -> Dict[str, Any]:
    """Swarm ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ (Sync wrapper)"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    if loop.is_running():
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(lambda: asyncio.run(swarm_node_async(state)))
            return future.result()
    else:
        return loop.run_until_complete(swarm_node_async(state))
