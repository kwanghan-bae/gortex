import json
import os
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from gortex.core.llm.factory import LLMFactory
from gortex.core.state import GortexState
from gortex.agents.researcher import ResearcherAgent
from gortex.utils.vector_store import LongTermMemory

logger = logging.getLogger("GortexTrendScout")

class TrendScoutAgent:
    """
    ì¸í„°ë„· íŠ¸ë Œë“œ(ì‹ ê·œ LLM, ì—ì´ì „íŠ¸ ê¸°ë²•)ë¥¼ ê²€ìƒ‰í•˜ê³  tech_radar.jsonì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì—ì´ì „íŠ¸.
    """
    def __init__(self, radar_path: str = "tech_radar.json"):
        self.radar_path = radar_path
        self.backend = LLMFactory.get_default_backend()
        self.researcher = ResearcherAgent()
        self.ltm = LongTermMemory()
        self.radar_data = self._load_radar()

    def _load_radar(self) -> Dict[str, Any]:
        if os.path.exists(self.radar_path):
            try:
                with open(self.radar_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Failed to load tech radar: {e}")
                return {}
        return {}

    def _save_radar(self):
        try:
            with open(self.radar_path, 'w', encoding='utf-8') as f:
                json.dump(self.radar_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save tech radar: {e}")

    async def check_vulnerabilities(self, model_id: str = "gemini-1.5-flash") -> List[str]:
        """requirements.txtë¥¼ ë¶„ì„í•˜ì—¬ ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì ê²€"""
        req_path = "requirements.txt"
        if not os.path.exists(req_path):
            return ["requirements.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë³´ì•ˆ ì ê²€ì„ ê±´ë„ˆëœë‹ˆë‹¤."]

        logger.info("ğŸ” Scanning for security vulnerabilities in dependencies...")
        try:
            with open(req_path, "r", encoding='utf-8') as f:
                packages = [line.strip() for line in f if line.strip() and not line.startswith("#")]
            
            if not packages:
                return ["ì ê²€í•  íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."]

            findings = []
            for pkg in packages[:10]: # í† í° ë° ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ìƒìœ„ 10ê°œ íŒ¨í‚¤ì§€ ìš°ì„  ì ê²€
                query = f"security vulnerability {pkg} python cve 2024 2025"
                result = await self.researcher.search_and_summarize(query)
                findings.append(f"Package: {pkg}\n{result}")

            analysis_prompt = f"""
            ë‹¤ìŒì€ í”„ë¡œì íŠ¸ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ë“¤ì— ëŒ€í•œ ë³´ì•ˆ ê²€ìƒ‰ ê²°ê³¼ì´ë‹¤.
            ì‹¬ê°í•œ ì·¨ì•½ì (Critical/High)ì´ ë°œê²¬ë˜ì—ˆëŠ”ì§€ ë¶„ì„í•˜ê³ , ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ íŒ¨í‚¤ì§€ ëª©ë¡ì„ ì œì•ˆí•˜ë¼.
            
            [Search Results]
            {"".join(findings)}
            
            ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ë¼:
            {{
                "vulnerabilities_found": true/false,
                "risky_packages": [{{ "name": "íŒ¨í‚¤ì§€ëª…", "cve": "CVE ID", "severity": "High/Medium", "recommendation": "ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ë“±" }}]
            }}
            """
            
            config = {"temperature": 0.0}
            if self.backend.supports_structured_output():
                from google.genai import types
                config = types.GenerateContentConfig(response_mime_type="application/json")

            response_text = self.backend.generate(model_id, [{"role": "user", "content": analysis_prompt}], config)
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            res_data = json.loads(json_match.group(0)) if json_match else json.loads(response_text)
            
            notifications = []
            if res_data.get("vulnerabilities_found"):
                for p in res_data.get("risky_packages", []):
                    msg = f"âš ï¸ [ë³´ì•ˆ ìœ„í—˜] {p['name']}: {p['recommendation']} ({p['severity']})"
                    notifications.append(msg)
                    # tech_radarì— ë³´ì•ˆ ì •ë³´ ê¸°ë¡
                    if "security_alerts" not in self.radar_data:
                        self.radar_data["security_alerts"] = []
                    self.radar_data["security_alerts"].append({
                        "package": p["name"],
                        "detected_at": datetime.now().isoformat(),
                        "details": p
                    })
                self._save_radar()
                return notifications
            return ["âœ… ì£¼ìš” íŒ¨í‚¤ì§€ ë³´ì•ˆ ì ê²€ ê²°ê³¼, ì•Œë ¤ì§„ ì‹¬ê°í•œ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
            
        except Exception as e:
            logger.error(f"Vulnerability scan failed: {e}")
            return [f"ë³´ì•ˆ ì ê²€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"]

    def should_scan(self, interval_hours: int = 24) -> bool:
        """ë§ˆì§€ë§‰ ìŠ¤ìº”ìœ¼ë¡œë¶€í„° ì§€ì •ëœ ì‹œê°„ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸"""
        last_scan_str = self.radar_data.get("last_scan")
        if not last_scan_str:
            return True
        
        try:
            last_scan = datetime.fromisoformat(last_scan_str)
            return datetime.now() > last_scan + timedelta(hours=interval_hours)
        except ValueError:
            return True

    async def scan_trends(self, model_id: str = "gemini-1.5-flash") -> List[str]:
        """ì›¹ ê²€ìƒ‰ì„ í†µí•´ íŠ¸ë Œë“œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„"""
        logger.info("ğŸš€ Scouting for new tech trends and LLM models...")
        
        # [OPTIMIZATION] ì¿¼ë¦¬ ê°œìˆ˜ ì¶•ì†Œ (ì§€ì—° ë°©ì§€)
        queries = [
            "latest LLM agent trends 2025"
        ]
        
        findings = []
        for q in queries:
            try:
                # Researcher íƒ€ì„ì•„ì›ƒ í™œìš©
                result = await self.researcher.search_and_summarize(q)
                findings.append(result)
            except Exception as e:
                logger.warning(f"Trend search failed for '{q}': {e}")

        # ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
        if not findings or not "".join(findings).strip():
            return ["ìƒˆë¡œìš´ íŠ¸ë Œë“œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."]

        # 2. ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½ (LLM)
        analysis_prompt = f"""
        ë‹¤ìŒì€ AI íŠ¸ë Œë“œ ê²€ìƒ‰ ê²°ê³¼ì´ë‹¤. Gortex ì‹œìŠ¤í…œì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ì‹ ê·œ ëª¨ë¸ì´ë‚˜ ì—ì´ì „íŠ¸ ê¸°ë²•ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ë¼.
        
        [Search Results]
        {"".join(findings)[:4000]}
        
        {{
            "models": [{{ "name": "ëª¨ë¸ëª…", "status": "new/updated", "note": "ì„¤ëª…" }}],
            "patterns": [{{ "topic": "ì£¼ì œ", "summary": "ì„¤ëª…" }}]
        }}
        """
        
        config = {"temperature": 0.0}
        if self.backend.supports_structured_output():
            from google.genai import types
            config = types.GenerateContentConfig(response_mime_type="application/json")

        try:
            response_text = self.backend.generate(model_id, [{"role": "user", "content": analysis_prompt}], config)
            
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                extracted = json.loads(json_match.group())
                
                # 3. tech_radar.json ì—…ë°ì´íŠ¸
                self.radar_data["last_scan"] = datetime.now().isoformat()
                
                # í…ŒìŠ¤íŠ¸ í™˜ê²½ì˜ Mock ê°ì²´ ë°©ì–´ ë¡œì§ (JSON ì§ë ¬í™” ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬)
                if not isinstance(extracted, dict):
                    extracted = {}
                
                models = extracted.get("models", [])
                patterns = extracted.get("patterns", [])
                
                # ë¦¬ìŠ¤íŠ¸ íƒ€ì…ì´ ì•„ë‹ˆë©´ (Mock ë“±) ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
                if not isinstance(models, list): models = []
                if not isinstance(patterns, list): patterns = []
                
                self.radar_data["models"] = models
                self.radar_data["patterns"] = patterns
                self._save_radar()
                
                # [Knowledge Base Integration] ìµœì‹  íŠ¸ë Œë“œë¥¼ ì¥ê¸° ê¸°ì–µ ì €ì¥ì†Œì— í†µí•©
                for m in models:
                    if isinstance(m, dict) and "name" in m:
                        knowledge_text = f"ìµœì‹  ëª¨ë¸ ì •ë³´: {m.get('name')}ëŠ” {m.get('status')} ìƒíƒœì´ë©°, íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤: {m.get('note')}"
                        self.ltm.memorize(knowledge_text, {"source": "TrendScout", "type": "model", "topic": m.get('name')})
                
                for p in patterns:
                    if isinstance(p, dict) and "topic" in p:
                        knowledge_text = f"ì‹ ê·œ ì—ì´ì „íŠ¸ íŒ¨í„´: {p.get('topic')} - {p.get('summary')}"
                        self.ltm.memorize(knowledge_text, {"source": "TrendScout", "type": "pattern", "topic": p.get('topic')})

                # ì•Œë¦¼ìš© ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
                notifications = []
                for m in models:
                    if isinstance(m, dict):
                        notifications.append(f"âœ¨ ì‹ ê·œ ëª¨ë¸ ë°œê²¬: {m.get('name')} ({m.get('status')})")
                return notifications
        except Exception as e:
            logger.error(f"Trend analysis parsing failed: {e}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë¬¸ì„ ìš”ì•½í•˜ì—¬ ë°˜í™˜ (ê°€ì§œ ë°ì´í„° ìƒì„± ê¸ˆì§€)
            return [f"íŠ¸ë Œë“œ ìŠ¤ìº” ì™„ë£Œ (êµ¬ì¡°í™” ì‹¤íŒ¨): {response_text[:200]}..."]
            
        return ["íŠ¸ë Œë“œ ë¶„ì„ ìŠ¤ìº”ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ìƒˆë¡œìš´ í•­ëª©ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]

    async def analyze_adoption_opportunity(self, file_list: List[str], model_id: str = "gemini-1.5-flash") -> List[str]:
        """ì‹ ê¸°ìˆ  ë„ì… ê¸°íšŒ ë¶„ì„"""
        if not self.radar_data.get("models") and not self.radar_data.get("patterns"):
            return []
            
        logger.info("ğŸ•µï¸ Analyzing code adoption opportunities...")
        
        # í”„ë¡œì íŠ¸ íŒŒì¼ êµ¬ì¡° ìš”ì•½ (í† í° ì ˆì•½)
        file_summary = "\n".join(file_list[:50]) # ìµœëŒ€ 50ê°œ íŒŒì¼ëª…ë§Œ
        
        radar_summary = json.dumps({
            "models": self.radar_data.get("models", []),
            "patterns": self.radar_data.get("patterns", [])
        }, ensure_ascii=False)
        
        prompt = f"""
        ë‹¤ìŒì€ í˜„ì¬ í”„ë¡œì íŠ¸ì˜ íŒŒì¼ êµ¬ì¡°ì™€ Tech Radarì—ì„œ ë°œê²¬ëœ ì‹ ê¸°ìˆ  ëª©ë¡ì´ë‹¤.
        í”„ë¡œì íŠ¸ì— ë„ì…í•  ë§Œí•œ ê¸°ìˆ ì´ë‚˜ íŒ¨í„´ì´ ìˆëŠ”ì§€ ë¶„ì„í•˜ê³ , ì ìš© ëŒ€ìƒ íŒŒì¼ê³¼ ì´ìœ ë¥¼ ì œì•ˆí•˜ë¼.
        
        [Project Files]
        {file_summary}
        
        [Tech Radar]
        {radar_summary}
        
        ê²°ê³¼ëŠ” JSONìœ¼ë¡œ:
        {{
            "candidates": [
                {{ "tech": "ì´ë¦„", "target_file": "ê²½ë¡œ", "reason": "ì´ìœ ", "effort": "High/Medium/Low" }}
            ]
        }}
        """
        config = {"temperature": 0.0}
        if self.backend.supports_structured_output():
            from google.genai import types
            config = types.GenerateContentConfig(response_mime_type="application/json")

        try:
            response_text = self.backend.generate(model_id, [{"role": "user", "content": prompt}], config)
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            res_data = json.loads(json_match.group(0)) if json_match else json.loads(response_text)
            candidates = res_data.get("candidates", [])
            
            if candidates:
                self.radar_data["adoption_candidates"] = candidates
                self._save_radar()
                return [f"ğŸ’¡ ê¸°ìˆ  ë„ì… ì œì•ˆ: {c['tech']} -> {c['target_file']} ({c['reason']})" for c in candidates]
        except Exception as e:
            logger.error(f"Adoption analysis failed: {e}")
            
        return []

    async def propose_new_agents(self, model_id: str = "gemini-1.5-flash") -> List[Dict[str, Any]]:
        """Tech Radar ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œìŠ¤í…œì— í•„ìš”í•œ ì‹ ê·œ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ ì˜ì… ì œì•ˆ"""
        if not self.radar_data.get("patterns") and not self.radar_data.get("models"):
            return []

        logger.info("ğŸ”­ Designing proactive agent expansion strategies...")
        
        radar_summary = json.dumps({
            "models": self.radar_data.get("models", []),
            "patterns": self.radar_data.get("patterns", [])
        }, ensure_ascii=False)

        prompt = f"""
        ë‹¹ì‹ ì€ Gortex ì‹œìŠ¤í…œì˜ ì§€ëŠ¥ í™•ì¥ ì „ëµê°€ì…ë‹ˆë‹¤. 
        ì•„ë˜ì˜ í…Œí¬ ë ˆì´ë” ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬, Gortex v3.0ì˜ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ ë†’ì¼ ìˆ˜ ìˆëŠ” 'ìƒˆë¡œìš´ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸'ë¥¼ 1ê°œ ì„¤ê³„í•˜ì‹­ì‹œì˜¤.
        
        [Tech Radar]
        {radar_summary}
        
        ì—ì´ì „íŠ¸ ì„¤ê³„ ì¡°ê±´:
        1. ê¸°ì¡´ì˜ Manager, Coder, Planner, Analystì™€ ì—­í• ì´ ê²¹ì¹˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.
        2. êµ¬ì²´ì ì¸ ë„êµ¬(Tools)ì™€ ì‹¤í–‰ ì „ëµì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
        
        ê²°ê³¼ëŠ” JSONìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì‹­ì‹œì˜¤:
        {{
            "proposed_agent": {{
                "agent_name": "UniqueNameAgent",
                "role": "ì—­í• ëª…",
                "description": "ìƒì„¸ ì„¤ëª…",
                "required_tools": ["tool1", "tool2"],
                "logic_strategy": "í•µì‹¬ ì•Œê³ ë¦¬ì¦˜/ë™ì‘ ë°©ì‹",
                "strategic_value": "ì´ ì—ì´ì „íŠ¸ë¥¼ ë„ì…í–ˆì„ ë•Œì˜ ì´ë“"
            }}
        }}
        """
        
        config = {"temperature": 0.0}
        if self.backend.supports_structured_output():
            from google.genai import types
            config = types.GenerateContentConfig(response_mime_type="application/json")

        try:
            response_text = self.backend.generate(model_id, [{"role": "user", "content": prompt}], config)
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            res_data = json.loads(json_match.group(0)) if json_match else json.loads(response_text)
            
            proposal = res_data.get("proposed_agent")
            if proposal:
                # tech_radarì— ì œì•ˆ ê¸°ë¡
                if "agent_proposals" not in self.radar_data:
                    self.radar_data["agent_proposals"] = []
                self.radar_data["agent_proposals"].append({
                    "timestamp": datetime.now().isoformat(),
                    "proposal": proposal
                })
                self._save_radar()
                return [proposal]
        except Exception as e:
            logger.error(f"Agent expansion proposal failed: {e}")
            
        return []

import asyncio
import re

def trend_scout_node(state: GortexState) -> Dict[str, Any]:
    """TrendScout ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    scout = TrendScoutAgent()
    
    interval = int(os.getenv("TREND_SCAN_INTERVAL_HOURS", "24"))
    assigned_model = state.get("assigned_model", "gemini-1.5-flash")
    
    if scout.should_scan(interval):
        file_list = list(state.get("file_cache", {}).keys())
        # ë¹„ë™ê¸° ì‹¤í–‰ (Researcherì™€ ë™ì¼í•œ íŒ¨í„´)
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                # íŠ¸ë Œë“œ ìŠ¤ìº”ê³¼ ë³´ì•ˆ ì ê²€ ë³‘ë ¬ ì‹¤í–‰
                f1 = executor.submit(lambda: asyncio.run(scout.scan_trends(assigned_model)))
                f2 = executor.submit(lambda: asyncio.run(scout.check_vulnerabilities(assigned_model)))
                notifications = f1.result() + f2.result()
                
                # ë„ì… ê¸°íšŒ ë° ì—ì´ì „íŠ¸ í™•ì¥ ì œì•ˆ ë¶„ì„
                f3 = executor.submit(lambda: asyncio.run(scout.analyze_adoption_opportunity(file_list, assigned_model)))
                f4 = executor.submit(lambda: asyncio.run(scout.propose_new_agents(assigned_model)))
                
                notifications += f3.result()
                agent_proposals = f4.result()
                
                for p in agent_proposals:
                    notifications.append(f"ğŸŒŸ [ì„ ì œì  í™•ì¥ ì œì•ˆ] '{p['agent_name']}' ì˜ì… ê²€í†  í•„ìš” ({p['strategic_value']})")
        else:
            n1 = loop.run_until_complete(scout.scan_trends(assigned_model))
            n2 = loop.run_until_complete(scout.check_vulnerabilities(assigned_model))
            n3 = loop.run_until_complete(scout.analyze_adoption_opportunity(file_list, assigned_model))
            n4 = loop.run_until_complete(scout.propose_new_agents(assigned_model))
            notifications = n1 + n2 + n3 + [f"ğŸŒŸ [ì„ ì œì  í™•ì¥ ì œì•ˆ] '{p['agent_name']}' ì˜ì… ê²€í†  í•„ìš”" for p in n4]
            agent_proposals = n4
            
        return {
            "messages": [("ai", "\n".join(notifications))],
            "next_node": "manager",
            "agent_proposals": agent_proposals # ë§¤ë‹ˆì €ì—ê²Œ ì œì•ˆ ë°ì´í„° ì „ë‹¬
        }
    
    return {
        "next_node": "manager"
    }
