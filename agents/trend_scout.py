import json
import os
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from gortex.core.auth import GortexAuth
from gortex.core.state import GortexState
from gortex.agents.researcher import ResearcherAgent

logger = logging.getLogger("GortexTrendScout")

class TrendScoutAgent:
    """
    ì¸í„°ë„· íŠ¸ë Œë“œ(ì‹ ê·œ LLM, ì—ì´ì „íŠ¸ ê¸°ë²•)ë¥¼ ê²€ìƒ‰í•˜ê³  tech_radar.jsonì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì—ì´ì „íŠ¸.
    """
    def __init__(self, radar_path: str = "tech_radar.json"):
        self.radar_path = radar_path
        self.auth = GortexAuth()
        self.researcher = ResearcherAgent()
        self.radar_data = self._load_radar()

    def _load_radar(self) -> Dict[str, Any]:
        if os.path.exists(self.radar_path):
            try:
                with open(self.radar_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Failed to load tech radar: {e}")
                return {}
        return {}

    def _save_radar(self):
        try:
            with open(self.radar_path, 'w', encoding='utf-8') as f:
                json.dump(self.radar_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save tech radar: {e}")

    def should_scan(self, interval_hours: int = 24) -> bool:
        """ë§ˆì§€ë§‰ ìŠ¤ìº”ìœ¼ë¡œë¶€í„° ì§€ì •ëœ ì‹œê°„ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸"""
        last_scan_str = self.radar_data.get("last_scan")
        if not last_scan_str:
            return True
        
        try:
            last_scan = datetime.fromisoformat(last_scan_str)
            return datetime.now() > last_scan + timedelta(hours=interval_hours)
        except ValueError:
            return True

    async def scan_trends(self) -> List[str]:
        """ì›¹ ê²€ìƒ‰ì„ í†µí•´ íŠ¸ë Œë“œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„"""
        logger.info("ğŸš€ Scouting for new tech trends and LLM models...")
        
        # 1. ê²€ìƒ‰ ì¿¼ë¦¬ ì„¤ì •
        queries = [
            "latest free LLM API 2025",
            "Gemini API updates and new models",
            "new autonomous agent patterns and best practices python"
        ]
        
        findings = []
        for q in queries:
            result = await self.researcher.search_and_summarize(q)
            findings.append(result)

        # 2. ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½ (LLM)
        analysis_prompt = f"""
        ë‹¤ìŒì€ ìµœì‹  AI íŠ¸ë Œë“œ ë° ëª¨ë¸ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë“¤ì´ë‹¤.
        Gortex ì‹œìŠ¤í…œì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ì‹ ê·œ ëª¨ë¸ ì†Œì‹ì´ë‚˜ ì—ì´ì „íŠ¸ ì„¤ê³„ ê¸°ë²•ì´ ìˆëŠ”ì§€ ë¶„ì„í•˜ë¼.
        
        [Search Results]
        {"".join(findings)}
        
        ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'models'ì™€ 'patterns' ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ë¼.
        {{
            "models": [{{ "name": "ëª¨ë¸ëª…", "status": "new/updated", "note": "ì„¤ëª…" }}],
            "patterns": [{{ "topic": "ì£¼ì œ", "summary": "ì„¤ëª…" }}]
        }}
        """
        
        response = self.auth.generate("gemini-1.5-flash", [("user", analysis_prompt)], None)
        
        try:
            # ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ (ì •ê·œì‹ ë˜ëŠ” ê°„ë‹¨í•œ íŒŒì‹±)
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            if json_match:
                extracted = json.loads(json_match.group())
                
                # 3. tech_radar.json ì—…ë°ì´íŠ¸
                self.radar_data["last_scan"] = datetime.now().isoformat()
                self.radar_data["models"] = extracted.get("models", [])
                self.radar_data["patterns"] = extracted.get("patterns", [])
                self._save_radar()
                
                # ì•Œë¦¼ìš© ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
                notifications = []
                for m in extracted.get("models", []):
                    notifications.append(f"âœ¨ ì‹ ê·œ ëª¨ë¸ ë°œê²¬: {m['name']} ({m['status']})")
                return notifications
        except Exception as e:
            logger.error(f"Trend analysis parsing failed: {e}")
            
        return ["íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìœ¼ë‚˜, ìŠ¤ìº”ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."]

import asyncio
import re

def trend_scout_node(state: GortexState) -> Dict[str, Any]:
    """TrendScout ë…¸ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    scout = TrendScoutAgent()
    
    interval = int(os.getenv("TREND_SCAN_INTERVAL_HOURS", "24"))
    
    if scout.should_scan(interval):
        # ë¹„ë™ê¸° ì‹¤í–‰ (Researcherì™€ ë™ì¼í•œ íŒ¨í„´)
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(lambda: asyncio.run(scout.scan_trends()))
                notifications = future.result()
        else:
            notifications = loop.run_until_complete(scout.scan_trends())
            
        return {
            "messages": [("ai", "\n".join(notifications))],
            "next_node": "manager"
        }
    
    return {
        "next_node": "manager"
    }
