# ğŸ“¡ Gortex Ollama-based Local Model Expansion Plan

**Status:** Phase 0 (Design Locked / Documentation Only)
**Core Concept:** "Ollama is how Gortex works longer, not how Gortex thinks better."

---

## 1. Core Principles

1.  **Non-Negotiable Continuity**: Ollama ë„ì…ì´ í˜„ì¬ì˜ ì›Œí¬í”Œë¡œìš°ë‚˜ ìë™í™” ê³„ì•½ì„ ê¹¨ëœ¨ë ¤ì„œëŠ” ì•ˆ ëœë‹¤.
2.  **Stateless First**: ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë”ë¼ë„ ëª¨ë“  ë§¥ë½ì€ íŒŒì¼(Repository)ì— ê¸°ë¡ë˜ì–´ì•¼ í•œë‹¤.
3.  **Worker vs Manager**: OllamaëŠ” ë°˜ë³µì ì´ê³  ì •ì˜ëœ ì‘ì—…(Worker)ì„ ìˆ˜í–‰í•˜ë©°, ê³ ìˆ˜ì¤€ì˜ ì„¤ê³„ì™€ ë¼ìš°íŒ…ì€ ì—¬ì „íˆ ê³ ì„±ëŠ¥ ì™¸ë¶€ ëª¨ë¸(Manager)ì´ ë‹´ë‹¹í•œë‹¤.

---

## 2. Phased Rollout Roadmap

### ğŸŸ¦ Phase 1: Utility Tasks (Read-Only)
*   **Target**: ë¡œê·¸ ìš”ì•½, ì»¨í…ìŠ¤íŠ¸ ì••ì¶•(`memory.py`), íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°.
*   **Rule**: íŒŒì¼ ìˆ˜ì •ì´ë‚˜ ì…¸ ì‹¤í–‰ ê¶Œí•œ ì—†ìŒ. ê²°ê³¼ëŠ” ì¡°ì–¸ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©.
*   **Fallback**: Ollama ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ Geminië¡œ ìë™ ì¬ì‹œë„.

### ğŸŸ¨ Phase 2: Bounded Execution (Workers)
*   **Target**: `Coder` (ë£¨í”„ ë‚´ ë‹¨ìˆœ êµ¬í˜„), `Optimizer` (ì„±ëŠ¥ íŠœë‹ ì œì•ˆ).
*   **Constraint**: Plannerê°€ ìˆ˜ë¦½í•œ ëª…ì‹œì  ê³„íš í•˜ì—ì„œë§Œ ì‘ë™. ì‹ ê·œ íŒŒì¼ ìƒì„± ë° ë¬¸ì„œ ìˆ˜ì • ê¸ˆì§€.

### ğŸŸ¥ Phase 3: Isolated Autonomous Loops
*   **Target**: ì¥ê¸° ì‹¤í–‰ ì§„í™” ì‹¤í—˜.
*   **Environment**: ë©”ì¸ ì €ì¥ì†Œì™€ ê²©ë¦¬ëœ ìƒŒë“œë°•ìŠ¤ì—ì„œ êµ¬ë™.

---

## 3. Configuration Plan

`.env` íŒŒì¼ì— ë‹¤ìŒ í•­ëª©ì´ ì¶”ê°€ë  ì˜ˆì •ì´ë‹¤ (Phase 1 ê°€ë™ ì‹œ).
```ini
LLM_BACKEND=gemini        # gemini | ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=qwen2.5-coder:7b
```
