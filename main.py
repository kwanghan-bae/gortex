import os
import asyncio
import random
import logging
from rich.console import Console
from rich.live import Live
from rich.panel import Panel
from dotenv import load_dotenv

from gortex.core.graph import compile_gortex_graph
from gortex.ui.dashboard import DashboardUI
from gortex.ui.dashboard_theme import GORTEX_THEME
from gortex.core.observer import GortexObserver
from gortex.utils.token_counter import count_tokens, estimate_cost

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("GortexMain")

load_dotenv()

async def get_user_input(console: Console):
    """ë¹„ì°¨ë‹¨ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŒ"""
    return await asyncio.get_event_loop().run_in_executor(None, console.input, "[bold green]User > [/bold green]")

async def handle_command(user_input: str, ui: DashboardUI, observer: GortexObserver) -> str:
    """'/'ë¡œ ì‹œì‘í•˜ëŠ” ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë°˜í™˜ê°’ì— ë”°ë¼ ë©”ì¸ ë£¨í”„ì˜ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤."""""
    cmd = user_input.lower().strip()
    
    if cmd == "/clear":
        ui.chat_history = []
        ui.update_main([])
        ui.update_thought("Chat history cleared.")
        return "skip"
    
    elif cmd == "/history":
        ui.chat_history.append(("system", "í˜„ì¬ ì„¸ì…˜ì˜ ëŒ€í™” ë‚´ì—­ì´ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤."))
        ui.update_main(ui.chat_history)
        return "skip"
        
    elif cmd == "/radar":
        import json
        if os.path.exists("tech_radar.json"):
            with open("tech_radar.json", "r") as f:
                radar = json.load(f)
                ui.chat_history.append(("system", f"Tech Radar: {json.dumps(radar, indent=2, ensure_ascii=False)}"))
        else:
            ui.chat_history.append(("system", "Tech Radar ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."))
        ui.update_main(ui.chat_history)
        return "skip"

    elif cmd == "/summarize":
        ui.chat_history.append(("system", "ìˆ˜ë™ ìš”ì•½ì„ ìš”ì²­í•˜ì…¨ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìš”ì•½ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤."))
        ui.update_main(ui.chat_history)
        return "summarize"

    return "continue"

async def run_gortex():
    console = Console(theme=GORTEX_THEME)
    ui = DashboardUI(console)
    observer = GortexObserver()
    
    # ëˆ„ì  í† í° ë° ë¹„ìš©
    total_tokens = 0
    total_cost = 0.0

    workflow = compile_gortex_graph()
    # Persistence ì„¤ì • (SQLite)
    from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
    import aiosqlite
    
    db_path = os.getenv("DB_PATH", "gortex_sessions.db")
    
    async with aiosqlite.connect(db_path) as db:
        memory = AsyncSqliteSaver(db)
        app = workflow.compile(checkpointer=memory)
        
        thread_id = str(random.randint(1000, 9999))
        config = {"configurable": {"thread_id": thread_id}}
        
        console.print(f"[bold cyan]ğŸš€ Gortex v1.0 Initialized. (Thread ID: {thread_id})[/bold cyan]")
        console.print("Type 'exit' to quit. Press 'Ctrl+C' during execution to interrupt current task.\n")

        with Live(ui.layout, console=console, refresh_per_second=4) as live:
            while True:
                try:
                    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
                    live.stop()
                    user_input = await get_user_input(console)
                    live.start()

                    if user_input.lower() in ["exit", "quit", "q"]:
                        break
                    
                    # ëª…ë ¹ì–´ ì²˜ë¦¬
                    cmd_status = "continue"
                    if user_input.startswith("/"):
                        cmd_status = await handle_command(user_input, ui, observer)
                        if cmd_status == "skip":
                            continue
                    
                    # 2. ì‹¤í–‰ ë° ìŠ¤íŠ¸ë¦¬ë° ì—…ë°ì´íŠ¸
                    initial_state = {
                        "messages": [("user", user_input)],
                        "working_dir": os.getenv("WORKING_DIR", "./workspace"),
                        "coder_iteration": 0,
                        "active_constraints": []
                    }
                    
                    # ìˆ˜ë™ ìš”ì•½ ìš”ì²­ ì‹œ ë”ë¯¸ ë©”ì‹œì§€ë¥¼ ì±„ì›Œ summarizer íŠ¸ë¦¬ê±°
                    if cmd_status == "summarize":
                        initial_state["messages"] = [("system", "Manual summary trigger")] * 12

                    from gortex.core.evolutionary_memory import EvolutionaryMemory
                    evo_mem = EvolutionaryMemory()
                    initial_state["active_constraints"] = evo_mem.get_active_constraints(user_input)

                    try:
                        async for event in app.astream(initial_state, config):
                            # ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ UIì— ë°˜ì˜
                            for node_name, output in event.items():
                                ui.current_agent = node_name
                                
                                # ë„êµ¬ ì‹¤í–‰ ê°ì§€
                                has_tool_call = False
                                if "messages" in output:
                                    for m in output["messages"]:
                                        if (isinstance(m, tuple) and m[0] == "tool") or (hasattr(m, 'type') and m.type == "tool"):
                                            has_tool_call = True
                                            break
                                
                                if has_tool_call:
                                    ui.start_tool_progress(f"Agent {node_name} is using tools...")
                                else:
                                    ui.stop_tool_progress()

                                # ì‚¬ê³  ê³¼ì •(Thought) ì¶”ì¶œ ë° UI ë°˜ì˜
                                thought = output.get("thought") or output.get("thought_process")
                                if thought:
                                    ui.update_thought(thought, agent_name=node_name)

                                if "messages" in output:
                                    for msg in output["messages"]:
                                        if isinstance(msg, tuple):
                                            role, content = msg
                                            ui.chat_history.append(msg)
                                        else:
                                            role = msg.type
                                            content = msg.content
                                            ui.chat_history.append((role, content))
                                        
                                        new_tokens = count_tokens(content)
                                        total_tokens += new_tokens
                                        total_cost += estimate_cost(new_tokens)
                                
                                ui.update_main(ui.chat_history)
                                ui.update_sidebar(
                                    agent=ui.current_agent,
                                    step=str(output.get("current_step", "N/A")),
                                    tokens=total_tokens,
                                    cost=total_cost,
                                    rules=len(initial_state["active_constraints"])
                                )
                                
                                log_entry = {"agent": node_name, "event": "node_complete"}
                                ui.update_logs(log_entry)
                                observer.log_event(node_name, "node_complete", output)
                                
                                await asyncio.sleep(0.1)
                                ui.reset_thought_style()
                                
                    except KeyboardInterrupt:
                        ui.chat_history.append(("system", "âš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì‘ì—…ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."))
                        ui.update_main(ui.chat_history)
                        ui.stop_tool_progress()
                        ui.reset_thought_style()
                        logger.info("Agent execution interrupted.")

                    ui.current_agent = "Idle"
                    ui.complete_thought_style()
                    ui.update_sidebar("Idle", "N/A", total_tokens, total_cost, len(initial_state["active_constraints"]))

                except KeyboardInterrupt:
                    break
                except Exception as e:
                    error_msg = str(e)
                    if "í• ë‹¹ëŸ‰" in error_msg or "exhausted" in error_msg.lower():
                        live.stop()
                        console.print("\n")
                        console.print(Panel(
                            "[bold red]ğŸš« API í• ë‹¹ëŸ‰ ê¸´ê¸‰ ì†Œì§„![/bold red]\n\n" 
                            "ëª¨ë“  Gemini API í‚¤ì˜ ë¬´ë£Œ í• ë‹¹ëŸ‰ì´ ë°”ë‹¥ë‚¬ìŠµë‹ˆë‹¤.\n" 
                            "1. [yellow].env[/yellow] íŒŒì¼ì— ìƒˆë¡œìš´ API í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.\n" 
                            "2. ì¼ì • ì‹œê°„ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n\n" 
                            "[dim]ì‹œìŠ¤í…œì„ ì•ˆì „í•˜ê²Œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.[/dim]",
                            title="Quota Emergency",
                            border_style="red",
                            expand=False
                        ))
                        break
                    
                    console.print(f"[bold red]Error: {e}[/bold red]")
                    observer.log_event("System", "error", str(e))
                    break

    console.print("\n[bold cyan]ğŸ‘‹ Gortex session ended. State saved.[/bold cyan]")

if __name__ == "__main__":
    try:
        asyncio.run(run_gortex())
    except KeyboardInterrupt:
        pass